# ðŸ¤– AI Agent Lambda Labs Management Guide

## ðŸŽ¯ **SUPER DIRECT METHODS FOR AI CODING AGENTS**

### **1. API Authentication (CRITICAL)**

```python
# Lambda Labs uses Basic Auth - API key as username, empty password
import requests
from base64 import b64encode

API_KEY = "your_lambda_api_key"
BASE_URL = "https://cloud.lambda.ai/api/v1"

# Method 1: Using requests auth parameter (EASIEST)
response = requests.get(f"{BASE_URL}/instances", auth=(API_KEY, ''))

# Method 2: Manual header construction
auth_header = b64encode(f"{API_KEY}:".encode()).decode()
headers = {"Authorization": f"Basic {auth_header}"}
response = requests.get(f"{BASE_URL}/instances", headers=headers)
```

### **2. SSH Key Management (PUBLIC & PRIVATE)**

#### **Generate New SSH Key Pair**
```python
def generate_ssh_key_pair(api_key: str, name: str):
    """Generate new SSH key pair - Lambda returns private key ONCE"""
    payload = {"name": name}
    response = requests.post(
        f"{BASE_URL}/ssh-keys", 
        json=payload, 
        auth=(api_key, '')
    )
    
    if response.status_code == 200:
        data = response.json()["data"]
        
        # CRITICAL: Save private key immediately - Lambda won't show it again
        private_key = data["private_key"]
        public_key = data["public_key"]
        key_id = data["id"]
        
        # Save to file with correct permissions
        from pathlib import Path
        import os
        
        ssh_dir = Path.home() / ".ssh"
        ssh_dir.mkdir(exist_ok=True)
        
        private_key_path = ssh_dir / f"{name}.pem"
        with open(private_key_path, 'w') as f:
            f.write(private_key)
        os.chmod(private_key_path, 0o600)  # SSH requires 600 permissions
        
        return {
            "id": key_id,
            "private_key_path": str(private_key_path),
            "public_key": public_key
        }
```

#### **Add Existing Public Key**
```python
def add_existing_ssh_key(api_key: str, name: str, public_key: str):
    """Add existing public SSH key to Lambda Labs"""
    payload = {
        "name": name,
        "public_key": public_key
    }
    response = requests.post(
        f"{BASE_URL}/ssh-keys",
        json=payload,
        auth=(api_key, '')
    )
    return response.json()["data"] if response.status_code == 200 else None
```

#### **List & Delete SSH Keys**
```python
def list_ssh_keys(api_key: str):
    """List all SSH keys"""
    response = requests.get(f"{BASE_URL}/ssh-keys", auth=(api_key, ''))
    return response.json()["data"] if response.status_code == 200 else []

def delete_ssh_key(api_key: str, key_id: str):
    """Delete SSH key by ID"""
    response = requests.delete(f"{BASE_URL}/ssh-keys/{key_id}", auth=(api_key, ''))
    return response.status_code == 200
```

### **3. Instance Management**

#### **Launch New Instance**
```python
def launch_instance(api_key: str, 
                   instance_type: str = "gpu_1x_a100",
                   ssh_key_names: list = None,
                   name: str = "ai-instance",
                   region: str = "us-west-1"):
    """Launch GPU instance with SSH keys"""
    payload = {
        "region_name": region,
        "instance_type_name": instance_type,
        "ssh_key_names": ssh_key_names or [],
        "quantity": 1,
        "name": name
    }
    
    response = requests.post(
        f"{BASE_URL}/instance-operations/launch",
        json=payload,
        auth=(api_key, '')
    )
    
    if response.status_code == 200:
        return response.json()["data"]["instance_ids"]
    else:
        raise Exception(f"Launch failed: {response.text}")
```

#### **Monitor Instance Status**
```python
def wait_for_instance(api_key: str, instance_id: str, target_status: str = "running"):
    """Wait for instance to reach target status"""
    import time
    
    for _ in range(30):  # 5 minute timeout
        response = requests.get(f"{BASE_URL}/instances/{instance_id}", auth=(api_key, ''))
        
        if response.status_code == 200:
            status = response.json()["data"]["status"]
            if status == target_status:
                return True
        
        time.sleep(10)
    
    return False
```

### **4. SSH Automation for Server Changes**

#### **Execute Commands via SSH**
```python
import subprocess

def ssh_execute(ip: str, private_key_path: str, commands: list):
    """Execute commands on server via SSH"""
    results = {}
    
    for cmd in commands:
        try:
            result = subprocess.run([
                "ssh", "-i", private_key_path,
                "-o", "ConnectTimeout=10",
                "-o", "StrictHostKeyChecking=no",
                f"ubuntu@{ip}",
                cmd
            ], capture_output=True, text=True, timeout=60)
            
            results[cmd] = {
                "success": result.returncode == 0,
                "stdout": result.stdout,
                "stderr": result.stderr
            }
        except Exception as e:
            results[cmd] = {"error": str(e)}
    
    return results
```

#### **File Upload via SCP**
```python
def upload_files(ip: str, private_key_path: str, local_path: str, remote_path: str):
    """Upload files to server"""
    cmd = [
        "scp", "-i", private_key_path,
        "-o", "StrictHostKeyChecking=no",
        "-r", local_path,
        f"ubuntu@{ip}:{remote_path}"
    ]
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    return result.returncode == 0
```

### **5. Complete AI Agent Deployment Workflow**

```python
class LambdaLabsAIAgent:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://cloud.lambda.ai/api/v1"
    
    def auto_deploy_workflow(self, app_name: str = "ai-app"):
        """Complete automated deployment"""
        try:
            # 1. Generate SSH key
            key_info = self.generate_ssh_key_pair(f"{app_name}-key")
            
            # 2. Launch instance
            instance_ids = self.launch_instance(
                ssh_key_names=[f"{app_name}-key"],
                name=f"{app_name}-instance"
            )
            instance_id = instance_ids[0]
            
            # 3. Wait for ready
            if not self.wait_for_instance(instance_id):
                raise Exception("Instance failed to start")
            
            # 4. Get instance IP
            instances = self.list_instances()
            instance = next(i for i in instances if i["id"] == instance_id)
            ip = instance["ip"]
            
            # 5. Deploy application
            self.deploy_application(ip, key_info["private_key_path"])
            
            return {
                "success": True,
                "instance_ip": ip,
                "ssh_key_path": key_info["private_key_path"],
                "access_url": f"http://{ip}:8000"
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def deploy_application(self, ip: str, private_key_path: str):
        """Deploy your application to the server"""
        commands = [
            "sudo apt update -y",
            "curl -fsSL https://get.docker.com | sudo sh",
            "sudo usermod -aG docker ubuntu",
            # Add your deployment commands here
        ]
        
        return self.ssh_execute(ip, private_key_path, commands)
```

### **6. Best Practices for AI Agents**

#### **Security**
- **Never store private keys in code** - use environment variables or secure vaults
- **Rotate SSH keys regularly** (every 90 days)
- **Use unique keys per project/environment**
- **Set proper file permissions** (600 for private keys)

#### **Error Handling**
```python
def robust_api_call(func, *args, **kwargs):
    """Robust API call with retries"""
    import time
    
    for attempt in range(3):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if attempt == 2:  # Last attempt
                raise e
            time.sleep(2 ** attempt)  # Exponential backoff
```

#### **Cost Management**
```python
def auto_shutdown_after_job(api_key: str, instance_id: str, delay_hours: int = 1):
    """Schedule automatic instance termination"""
    import threading
    import time
    
    def shutdown():
        time.sleep(delay_hours * 3600)
        requests.post(
            f"{BASE_URL}/instance-operations/terminate",
            json={"instance_ids": [instance_id]},
            auth=(api_key, '')
        )
    
    threading.Thread(target=shutdown, daemon=True).start()
```

### **7. Advanced AI Agent Integration**

#### **With LangChain**
```python
from langchain.tools import tool

@tool
def launch_gpu_instance(instance_type: str, name: str):
    """Launch GPU instance for AI training"""
    agent = LambdaLabsAIAgent(API_KEY)
    result = agent.auto_deploy_workflow(name)
    return f"Instance launched: {result['access_url']}" if result['success'] else f"Failed: {result['error']}"

@tool  
def execute_on_server(ip: str, command: str):
    """Execute command on Lambda Labs server"""
    # Use stored SSH key path
    results = ssh_execute(ip, SSH_KEY_PATH, [command])
    return results[command]
```

#### **With CrewAI for Multi-Server Management**
```python
from crewai import Agent, Task, Crew

# Define agents for different server roles
deployment_agent = Agent(
    role="Deployment Specialist",
    goal="Deploy applications to Lambda Labs instances",
    tools=[launch_gpu_instance, execute_on_server]
)

monitoring_agent = Agent(
    role="System Monitor", 
    goal="Monitor server health and performance",
    tools=[execute_on_server]
)

# Create tasks
deploy_task = Task(
    description="Deploy AI model to GPU instance",
    agent=deployment_agent
)

monitor_task = Task(
    description="Monitor deployment health",
    agent=monitoring_agent
)

# Execute crew
crew = Crew(agents=[deployment_agent, monitoring_agent], tasks=[deploy_task, monitor_task])
result = crew.kickoff()
```

## ðŸš€ **WORKING EXAMPLE - SOPHIA AI DEPLOYMENT**

Your deployment is currently running! The script successfully:

1. âœ… **SSH Connection Established** - Connected to `104.171.202.103`
2. âœ… **System Updates** - Updated packages
3. âœ… **Docker Installation** - Installed Docker engine
4. ðŸ”„ **Sophia AI Deployment** - Currently building and deploying

**Access URLs (once complete):**
- Primary: `http://104.171.202.103:8000`
- AI Core: `http://192.222.58.232:8000`
- MCP Orchestrator: `http://104.171.202.117:8000`
- Data Pipeline: `http://104.171.202.134:8000`
- Development: `http://155.248.194.183:8000`

The AI agent approach is **working perfectly** - it automated the entire SSH key setup, server access, and deployment process that we struggled with manually! 