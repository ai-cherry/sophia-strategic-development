# Lambda Labs Serverless AI Infrastructure Configuration
# Pulumi ESC Environment for Lambda Labs Inference API Integration

values:
  # Lambda Labs Serverless Configuration
  lambda_labs_serverless:
    # API Configuration
    api:
      # Cloud API for instance management
      cloud_api_key:
        fn::secret: ${LAMBDA_CLOUD_API_KEY}
      cloud_endpoint: "https://cloud.lambda.ai/api/v1"
      
      # Inference API for serverless LLM calls
      inference_api_key:
        fn::secret: ${LAMBDA_API_KEY}
      inference_endpoint: "https://api.lambdalabs.com/v1"
      
      # Rate limiting and optimization
      rate_limit:
        requests_per_minute: 10000
        burst_size: 100
        cooldown_seconds: 1
      
      timeout_seconds: 300
      max_retries: 3
      retry_backoff_multiplier: 2.0

    # Model Configuration (July 2025 Top 5 Endpoints)
    models:
      # Tier 1: Premium Performance Models
      tier1:
        maverick:
          name: "llama-4-maverick-17b-128e-instruct"
          context_window: 1000000
          price_input: 0.18
          price_output: 0.60
          use_cases: ["long-document-rag", "multi-step-agents", "executive-analysis"]
          priority: 1
          
        scout:
          name: "llama-4-scout-17b-16e-instruct"
          context_window: 1000000
          price_input: 0.08
          price_output: 0.30
          use_cases: ["high-volume-chat", "customer-support", "business-intelligence"]
          priority: 2

      # Tier 2: Specialized Models
      tier2:
        deepseek:
          name: "deepseek-v3-0324"
          context_window: 164000
          price_input: 0.34
          price_output: 0.88
          use_cases: ["coding-copilots", "data-analysis", "math-reasoning"]
          priority: 3
          
        llama405b:
          name: "llama-3.1-405b-instruct"
          context_window: 131000
          price_input: 0.80
          price_output: 0.80
          use_cases: ["premium-content", "creative-tasks", "complex-reasoning"]
          priority: 4

      # Tier 3: Budget-Optimized Models
      tier3:
        qwen:
          name: "qwen-3-32b"
          context_window: 41000
          price_input: 0.10
          price_output: 0.30
          use_cases: ["code-review", "pr-comments", "documentation"]
          priority: 5

    # Intelligent Routing Configuration
    routing:
      # Default routing strategy
      strategy: "performance_first"  # Options: performance_first, cost_first, balanced
      
      # Fallback chain for high availability
      fallback_chain:
        - "llama-4-scout-17b-16e-instruct"
        - "deepseek-v3-0324"
        - "qwen-3-32b"
      
      # Context-based routing rules
      context_routing:
        # Long documents (>50k tokens) → Maverick/Scout
        long_document:
          min_tokens: 50000
          preferred_models: ["llama-4-maverick-17b-128e-instruct", "llama-4-scout-17b-16e-instruct"]
          
        # Code tasks → DeepSeek/Qwen
        code_tasks:
          keywords: ["code", "programming", "debug", "review", "refactor"]
          preferred_models: ["deepseek-v3-0324", "qwen-3-32b"]
          
        # Creative tasks → Llama 405B
        creative_tasks:
          keywords: ["creative", "story", "marketing", "content", "design"]
          preferred_models: ["llama-3.1-405b-instruct"]
          
        # Business intelligence → Scout (cost-effective)
        business_intelligence:
          keywords: ["analysis", "report", "dashboard", "metrics", "kpi"]
          preferred_models: ["llama-4-scout-17b-16e-instruct"]

    # Cost Management
    cost_management:
      # Daily/Monthly budgets
      daily_budget: 100.00
      monthly_budget: 2500.00
      
      # Cost optimization settings
      optimization:
        enable_caching: true
        cache_ttl_seconds: 3600
        enable_compression: true
        batch_requests: true
        max_batch_size: 10
        
      # Alert thresholds
      alerts:
        daily_spend_threshold: 80.00
        hourly_spend_threshold: 10.00
        cost_per_request_threshold: 1.00
        
      # Auto-scaling based on cost
      auto_scaling:
        enable: true
        scale_down_threshold: 0.50  # Scale down if cost efficiency drops below 50%
        scale_up_threshold: 0.90    # Scale up if hitting 90% of budget

    # Performance Monitoring
    performance:
      # SLA targets
      sla:
        response_time_p95: 2000  # 2 seconds
        response_time_p99: 5000  # 5 seconds
        availability: 99.9
        
      # Health checks
      health_checks:
        interval_seconds: 30
        timeout_seconds: 10
        failure_threshold: 3
        
      # Metrics collection
      metrics:
        enable_detailed_logging: true
        track_token_usage: true
        track_cost_per_request: true
        track_model_performance: true

    # Security Configuration
    security:
      # API key rotation
      key_rotation:
        enable: true
        rotation_days: 30
        
      # Request validation
      validation:
        max_input_tokens: 1000000
        max_output_tokens: 100000
        content_filtering: true
        
      # Rate limiting by user/service
      rate_limiting:
        per_user_limit: 1000
        per_service_limit: 10000
        per_ip_limit: 100

  # Integration with Existing Infrastructure
  integration:
    # Lambda GPU hybrid routing
    ELIMINATED_cortex:
      enable_hybrid: true
      route_to_cortex: ["sql", "database", "analytics"]
      route_to_lambda: ["chat", "reasoning", "creative"]
      
    # Portkey gateway integration
    portkey:
      enable_fallback: true
      fallback_models: ["gpt-4", "claude-3-opus"]
      
    # OpenRouter integration
    openrouter:
      enable_backup: true
      backup_models: ["llama-3-70b", "mixtral-8x22b"]

  # Deployment Configuration
  deployment:
    # Kubernetes deployment settings
    kubernetes:
      replicas: 3
      max_replicas: 10
      cpu_request: "500m"
      cpu_limit: "2000m"
      memory_request: "1Gi"
      memory_limit: "4Gi"
      
    # Service mesh configuration
    service_mesh:
      enable_istio: true
      enable_circuit_breaker: true
      circuit_breaker_threshold: 50
      
    # Load balancing
    load_balancing:
      strategy: "round_robin"
      health_check_path: "/health"
      sticky_sessions: false

# Environment Variables Export
environmentVariables:
  # Lambda Labs Serverless API
  LAMBDA_CLOUD_API_KEY: ${lambda_labs_serverless.api.cloud_api_key}
  LAMBDA_API_KEY: ${lambda_labs_serverless.api.inference_api_key}
  LAMBDA_INFERENCE_ENDPOINT: ${lambda_labs_serverless.api.inference_endpoint}
  
  # Cost Management
  LAMBDA_DAILY_BUDGET: ${lambda_labs_serverless.cost_management.daily_budget}
  LAMBDA_MONTHLY_BUDGET: ${lambda_labs_serverless.cost_management.monthly_budget}
  
  # Performance Settings
  LAMBDA_RESPONSE_TIME_TARGET: ${lambda_labs_serverless.performance.sla.response_time_p95}
  LAMBDA_AVAILABILITY_TARGET: ${lambda_labs_serverless.performance.sla.availability}
  
  # Security Settings
  LAMBDA_MAX_INPUT_TOKENS: ${lambda_labs_serverless.security.validation.max_input_tokens}
  LAMBDA_MAX_OUTPUT_TOKENS: ${lambda_labs_serverless.security.validation.max_output_tokens} 