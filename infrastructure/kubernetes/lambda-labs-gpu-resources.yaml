# Lambda Labs GPU Resource Configuration for Sophia AI
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: lambda-labs-gpu-quota
  namespace: sophia-ai
spec:
  hard:
    requests.nvidia.com/gpu: "4" # Total GPU requests
    limits.nvidia.com/gpu: "4" # Total GPU limits
    requests.cpu: "16" # Total CPU requests
    requests.memory: 32Gi # Total memory requests
    limits.cpu: "32" # Total CPU limits
    limits.memory: 64Gi # Total memory limits
    persistentvolumeclaims: "10" # Total PVC count
    requests.storage: 100Gi # Total storage requests

---
apiVersion: v1
kind: LimitRange
metadata:
  name: lambda-labs-limits
  namespace: sophia-ai
spec:
  limits:
    - default:
        nvidia.com/gpu: "0.25"
        cpu: "1000m"
        memory: "2Gi"
      defaultRequest:
        nvidia.com/gpu: "0.25"
        cpu: "200m"
        memory: "512Mi"
      type: Container
    - max:
        nvidia.com/gpu: "1"
        cpu: "4000m"
        memory: "8Gi"
      min:
        nvidia.com/gpu: "0.1"
        cpu: "100m"
        memory: "128Mi"
      type: Container

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: lambda-labs-nodepool-config
  namespace: sophia-ai
  labels:
    app: sophia-ai
    component: nodepool-config
data:
  nodepool.yaml: |
    # Lambda Labs GPU Node Pool Configuration
    apiVersion: v1
    kind: Node
    metadata:
      labels:
        lambdalabs.com/gpu-type: "rtx-4090"
        lambdalabs.com/instance-type: "gpu_1x_a10"
        nvidia.com/gpu.present: "true"
        nvidia.com/gpu.count: "1"
        kubernetes.io/arch: "amd64"
        node.kubernetes.io/instance-type: "gpu_1x_a10"
    spec:
      capacity:
        nvidia.com/gpu: "1"
        cpu: "8"
        memory: "32Gi"
        ephemeral-storage: "100Gi"
      allocatable:
        nvidia.com/gpu: "1"
        cpu: "7.5"
        memory: "30Gi"
        ephemeral-storage: "95Gi"
      taints:
        - key: "lambdalabs.com/gpu"
          value: "true"
          effect: "NoSchedule"

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-dcgm-exporter
  namespace: sophia-ai
  labels:
    app: nvidia-dcgm-exporter
spec:
  selector:
    matchLabels:
      app: nvidia-dcgm-exporter
  template:
    metadata:
      labels:
        app: nvidia-dcgm-exporter
    spec:
      nodeSelector:
        lambdalabs.com/gpu-type: "rtx-4090"
      tolerations:
        - key: "lambdalabs.com/gpu"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
      containers:
        - name: nvidia-dcgm-exporter
          image: nvcr.io/nvidia/k8s/dcgm-exporter:3.1.7-3.1.4-ubuntu20.04
          ports:
            - name: metrics
              containerPort: 9400
          securityContext:
            privileged: true
          volumeMounts:
            - name: proc
              mountPath: /host/proc
              readOnly: true
            - name: sys
              mountPath: /host/sys
              readOnly: true
          resources:
            requests:
              memory: "128Mi"
              cpu: "100m"
            limits:
              memory: "256Mi"
              cpu: "200m"
      volumes:
        - name: proc
          hostPath:
            path: /proc
        - name: sys
          hostPath:
            path: /sys
      hostNetwork: true
      hostPID: true
