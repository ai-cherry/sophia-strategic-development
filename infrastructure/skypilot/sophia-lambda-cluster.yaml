# SkyPilot configuration for Sophia AI on Lambda Labs
# This creates a multi-region GPU cluster with Kubernetes

name: sophia-ai-cluster

# Lambda Labs cloud provider
cloud: lambda

# Multi-node cluster configuration
num_nodes: 5

# Node-specific configurations
node_config:
  # Control plane on RTX 6000
  - name: sophia-production-instance
    instance_type: gpu_1x_rtx6000
    region: us-south-1
    disk_size: 100
    role: control-plane
    
  # AI Core on GH200
  - name: sophia-ai-core
    instance_type: gpu_1x_gh200
    region: us-east-3
    disk_size: 500
    role: worker
    labels:
      gpu-type: gh200
      workload: ai-ml
    
  # MCP Orchestrator on A6000
  - name: sophia-mcp-orchestrator
    instance_type: gpu_1x_a6000
    region: us-south-1
    disk_size: 200
    role: worker
    labels:
      gpu-type: a6000
      workload: mcp-servers
    
  # Data Pipeline on A100
  - name: sophia-data-pipeline
    instance_type: gpu_1x_a100
    region: us-south-1
    disk_size: 500
    role: worker
    labels:
      gpu-type: a100
      workload: data-processing
    
  # Development on A10
  - name: sophia-development
    instance_type: gpu_1x_a10
    region: us-west-1
    disk_size: 100
    role: worker
    labels:
      gpu-type: a10
      workload: development

# Setup commands run on all nodes
setup: |
  # Update system
  sudo apt-get update
  sudo apt-get upgrade -y
  
  # Install Docker
  curl -fsSL https://get.docker.com -o get-docker.sh
  sudo sh get-docker.sh
  sudo usermod -aG docker $USER
  
  # Install Kubernetes prerequisites
  sudo apt-get install -y apt-transport-https ca-certificates curl gpg
  
  # Add Kubernetes repository
  curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
  echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
  
  # Install Kubernetes components
  sudo apt-get update
  sudo apt-get install -y kubelet=1.29.0-1.1 kubeadm=1.29.0-1.1 kubectl=1.29.0-1.1
  sudo apt-mark hold kubelet kubeadm kubectl
  
  # Configure container runtime
  sudo mkdir -p /etc/containerd
  containerd config default | sudo tee /etc/containerd/config.toml
  sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/g' /etc/containerd/config.toml
  sudo systemctl restart containerd
  
  # Enable IP forwarding
  sudo modprobe br_netfilter
  sudo sysctl net.bridge.bridge-nf-call-iptables=1
  sudo sysctl net.ipv4.ip_forward=1
  echo "net.bridge.bridge-nf-call-iptables=1" | sudo tee -a /etc/sysctl.conf
  echo "net.ipv4.ip_forward=1" | sudo tee -a /etc/sysctl.conf
  
  # Install NVIDIA container toolkit
  distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
  curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
  curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
  sudo apt-get update
  sudo apt-get install -y nvidia-container-toolkit
  sudo nvidia-ctk runtime configure --runtime=docker
  sudo systemctl restart docker

# Run commands - different for control plane vs workers
run: |
  # Determine node role
  HOSTNAME=$(hostname)
  
  if [[ "$HOSTNAME" == *"production-instance"* ]]; then
    echo "Initializing Kubernetes control plane..."
    
    # Initialize cluster
    sudo kubeadm init \
      --pod-network-cidr=10.244.0.0/16 \
      --service-cidr=10.96.0.0/12 \
      --apiserver-advertise-address=$(hostname -I | awk '{print $1}')
    
    # Configure kubectl
    mkdir -p $HOME/.kube
    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    sudo chown $(id -u):$(id -g) $HOME/.kube/config
    
    # Install Flannel CNI
    kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
    
    # Install NVIDIA GPU Operator
    kubectl create ns gpu-operator
    kubectl label ns gpu-operator pod-security.kubernetes.io/enforce=privileged
    kubectl apply -f https://raw.githubusercontent.com/NVIDIA/gpu-operator/v23.9.1/deployments/gpu-operator.yaml
    
    # Install metrics server
    kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
    
    # Create namespace for Sophia AI
    kubectl create namespace sophia-ai-prod
    
    # Generate join command for workers
    kubeadm token create --print-join-command > /tmp/join-command.sh
    
    # Install Helm
    curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
    
    # Add ingress-nginx
    helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
    helm repo update
    helm install ingress-nginx ingress-nginx/ingress-nginx \
      --namespace ingress-nginx \
      --create-namespace \
      --set controller.service.type=LoadBalancer
    
    # Install cert-manager for SSL
    kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.yaml
    
  else
    echo "Joining worker node to cluster..."
    # Workers will need the join command from control plane
    # This would be handled by SkyPilot's cluster management
  fi

# File mounts for persistent storage
file_mounts:
  # Mount models directory
  /models:
    source: s3://sophia-ai-models/
    mode: MOUNT
    
  # Mount configs
  /configs:
    source: ./configs/
    mode: COPY

# Environment variables
envs:
  ENVIRONMENT: prod
  PULUMI_ORG: scoobyjava-org
  KUBERNETES_VERSION: "1.29.0"

# Resources required
resources:
  cloud: lambda
  accelerators: 
    - gpu_1x_rtx6000
    - gpu_1x_gh200
    - gpu_1x_a6000
    - gpu_1x_a100
    - gpu_1x_a10
  
# Post-setup verification
post_setup: |
  # Verify Kubernetes is running
  kubectl get nodes
  kubectl get pods --all-namespaces
  
  # Verify GPU support
  kubectl get nodes -o json | jq '.items[].status.allocatable."nvidia.com/gpu"' 