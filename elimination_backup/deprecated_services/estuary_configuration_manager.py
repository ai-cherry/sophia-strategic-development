from backend.services.unified_memory_service import UnifiedMemoryService
from datetime import UTC, datetime

#!/usr/bin/env python3
"""
Enhanced Estuary Configuration Manager for Sophia AI Platform

Production-ready Estuary management with comprehensive error handling,
retry logic, data quality validation, and performance monitoring.
Extended to support Asana project management integration.
"""

"""
File Decomposition Plan (auto-generated by Phase 3)
Current size: 867 lines

Recommended decomposition:
- estuary_configuration_manager_core.py - Core functionality
- estuary_configuration_manager_utils.py - Utility functions
- estuary_configuration_manager_models.py - Data models
- estuary_configuration_manager_handlers.py - Request handlers

TODO: Implement file decomposition (Plan created: 2025-07-13)
"""

import asyncio
import random
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any

import aiohttp
import structlog

from core.config_manager import get_config_value
from backend.services.unified_memory_service import UnifiedMemoryService

logger = structlog.get_logger(__name__)


class ErrorType(Enum):
    """Categorized error types for enhanced error handling"""

    NETWORK_ERROR = "network_error"
    AUTHENTICATION_ERROR = "authentication_error"
    CONFIGURATION_ERROR = "configuration_error"
    DATA_QUALITY_ERROR = "data_quality_error"
    RATE_LIMIT_ERROR = "rate_limit_error"
    TIMEOUT_ERROR = "timeout_error"
    VALIDATION_ERROR = "validation_error"
    BUSINESS_LOGIC_ERROR = "business_logic_error"
    INFRASTRUCTURE_ERROR = "infrastructure_error"
    UNKNOWN_ERROR = "unknown_error"


class EstuaryOperationStatus(Enum):
    """Status indicators for Estuary operations"""

    SUCCESS = "success"
    FAILED = "failed"
    RETRY = "retry"
    TIMEOUT = "timeout"
    VALIDATION_FAILED = "validation_failed"
    RATE_LIMITED = "rate_limited"


class SourceType(Enum):
    """Supported source types for Estuary integration"""

    GONG = "gong"
    ASANA = "asana"
    NETSUITE = "netsuite"
    HUBSPOT = "hubspot"
    SLACK = "slack"


@dataclass
class RetryConfig:
    """Configuration for retry mechanisms"""

    max_attempts: int = 3
    base_delay: float = 1.0
    max_delay: float = 60.0
    exponential_base: float = 2.0
    jitter: bool = True


@dataclass
class DataQualityMetrics:
    """Data quality metrics for ingested data"""

    total_records: int = 0
    valid_records: int = 0
    invalid_records: int = 0
    missing_required_fields: int = 0
    data_type_violations: int = 0
    business_rule_violations: int = 0
    quality_score: float = 0.0
    validation_timestamp: datetime | None = None
    issues: list[str] = field(default_factory=list)


@dataclass
class EstuaryOperationResult:
    """Result of an Estuary operation with comprehensive metadata"""

    status: EstuaryOperationStatus
    operation_type: str
    resource_id: str | None = None
    execution_time: float | None = None
    error_type: ErrorType | None = None
    error_message: str | None = None
    retry_count: int = 0
    data_quality: DataQualityMetrics | None = None
    metadata: dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(default_factory=datetime.utcnow)


class EnhancedEstuaryManager:
    """Enhanced Estuary Configuration Manager with production-ready features"""

    def __init__(self, environment: str = "dev"):
        self.environment = environment
        self.session: aiohttp.ClientSession | None = None
        self.cortex_service: QdrantUnifiedMemoryService | None = None

        # Configuration
        self.estuary_config = self._load_estuary_config()
        self.gong_config = self._load_gong_config()
        self.asana_config = self._load_asana_config()


        # Retry configuration
        self.retry_config = RetryConfig()

        # Operation tracking
        self.operation_history: list[EstuaryOperationResult] = []
        self.health_status = {"last_check": None, "status": "unknown"}

        # Estuary Flow connector definitions
        self.connector_definitions = {
            SourceType.GONG: {
                "source_definition_id": "2f2d9b3e-4e3b-4f8a-9b3e-4e3b4f8a9b3e",
                "name": "Gong",
                "documentation_url": "https://docs.estuary.dev/integrations/sources/gong",
            },
            SourceType.ASANA: {
                "source_definition_id": "f1e4c7f0-3b2a-4c5d-8e9f-1a2b3c4d5e6f",
                "name": "Asana",
                "documentation_url": "https://docs.estuary.dev/integrations/sources/asana",
            },
        }

    def _load_estuary_config(self) -> dict[str, Any]:
        """Load Estuary configuration from Pulumi ESC"""
        return {
            "base_url": get_config_value("estuary_server_url", "http://localhost:8000"),
            "username": get_config_value("estuary_username", "estuary"),
            "password": get_config_value("estuary_password", "password"),
            "workspace_id": get_config_value("estuary_workspace_id", "default"),
        }

    def _load_gong_config(self) -> dict[str, Any]:
        """Load Gong configuration from Pulumi ESC"""
        return {
            "access_key": get_config_value("gong_access_key"),
            "access_key_secret": get_config_value("gong_client_secret"),
            "start_date": get_config_value(
                "gong_sync_start_date", "2024-01-01T00:00:00Z"
            ),
            "include_transcripts": get_config_value("gong_include_transcripts", True),
            "call_types": get_config_value("gong_call_types", ["inbound", "outbound"]),
        }

    def _load_asana_config(self) -> dict[str, Any]:
        """Load Asana configuration from Pulumi ESC"""
        return {
            "personal_access_token": get_config_value("asana_api_token"),
            "start_date": get_config_value(
                "asana_sync_start_date", "2024-01-01T00:00:00Z"
            ),
            "include_archived": get_config_value("asana_include_archived", False),
            "workspace_gids": get_config_value("asana_workspace_gids", []),
            "project_gids": get_config_value("asana_project_gids", []),
            "team_gids": get_config_value("asana_team_gids", []),
        }



        return {
            "host": f"{get_config_value('postgres_host')}.qdrantcomputing.com",
            "username": get_config_value("qdrant_user", "SCOOBYJAVA15"),
            "password": get_config_value("postgres_password"),
            "warehouse": get_config_value(
                "postgres_database", "WH_SOPHIA_ETL_TRANSFORM"
            ),
            "database": get_config_value(
                "postgres_database", f"SOPHIA_AI_{self.environment.upper()}"
            ),
            "role": get_config_value("qdrant_role", "ROLE_SOPHIA_ESTUARY_INGEST"),
            "raw_schema": "RAW_ESTUARY",
        }

    async def initialize(self) -> EstuaryOperationResult:
        """Initialize the Estuary manager with enhanced error handling"""
        try:
            timeout = aiohttp.ClientTimeout(total=300, connect=30)
            headers = {
                "Content-Type": "application/json",
                "Accept": "application/json",
                "User-Agent": "Sophia-AI-Estuary-Manager/1.0",
            }

            auth = aiohttp.BasicAuth(
                self.estuary_config["username"], self.estuary_config["password"]
            )

            self.session = aiohttp.ClientSession(
                timeout=timeout, headers=headers, auth=auth
            )

            self.cortex_service = UnifiedMemoryService()
            await self.cortex_service.initialize()

            logger.info("✅ Enhanced Estuary Manager initialized successfully")

            return EstuaryOperationResult(
                status=EstuaryOperationStatus.SUCCESS,
                operation_type="initialization",
                execution_time=0.0,
                metadata={"environment": self.environment},
            )

        except Exception as e:
            logger.exception(f"Failed to initialize Estuary manager: {e}")

            return EstuaryOperationResult(
                status=EstuaryOperationStatus.FAILED,
                operation_type="initialization",
                error_message=str(e),
            )

    async def execute_with_retry(
        self, operation_func, operation_name: str, *args, **kwargs
    ) -> EstuaryOperationResult:
        """Execute operation with comprehensive retry logic and error handling"""
        start_time = time.time()
        last_exception = None

        for attempt in range(self.retry_config.max_attempts):
            try:
                result = await operation_func(*args, **kwargs)
                execution_time = time.time() - start_time

                return EstuaryOperationResult(
                    status=EstuaryOperationStatus.SUCCESS,
                    operation_type=operation_name,
                    execution_time=execution_time,
                    retry_count=attempt,
                    metadata={"result": result},
                )

            except aiohttp.ClientTimeout as e:
                last_exception = e
                error_type = ErrorType.TIMEOUT_ERROR

            except aiohttp.ClientResponseError as e:
                last_exception = e
                if e.status == 429:
                    error_type = ErrorType.RATE_LIMIT_ERROR
                elif e.status in [401, 403]:
                    error_type = ErrorType.AUTHENTICATION_ERROR
                else:
                    error_type = ErrorType.NETWORK_ERROR

            except Exception as e:
                last_exception = e
                error_type = ErrorType.UNKNOWN_ERROR

            if attempt < self.retry_config.max_attempts - 1:
                delay = min(
                    self.retry_config.base_delay
                    * (self.retry_config.exponential_base**attempt),
                    self.retry_config.max_delay,
                )

                if self.retry_config.jitter:
                    delay *= 0.5 + random.random() * 0.5

                logger.warning(
                    f"Attempt {attempt + 1} failed for {operation_name}, retrying in {delay:.2f}s: {last_exception}"
                )
                await asyncio.sleep(delay)

        execution_time = time.time() - start_time

        return EstuaryOperationResult(
            status=EstuaryOperationStatus.FAILED,
            operation_type=operation_name,
            execution_time=execution_time,
            error_type=error_type,
            error_message=str(last_exception),
            retry_count=self.retry_config.max_attempts,
        )

    async def _make_estuary_request(
        self, method: str, endpoint: str, data: dict | None = None
    ) -> dict[str, Any]:
        """Make authenticated request to Estuary Flow API"""
        url = f"{self.estuary_config['base_url']}/api/v1/{endpoint}"

        async with self.session.request(method, url, json=data) as response:
            response.raise_for_status()
            return await response.json()

    # ASANA INTEGRATION METHODS

    async def configure_asana_source(self) -> EstuaryOperationResult:
        """Configure Asana source connector in Estuary"""
        try:
            logger.info("🔄 Configuring Asana source connector")

            source_config = {
                "sourceDefinitionId": self.connector_definitions[SourceType.ASANA][
                    "source_definition_id"
                ],
                "connectionConfiguration": {
                    "personal_access_token": self.asana_config["personal_access_token"],
                    "start_date": self.asana_config["start_date"],
                    "include_archived_projects": self.asana_config["include_archived"],
                    "workspace_gids": self.asana_config["workspace_gids"],
                    "project_gids": self.asana_config["project_gids"],
                    "team_gids": self.asana_config["team_gids"],
                },
                "name": "Asana-PayReady-Source",
                "workspaceId": self.estuary_config["workspace_id"],
            }

            response = await self._make_estuary_request(
                "POST", "sources", source_config
            )
            source_id = response["sourceId"]

            logger.info(f"✅ Asana source configured successfully: {source_id}")

            return EstuaryOperationResult(
                status=EstuaryOperationStatus.SUCCESS,
                operation_type="configure_asana_source",
                resource_id=source_id,
                metadata={"source_config": source_config},
            )

        except Exception as e:
            logger.exception(f"❌ Failed to configure Asana source: {e}")
            return EstuaryOperationResult(
                status=EstuaryOperationStatus.FAILED,
                operation_type="configure_asana_source",
                error_message=str(e),
            )

    async def configure_asana_qdrant_destination(self) -> EstuaryOperationResult:
        """Configure Qdrant destination for Asana data"""
        try:
            logger.info("🔄 Configuring Qdrant destination for Asana")

            destination_config = {
                "destinationDefinitionId": "424892c4-daac-4491-b35d-c6688ba547ba",  # Qdrant destination ID
                "connectionConfiguration": {







                    "jdbc_url_params": "",

                    "loading_method": {"method": "Standard"},
                    "purge_staging_data": True,
                    "upload_threads_count": 6,
                    "batch_size": 50000,
                },
                "name": "Qdrant-Asana-Destination",
                "workspaceId": self.estuary_config["workspace_id"],
            }

            response = await self._make_estuary_request(
                "POST", "destinations", destination_config
            )
            destination_id = response["destinationId"]

            logger.info(

            )

            return EstuaryOperationResult(
                status=EstuaryOperationStatus.SUCCESS,
                operation_type="configure_asana_qdrant_destination",
                resource_id=destination_id,
                metadata={"destination_config": destination_config},
            )

        except Exception as e:
            logger.exception(
                f"❌ Failed to configure Qdrant destination for Asana: {e}"
            )
            return EstuaryOperationResult(
                status=EstuaryOperationStatus.FAILED,
                operation_type="configure_asana_qdrant_destination",
                error_message=str(e),
            )

    async def create_asana_connection(
        self, source_id: str, destination_id: str
    ) -> EstuaryOperationResult:
        """Create connection between Asana source and Qdrant destination"""
        try:
            logger.info("🔄 Creating Asana to Qdrant connection")

            # Define Asana streams to sync
            streams_config = [
                {
                    "stream": {
                        "name": "projects",
                        "json_schema": {},
                        "supported_sync_modes": ["full_refresh", "incremental"],
                    },
                    "config": {
                        "sync_mode": "incremental",
                        "destination_sync_mode": "append_dedup",
                        "cursor_field": ["modified_at"],
                        "primary_key": [["gid"]],
                    },
                },
                {
                    "stream": {
                        "name": "tasks",
                        "json_schema": {},
                        "supported_sync_modes": ["full_refresh", "incremental"],
                    },
                    "config": {
                        "sync_mode": "incremental",
                        "destination_sync_mode": "append_dedup",
                        "cursor_field": ["modified_at"],
                        "primary_key": [["gid"]],
                    },
                },
                {
                    "stream": {
                        "name": "users",
                        "json_schema": {},
                        "supported_sync_modes": ["full_refresh"],
                    },
                    "config": {
                        "sync_mode": "full_refresh",
                        "destination_sync_mode": "overwrite",
                        "primary_key": [["gid"]],
                    },
                },
                {
                    "stream": {
                        "name": "teams",
                        "json_schema": {},
                        "supported_sync_modes": ["full_refresh"],
                    },
                    "config": {
                        "sync_mode": "full_refresh",
                        "destination_sync_mode": "overwrite",
                        "primary_key": [["gid"]],
                    },
                },
                {
                    "stream": {
                        "name": "stories",
                        "json_schema": {},
                        "supported_sync_modes": ["incremental"],
                    },
                    "config": {
                        "sync_mode": "incremental",
                        "destination_sync_mode": "append_dedup",
                        "cursor_field": ["created_at"],
                        "primary_key": [["gid"]],
                    },
                },
                {
                    "stream": {
                        "name": "workspaces",
                        "json_schema": {},
                        "supported_sync_modes": ["full_refresh"],
                    },
                    "config": {
                        "sync_mode": "full_refresh",
                        "destination_sync_mode": "overwrite",
                        "primary_key": [["gid"]],
                    },
                },
            ]

            connection_config = {
                "sourceId": source_id,
                "destinationId": destination_id,
                "syncCatalog": {"streams": streams_config},
                "schedule": {
                    "scheduleType": "cron",
                    "cronExpression": "0 */1 * * *",  # Every hour
                },
                "name": "Asana-to-Qdrant-Connection",
                "namespaceDefinition": "source",
                "namespaceFormat": "${SOURCE_NAMESPACE}",
                "prefix": "asana_",
                "workspaceId": self.estuary_config["workspace_id"],
            }

            response = await self._make_estuary_request(
                "POST", "connections", connection_config
            )
            connection_id = response["connectionId"]

            logger.info(f"✅ Asana connection created successfully: {connection_id}")

            return EstuaryOperationResult(
                status=EstuaryOperationStatus.SUCCESS,
                operation_type="create_asana_connection",
                resource_id=connection_id,
                metadata={
                    "connection_config": connection_config,
                    "source_id": source_id,
                    "destination_id": destination_id,
                },
            )

        except Exception as e:
            logger.exception(f"❌ Failed to create Asana connection: {e}")
            return EstuaryOperationResult(
                status=EstuaryOperationStatus.FAILED,
                operation_type="create_asana_connection",
                error_message=str(e),
            )

    async def setup_complete_asana_pipeline(self) -> dict[str, EstuaryOperationResult]:
        """Set up complete Asana data pipeline end-to-end"""
        try:
            logger.info("🚀 Setting up complete Asana data pipeline")

            results = {}

            # Step 1: Configure Asana source
            source_result = await self.execute_with_retry(
                self.configure_asana_source, "configure_asana_source"
            )
            results["source"] = source_result

            if source_result.status != EstuaryOperationStatus.SUCCESS:
                raise Exception(
                    f"Asana source configuration failed: {source_result.error_message}"
                )

            # Step 2: Configure Qdrant destination
            destination_result = await self.execute_with_retry(
                self.configure_asana_qdrant_destination,
                "configure_asana_qdrant_destination",
            )
            results["destination"] = destination_result

            if destination_result.status != EstuaryOperationStatus.SUCCESS:
                raise Exception(

                )

            # Step 3: Create connection
            connection_result = await self.execute_with_retry(
                self.create_asana_connection,
                "create_asana_connection",
                source_result.resource_id,
                destination_result.resource_id,
            )
            results["connection"] = connection_result

            if connection_result.status != EstuaryOperationStatus.SUCCESS:
                raise Exception(
                    f"Asana connection creation failed: {connection_result.error_message}"
                )

            # Step 4: Trigger initial sync
            sync_result = await self.trigger_asana_sync(connection_result.resource_id)
            results["initial_sync"] = sync_result

            logger.info("✅ Complete Asana pipeline setup completed successfully")

            return results

        except Exception as e:
            logger.exception(f"❌ Complete Asana pipeline setup failed: {e}")
            raise

    async def trigger_asana_sync(self, connection_id: str) -> EstuaryOperationResult:
        """Trigger manual sync for Asana connection"""
        try:
            logger.info(f"🔄 Triggering Asana sync for connection: {connection_id}")

            sync_config = {"connectionId": connection_id}

            response = await self._make_estuary_request(
                "POST", "connections/sync", sync_config
            )
            job_id = response.get("job", {}).get("id")

            logger.info(f"✅ Asana sync triggered successfully: {job_id}")

            return EstuaryOperationResult(
                status=EstuaryOperationStatus.SUCCESS,
                operation_type="trigger_asana_sync",
                resource_id=job_id,
                metadata={"connection_id": connection_id},
            )

        except Exception as e:
            logger.exception(f"❌ Failed to trigger Asana sync: {e}")
            return EstuaryOperationResult(
                status=EstuaryOperationStatus.FAILED,
                operation_type="trigger_asana_sync",
                error_message=str(e),
            )

    async def get_asana_sync_status(self, connection_id: str) -> EstuaryOperationResult:
        """Get sync status for Asana connection"""
        try:
            response = await self._make_estuary_request(
                "GET", f"connections/{connection_id}/status"
            )

            return EstuaryOperationResult(
                status=EstuaryOperationStatus.SUCCESS,
                operation_type="get_asana_sync_status",
                metadata={"sync_status": response},
            )

        except Exception as e:
            logger.exception(f"❌ Failed to get Asana sync status: {e}")
            return EstuaryOperationResult(
                status=EstuaryOperationStatus.FAILED,
                operation_type="get_asana_sync_status",
                error_message=str(e),
            )

    async def validate_asana_data_quality(self) -> DataQualityMetrics:
        """Validate quality of ingested Asana data"""
        try:
            logger.info("🔍 Validating Asana data quality")

            # Query raw Asana data from Qdrant
            quality_queries = {
                "projects": """
                    SELECT
                        COUNT(*) as total_records,
                        COUNT(CASE WHEN _estuary_data:gid IS NOT NULL THEN 1 END) as valid_gids,
                        COUNT(CASE WHEN _estuary_data:name IS NOT NULL THEN 1 END) as valid_names,
                        COUNT(CASE WHEN _estuary_data:modified_at IS NOT NULL THEN 1 END) as valid_timestamps
                    FROM RAW_ESTUARY._ESTUARY_RAW_ASANA_PROJECTS
                """,
                "tasks": """
                    SELECT
                        COUNT(*) as total_records,
                        COUNT(CASE WHEN _estuary_data:gid IS NOT NULL THEN 1 END) as valid_gids,
                        COUNT(CASE WHEN _estuary_data:name IS NOT NULL THEN 1 END) as valid_names,
                        COUNT(CASE WHEN _estuary_data:completed IS NOT NULL THEN 1 END) as valid_status
                    FROM RAW_ESTUARY._ESTUARY_RAW_ASANA_TASKS
                """,
            }

            total_records = 0
            valid_records = 0
            issues = []

            for table, query in quality_queries.items():
                try:
                    result = await self.cortex_service.execute_query(query)
                    if not result.empty:
                        row = result.iloc[0]
                        table_total = row.get("TOTAL_RECORDS", 0)
                        table_valid = min(
                            [
                                row.get(col, 0)
                                for col in row.index
                                if col != "TOTAL_RECORDS"
                            ]
                        )

                        total_records += table_total
                        valid_records += table_valid

                        if table_total > 0:
                            table_quality = (table_valid / table_total) * 100
                            if table_quality < 95:
                                issues.append(
                                    f"{table} data quality below 95%: {table_quality:.1f}%"
                                )

                except Exception as e:
                    issues.append(f"Failed to validate {table}: {e!s}")

            quality_score = (
                (valid_records / total_records * 100) if total_records > 0 else 0
            )

            return DataQualityMetrics(
                total_records=total_records,
                valid_records=valid_records,
                invalid_records=total_records - valid_records,
                quality_score=quality_score,
                validation_timestamp=datetime.now(UTC),
                issues=issues,
            )

        except Exception as e:
            logger.exception(f"❌ Failed to validate Asana data quality: {e}")
            return DataQualityMetrics(
                quality_score=0.0,
                validation_timestamp=datetime.now(UTC),
                issues=[f"Validation failed: {e!s}"],
            )

    async def perform_health_check(self) -> dict[str, Any]:
        """Perform comprehensive health check of Estuary pipelines"""
        try:
            logger.info("🏥 Performing Estuary health check")

            health_status = {
                "timestamp": datetime.now(UTC).isoformat(),
                "overall_status": "healthy",
                "components": {},
                "metrics": {},
            }

            # Check Estuary server connectivity
            try:
                await self._make_estuary_request("GET", "health")
                health_status["components"]["estuary_server"] = "healthy"
            except Exception as e:
                health_status["components"]["estuary_server"] = f"unhealthy: {e!s}"
                health_status["overall_status"] = "degraded"

            # Check Qdrant connectivity
            try:
                await self.cortex_service.execute_query("SELECT 1 as health_check")
                health_status["components"]["qdrant"] = "healthy"
            except Exception as e:
                health_status["components"]["qdrant"] = f"unhealthy: {e!s}"
                health_status["overall_status"] = "degraded"

            # Validate Asana data quality
            asana_quality = await self.validate_asana_data_quality()
            health_status["metrics"]["asana_data_quality"] = {
                "quality_score": asana_quality.quality_score,
                "total_records": asana_quality.total_records,
                "issues": asana_quality.issues,
            }

            if asana_quality.quality_score < 90:
                health_status["overall_status"] = "degraded"

            self.health_status = health_status
            return health_status

        except Exception as e:
            logger.exception(f"❌ Health check failed: {e}")
            return {
                "timestamp": datetime.now(UTC).isoformat(),
                "overall_status": "unhealthy",
                "error": str(e),
            }

    async def cleanup(self) -> None:
        """Clean up resources"""
        if self.session:
            await self.session.close()
        if self.cortex_service:
            await self.cortex_service.close()

    # CLI SUPPORT METHODS

    def get_supported_sources(self) -> list[str]:
        """Get list of supported source types"""
        return [source.value for source in SourceType]

    async def setup_source_pipeline(
        self, source_type: str
    ) -> dict[str, EstuaryOperationResult]:
        """Generic method to setup pipeline for any supported source"""
        source_enum = SourceType(source_type.lower())

        if source_enum == SourceType.ASANA:
            return await self.setup_complete_asana_pipeline()
        elif source_enum == SourceType.GONG:
            # Would call setup_complete_gong_pipeline() if implemented
            raise NotImplementedError("Gong pipeline setup not yet implemented")
        else:
            raise ValueError(f"Unsupported source type: {source_type}")

    async def test_source_connection(self, source_type: str) -> EstuaryOperationResult:
        """Test connection for specified source type"""
        source_enum = SourceType(source_type.lower())

        if source_enum == SourceType.ASANA:
            # Test Asana API connectivity
            try:
                import aiohttp

                async with aiohttp.ClientSession() as session:
                    headers = {
                        "Authorization": f"Bearer {self.asana_config['personal_access_token']}"
                    }
                    async with session.get(
                        "https://app.asana.com/api/1.0/users/me", headers=headers
                    ) as response:
                        if response.status == 200:
                            return EstuaryOperationResult(
                                status=EstuaryOperationStatus.SUCCESS,
                                operation_type="test_asana_connection",
                            )
                        else:
                            return EstuaryOperationResult(
                                status=EstuaryOperationStatus.FAILED,
                                operation_type="test_asana_connection",
                                error_message=f"Asana API returned status {response.status}",
                            )
            except Exception as e:
                return EstuaryOperationResult(
                    status=EstuaryOperationStatus.FAILED,
                    operation_type="test_asana_connection",
                    error_message=str(e),
                )
        else:
            raise ValueError(f"Unsupported source type: {source_type}")


# CLI Interface
async def main():
    """CLI interface for Estuary configuration management"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Enhanced Estuary Configuration Manager"
    )
    parser.add_argument(
        "--environment", default="dev", choices=["dev", "staging", "prod"]
    )
    parser.add_argument(
        "--source", choices=["gong", "asana"], help="Source to configure"
    )
    parser.add_argument(
        "--action", choices=["setup", "test", "sync", "status", "health"], required=True
    )

    args = parser.parse_args()

    manager = EnhancedEstuaryManager(args.environment)

    try:
        await manager.initialize()

        if args.action == "setup" and args.source:
            await manager.setup_source_pipeline(args.source)

        elif args.action == "test" and args.source:
            await manager.test_source_connection(args.source)

        elif args.action == "health":
            await manager.perform_health_check()

        else:
            pass

    except Exception:
        pass
    finally:
        await manager.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
