{
  "comment": "Enhanced MCP server port assignments for CLI/SDK integration enhancements",
  "version": "2.0",
  "last_updated": "2024-12-19",
  "port_ranges": {
    "core_services": "9000-9014",
    "enhancement_servers": "9015-9019",
    "business_intelligence": "9100-9199", 
    "data_integrations": "9200-9299",
    "development_tools": "9300-9399",
    "future_expansion": "9020-9099"
  },
  "servers": {
    "comment_existing": "=== EXISTING CORE SERVERS (9000-9014) ===",
    "ai_memory": 9000,
    "figma": 9001,
    "ui_ux_agent": 9002,
    "codacy": 9003,
    "asana": 9004,
    "notion": 9005,
    "linear": 9006,
    "github": 9007,
    "slack": 9008,
    "postgres": 9009,
    "sophia_data": 9010,
    "sophia_infrastructure": 9011,
    "snowflake_admin": 9012,
    "portkey_admin_official": 9013,
    "openrouter_search_official": 9014,
    
    "comment_enhancements": "=== CLI/SDK ENHANCEMENT SERVERS (9015-9019) ===",
    "apify_intelligence": {
      "port": 9015,
      "description": "Competitive intelligence and web scraping using Apify CLI/SDK",
      "capabilities": ["competitive_analysis", "pricing_intelligence", "market_research", "social_listening", "news_monitoring"],
      "priority": "high",
      "implementation_phase": "phase_1",
      "business_value": "80% faster competitive analysis"
    },
    "huggingface_ai": {
      "port": 9016,
      "description": "Advanced ML model management using Hugging Face CLI/SDK",
      "capabilities": ["text_generation", "embeddings", "summarization", "sentiment_analysis", "question_answering"],
      "priority": "high", 
      "implementation_phase": "phase_1",
      "business_value": "70% more AI model options"
    },
    "weaviate_primary": {
      "port": 9017,
      "description": "Vector database redundancy using Weaviate CLI",
      "capabilities": ["vector_storage", "semantic_search", "backup_vectors", "advanced_filtering"],
      "priority": "medium",
      "implementation_phase": "phase_2",
      "business_value": "99.9% vector search uptime"
    },
    "arize_phoenix": {
      "port": 9018,
      "description": "AI observability and monitoring using Arize Phoenix CLI",
      "capabilities": ["ai_monitoring", "performance_tracking", "model_debugging", "observability"],
      "priority": "medium",
      "implementation_phase": "phase_2", 
      "business_value": "50% faster issue detection"
    },
    "n8n_workflow_cli": {
      "port": 9019,
      "description": "Enhanced N8N workflow management using N8N CLI",
      "capabilities": ["workflow_export", "workflow_import", "credential_management", "monitoring"],
      "priority": "high",
      "implementation_phase": "phase_1",
      "business_value": "60% faster workflow development"
    },
    
    "comment_business": "=== BUSINESS INTELLIGENCE SERVERS (9100-9199) ===",
    "gong": 9100,
    "hubspot": 9101,
    
    "comment_data": "=== DATA INTEGRATION SERVERS (9200-9299) ===", 
    "apollo_io": 9200,
    "estuary": 9201,
    
    "comment_development": "=== DEVELOPMENT TOOLS (9300-9399) ===",
    "docker": 9300,
    "pulumi": 9301
  },
  "universal_chat_integration": {
    "description": "Enhanced universal chat routing for CLI/SDK servers",
    "mode_mappings": {
      "universal": {
        "servers": ["ai_memory", "huggingface_ai", "basic_search"],
        "capabilities": ["general_knowledge", "ml_inference", "text_processing"]
      },
      "sophia": {
        "servers": ["ai_memory", "apify_intelligence", "huggingface_ai", "weaviate_primary"],
        "capabilities": ["competitive_intelligence", "advanced_ml", "market_research", "redundant_search"]
      },
      "executive": {
        "servers": ["portkey_admin_official", "apify_intelligence", "weaviate_primary", "arize_phoenix"],
        "capabilities": ["cost_optimization", "strategic_intelligence", "performance_monitoring", "business_insights"]
      }
    }
  },
  "data_flow_integration": {
    "description": "Enhanced data flow with new vector and AI services",
    "primary_vector": "ai_memory -> pinecone",
    "backup_vector": "weaviate_primary",
    "ai_enhancement": "huggingface_ai",
    "business_intelligence": "apify_intelligence",
    "monitoring": "arize_phoenix",
    "workflow_automation": "n8n_workflow_cli"
  },
  "deployment_requirements": {
    "phase_1_servers": ["apify_intelligence", "huggingface_ai", "n8n_workflow_cli"],
    "phase_2_servers": ["weaviate_primary", "arize_phoenix"],
    "dependencies": {
      "apify_intelligence": ["ai_memory"],
      "huggingface_ai": ["ai_memory", "snowflake_cortex"],
      "weaviate_primary": ["ai_memory", "pinecone"],
      "arize_phoenix": ["existing_monitoring"],
      "n8n_workflow_cli": ["n8n_instance"]
    },
    "environment_variables": {
      "apify_intelligence": ["APIFY_API_TOKEN"],
      "huggingface_ai": ["HF_TOKEN"],
      "weaviate_primary": ["WEAVIATE_URL", "WEAVIATE_API_KEY"],
      "arize_phoenix": ["PHOENIX_API_KEY"],
      "n8n_workflow_cli": ["N8N_URL", "N8N_USER", "N8N_PASSWORD"]
    }
  },
  "success_metrics": {
    "phase_1_targets": {
      "competitive_analysis_speed": "80% improvement",
      "ai_model_availability": "70% increase",
      "workflow_development": "60% faster"
    },
    "phase_2_targets": {
      "vector_search_uptime": "99.9%",
      "issue_detection_speed": "50% faster",
      "overall_system_reliability": "95%+"
    }
  },
  "mcp_orchestration_integration": {
    "description": "Integration with existing MCP orchestration service",
    "orchestration_port": 9000,
    "health_check_interval": 30,
    "auto_restart": true,
    "priority_routing": {
      "high": ["apify_intelligence", "huggingface_ai", "n8n_workflow_cli"],
      "medium": ["weaviate_primary", "arize_phoenix"],
      "low": ["development_tools"]
    }
  }
} 