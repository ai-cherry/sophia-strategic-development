{
  "version": "6.0-gpu",
  "description": "GPU-Accelerated MCP Configuration with Weaviate/Redis/PostgreSQL",
  "last_updated": "2025-07-12T16:00:00.000Z",
  "lambda_labs": {
    "host": "192.222.58.232",
    "gpu_inference_endpoint": "http://lambda-inference-service:8080",
    "docker_swarm": true,
    "health_check_interval": 30
  },
  "memory_stack": {
    "weaviate": {
      "endpoint": "${WEAVIATE_URL}",
      "default": "http://weaviate-service:8080"
    },
    "redis": {
      "endpoint": "${REDIS_URL}",
      "default": "redis://redis-service:6379"
    },
    "postgresql": {
      "endpoint": "${POSTGRESQL_URL}",
      "default": "postgresql://postgresql-service:5432/sophia_vectors"
    },
    "lambda_inference": {
      "endpoint": "${LAMBDA_INFERENCE_URL}",
      "default": "http://lambda-inference-service:8080"
    }
  },
  "mcpServers": {
    "ai_memory": {
      "command": "python3",
      "args": [
        "mcp-servers/ai_memory/server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PULUMI_ORG": "scoobyjava-org",
        "LAMBDA_LABS_HOST": "192.222.58.232",
        "WEAVIATE_URL": "${WEAVIATE_URL}",
        "REDIS_URL": "${REDIS_URL}",
        "POSTGRESQL_URL": "${POSTGRESQL_URL}",
        "LAMBDA_INFERENCE_URL": "${LAMBDA_INFERENCE_URL}"
      },
      "port": 9000,
      "cwd": ".",
      "capabilities": [
        "memory_storage",
        "memory_recall",
        "semantic_search",
        "gpu_embeddings",
        "hybrid_search"
      ],
      "health_endpoint": "/health",
      "performance": {
        "max_concurrent_requests": 20,
        "request_timeout_seconds": 30,
        "cache_ttl_seconds": 300,
        "enable_request_batching": true,
        "gpu_acceleration": true
      },
      "monitoring": {
        "enable_metrics": true,
        "metrics_port": 10000,
        "health_check_interval": 30,
        "log_level": "INFO",
        "latency_target_ms": 50
      }
    },
    "gong": {
      "command": "python3",
      "args": [
        "mcp-servers/gong/server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9101",
        "LAMBDA_LABS_HOST": "192.222.58.232",
        "WEAVIATE_URL": "${WEAVIATE_URL}",
        "REDIS_URL": "${REDIS_URL}",
        "LAMBDA_INFERENCE_URL": "${LAMBDA_INFERENCE_URL}"
      },
      "port": 9101,
      "cwd": ".",
      "capabilities": [
        "call_analytics",
        "transcript_storage",
        "insight_generation",
        "memory_integration"
      ],
      "health_endpoint": "/health",
      "performance": {
        "max_concurrent_requests": 10,
        "request_timeout_seconds": 30,
        "gpu_acceleration": true
      }
    },
    "hubspot_unified": {
      "command": "python3",
      "args": [
        "mcp-servers/hubspot_unified/server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9103",
        "LAMBDA_LABS_HOST": "192.222.58.232",
        "WEAVIATE_URL": "${WEAVIATE_URL}",
        "REDIS_URL": "${REDIS_URL}",
        "LAMBDA_INFERENCE_URL": "${LAMBDA_INFERENCE_URL}"
      },
      "port": 9103,
      "cwd": ".",
      "capabilities": [
        "crm_integration",
        "contact_management",
        "deal_tracking",
        "memory_integration"
      ],
      "health_endpoint": "/health"
    },
    "slack": {
      "command": "python3",
      "args": [
        "mcp-servers/slack/server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9008",
        "LAMBDA_LABS_HOST": "192.222.58.232",
        "WEAVIATE_URL": "${WEAVIATE_URL}",
        "REDIS_URL": "${REDIS_URL}",
        "LAMBDA_INFERENCE_URL": "${LAMBDA_INFERENCE_URL}"
      },
      "port": 9008,
      "cwd": ".",
      "capabilities": [
        "message_search",
        "channel_management",
        "real_time_updates",
        "memory_integration"
      ],
      "health_endpoint": "/health"
    },
    "snowflake_admin": {
      "command": "python3",
      "args": [
        "backend/mcp_servers/snowflake_admin_mcp_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PULUMI_ORG": "scoobyjava-org",
        "PORT": "9020",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9020,
      "health_endpoint": "/health",
      "capabilities": [
        "schema_sync",
        "query_execution",
        "legacy_support"
      ],
      "performance": {
        "max_concurrent_requests": 5,
        "request_timeout_seconds": 60
      }
    },
    "codacy": {
      "command": "python3",
      "args": [
        "mcp-servers/codacy/production_codacy_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "3008",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 3008,
      "cwd": ".",
      "capabilities": [
        "code_analysis",
        "security_scan",
        "quality_metrics"
      ],
      "health_endpoint": "/health",
      "performance": {
        "max_concurrent_requests": 10,
        "request_timeout_seconds": 30,
        "cache_ttl_seconds": 300,
        "enable_request_batching": true
      },
      "monitoring": {
        "enable_metrics": true,
        "metrics_port": 4008,
        "health_check_interval": 30,
        "log_level": "INFO"
      }
    },
    "linear": {
      "command": "python3",
      "args": [
        "mcp-servers/linear/linear_mcp_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9006",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9006,
      "cwd": ".",
      "capabilities": [
        "project_management",
        "issue_tracking",
        "team_analytics"
      ],
      "health_endpoint": "/health"
    },
    "github": {
      "command": "python3",
      "args": [
        "mcp-servers/github/github_mcp_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9007",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9007,
      "cwd": ".",
      "capabilities": [
        "repository_management",
        "issue_tracking",
        "code_review"
      ],
      "health_endpoint": "/health"
    },
    "asana": {
      "command": "python3",
      "args": [
        "mcp-servers/asana/asana_mcp_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9004",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9004,
      "cwd": ".",
      "capabilities": [
        "task_management",
        "project_tracking",
        "team_collaboration"
      ],
      "health_endpoint": "/health"
    },
    "notion": {
      "command": "python3",
      "args": [
        "mcp-servers/notion/enhanced_notion_mcp_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9005",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9005,
      "cwd": ".",
      "capabilities": [
        "documentation",
        "knowledge_base",
        "wiki_management"
      ],
      "health_endpoint": "/health"
    },
    "ui_ux_agent": {
      "command": "python3",
      "args": [
        "mcp-servers/ui_ux_agent/ui_ux_agent_mcp_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9002",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9002,
      "cwd": ".",
      "capabilities": [
        "ui_generation",
        "design_analysis",
        "component_creation"
      ],
      "health_endpoint": "/health",
      "performance": {
        "max_concurrent_requests": 10,
        "request_timeout_seconds": 30,
        "cache_ttl_seconds": 300,
        "enable_request_batching": true
      },
      "monitoring": {
        "enable_metrics": true,
        "metrics_port": 10002,
        "health_check_interval": 30,
        "log_level": "INFO"
      }
    },
    "portkey_admin": {
      "command": "python3",
      "args": [
        "mcp-servers/portkey_admin/portkey_admin_mcp_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9013",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9013,
      "cwd": ".",
      "capabilities": [
        "ai_routing",
        "cost_optimization",
        "model_selection"
      ],
      "health_endpoint": "/health",
      "performance": {
        "max_concurrent_requests": 10,
        "request_timeout_seconds": 30,
        "cache_ttl_seconds": 300,
        "enable_request_batching": true
      },
      "monitoring": {
        "enable_metrics": true,
        "metrics_port": 10013,
        "health_check_interval": 30,
        "log_level": "INFO"
      }
    },
    "lambda_labs_cli": {
      "command": "python3",
      "args": [
        "mcp-servers/lambda_labs_cli/lambda_labs_cli_mcp_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9020",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9020,
      "cwd": ".",
      "capabilities": [
        "instance_management",
        "gpu_monitoring",
        "cost_tracking"
      ],
      "health_endpoint": "/health",
      "performance": {
        "max_concurrent_requests": 10,
        "request_timeout_seconds": 30,
        "cache_ttl_seconds": 300,
        "enable_request_batching": true
      },
      "monitoring": {
        "enable_metrics": true,
        "metrics_port": 10020,
        "health_check_interval": 30,
        "log_level": "INFO"
      }
    },
    "snowflake_cortex": {
      "command": "python3",
      "args": [
        "mcp-servers/snowflake_cortex/production_snowflake_cortex_mcp_server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9201",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9201,
      "cwd": ".",
      "capabilities": [
        "cortex_ai",
        "legacy_embeddings",
        "migration_support"
      ],
      "health_endpoint": "/health",
      "performance": {
        "max_concurrent_requests": 5,
        "request_timeout_seconds": 60
      }
    },
    "figma": {
      "command": "python3",
      "args": [
        "mcp-servers/figma/server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9001",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9001,
      "cwd": ".",
      "capabilities": [
        "design_analysis",
        "component_extraction",
        "style_management"
      ],
      "health_endpoint": "/health"
    },
    "postgres": {
      "command": "python3",
      "args": [
        "mcp-servers/postgres/server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9009",
        "LAMBDA_LABS_HOST": "192.222.58.232",
        "POSTGRESQL_URL": "${POSTGRESQL_URL}"
      },
      "port": 9009,
      "cwd": ".",
      "capabilities": [
        "sql_queries",
        "schema_management",
        "vector_operations"
      ],
      "health_endpoint": "/health"
    },
    "openrouter_search": {
      "command": "python3",
      "args": [
        "mcp-servers/openrouter_search/server.py"
      ],
      "env": {
        "ENVIRONMENT": "prod",
        "PORT": "9014",
        "LAMBDA_LABS_HOST": "192.222.58.232"
      },
      "port": 9014,
      "cwd": ".",
      "capabilities": [
        "model_search",
        "pricing_info",
        "availability_check"
      ],
      "health_endpoint": "/health"
    }
  },
  "orchestration": {
    "startup_order": [
      "ai_memory",
      "postgres",
      "gong",
      "hubspot_unified",
      "slack",
      "codacy",
      "linear",
      "github",
      "asana",
      "notion",
      "ui_ux_agent",
      "portkey_admin",
      "lambda_labs_cli",
      "figma",
      "openrouter_search",
      "snowflake_admin",
      "snowflake_cortex"
    ],
    "health_check_timeout": 30,
    "retry_attempts": 3,
    "retry_delay": 5,
    "gpu_priority_servers": [
      "ai_memory",
      "gong"
    ]
  },
  "capabilities_map": {
    "data_analysis": ["ai_memory", "postgres", "gong"],
    "memory_operations": ["ai_memory"],
    "embeddings": ["ai_memory"],
    "crm": ["gong", "hubspot_unified"],
    "project_management": ["linear", "asana", "notion"],
    "code_analysis": ["codacy", "github"],
    "communication": ["slack"],
    "infrastructure": ["lambda_labs_cli"],
    "ai_routing": ["portkey_admin"],
    "design": ["figma", "ui_ux_agent"]
  },
  "monitoring": {
    "prometheus_endpoint": "http://192.222.58.232:9090",
    "grafana_endpoint": "http://192.222.58.232:3000",
    "alert_webhook": "https://hooks.slack.com/services/sophia-ai-alerts",
    "latency_alerts": {
      "ai_memory": 50,
      "gong": 150,
      "default": 200
    }
  },
  "migration": {
    "status": "completed",
    "from": "snowflake_unified",
    "to": "gpu_accelerated_stack",
    "deprecated_servers": ["snowflake_unified"],
    "legacy_support": ["snowflake_admin", "snowflake_cortex"]
  }
}
