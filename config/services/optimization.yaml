# Sophia AI Service Optimization Configuration
# Centralized configuration for all integrated services

# AI Services Configuration
ai_services:
  arize:
    optimization_level: standard
    performance_targets:
      response_time_ms: 500
      uptime_percentage: 99.9
    cost_targets:
      monthly_budget_usd: 500
      cost_per_prediction: 0.001
    monitoring:
      enabled: true
      interval: 60
      metrics:
        - prediction_accuracy
        - drift_detection
        - performance_degradation
    features:
      - model_monitoring
      - drift_detection
      - performance_tracking

  openrouter:
    optimization_level: aggressive
    performance_targets:
      response_time_ms: 1000
      uptime_percentage: 99.5
    cost_targets:
      monthly_budget_usd: 1000
      cost_per_request: 0.01
    routing_strategy:
      primary_models:
        - gpt-4-turbo
        - claude-3-opus
      fallback_models:
        - gpt-3.5-turbo
        - claude-3-haiku
    features:
      - model_routing
      - cost_optimization
      - unified_api

  portkey:
    optimization_level: aggressive
    performance_targets:
      response_time_ms: 800
      cache_hit_rate: 0.6
    cost_targets:
      monthly_budget_usd: 800
      cache_savings_target: 0.4
    caching:
      semantic_threshold: 0.92
      ttl_hours: 12
      max_cache_size_gb: 10
    features:
      - smart_routing
      - semantic_caching
      - observability
      - load_balancing

# Data Services Configuration
data_services:
  snowflake:
    optimization_level: standard
    performance_targets:
      query_time_ms: 100
      concurrent_queries: 50
    cost_targets:
      monthly_budget_usd: 2000
      compute_credits: 1000
    connection_pool:
      min_connections: 5
      max_connections: 20
      timeout_seconds: 30

  pinecone:
    optimization_level: aggressive
    performance_targets:
      query_time_ms: 50
      index_size_limit_gb: 100
    cost_targets:
      monthly_budget_usd: 500
      queries_per_month: 1000000
    index_config:
      dimension: 1536
      metric: cosine
      pods: 1
      replicas: 1

  apify:
    optimization_level: moderate
    performance_targets:
      scraping_concurrency: 10
      success_rate: 0.95
    cost_targets:
      monthly_budget_usd: 300
      actor_compute_units: 1000
    rate_limiting:
      requests_per_minute: 60
      retry_attempts: 3
      backoff_multiplier: 2

# Infrastructure Services Configuration
infrastructure_services:
  lambda_labs:
    optimization_level: moderate
    performance_targets:
      gpu_utilization: 0.8
      uptime_percentage: 99.5
    cost_targets:
      monthly_budget_usd: 3000
      hourly_rate_limit: 10
    auto_scaling:
      enabled: true
      min_instances: 1
      max_instances: 5
      scale_up_threshold: 0.8
      scale_down_threshold: 0.2

  docker:
    optimization_level: standard
    performance_targets:
      container_startup_time_s: 30
      memory_limit_gb: 4
    registry:
      cleanup_policy: 30d
      max_image_size_gb: 5

  pulumi:
    optimization_level: standard
    deployment:
      parallel_operations: 10
      preview_before_deploy: true
      auto_rollback: true
    state_management:
      backend: s3
      encryption: true
      versioning: true

# Business Services Configuration
business_services:
  gong:
    optimization_level: moderate
    performance_targets:
      call_processing_time_m: 5
      insight_generation_time_m: 10
    cost_targets:
      monthly_budget_usd: 1000
      calls_per_month: 10000
    data_retention:
      call_recordings_days: 90
      transcripts_days: 365
      insights_days: 365

  slack:
    optimization_level: standard
    performance_targets:
      message_delivery_time_ms: 100
      webhook_response_time_ms: 3000
    rate_limits:
      messages_per_minute: 60
      api_calls_per_minute: 100

# Global Optimization Settings
global_settings:
  cost_optimization:
    total_monthly_budget_usd: 10000
    alert_threshold_percentage: 80
    cost_allocation:
      ai_services: 0.4
      data_services: 0.3
      infrastructure: 0.2
      business_services: 0.1

  performance_optimization:
    global_sla_uptime: 99.5
    global_response_time_p95_ms: 2000
    error_rate_threshold: 0.001

  caching_strategy:
    global_cache_enabled: true
    cache_providers:
      - redis
      - portkey
    cache_invalidation_strategy: ttl_based

  monitoring:
    providers:
      - arize
      - prometheus
      - grafana
    alert_channels:
      - slack
      - email
    metrics_retention_days: 90

# Service Routing Rules - Enhanced Portkey + OpenRouter Architecture
routing_rules:
  llm_gateway:
    # Primary: Portkey Gateway with OpenRouter backend
    primary: "portkey"
    portkey_endpoint: "https://api.portkey.ai/v1/chat/completions"
    portkey_api_key_env: "PORTKEY_API_KEY"
    
    # OpenRouter as backend provider through Portkey
    backend_provider: "openrouter"
    openrouter_api_key_env: "OPENROUTER_API_KEY"
    
    # Intelligent routing configuration
    routing_strategy:
      # Performance-optimized model selection
      performance_tier_1:
        models: ["gpt-4o", "claude-3-opus", "gemini-1.5-pro"]
        use_case: ["complex_reasoning", "executive_insights", "strategic_analysis"]
        cost_multiplier: 1.0
        
      performance_tier_2: 
        models: ["claude-3-haiku", "gpt-4-turbo", "deepseek-v3"]
        use_case: ["code_generation", "document_analysis", "routine_queries"]
        cost_multiplier: 0.6
        
      cost_optimized:
        models: ["llama-3-70b", "qwen2-72b", "mixtral-8x22b"]
        use_case: ["bulk_processing", "training_data", "cost_sensitive"]
        cost_multiplier: 0.2
    
    # Portkey-specific configurations
    portkey_config:
      # Semantic caching for cost optimization
      semantic_caching:
        enabled: true
        similarity_threshold: 0.92
        ttl_hours: 24
        cache_size_gb: 50
        
      # Smart routing and load balancing
      load_balancing:
        strategy: "weighted_round_robin"
        health_check_interval: 30
        fallback_enabled: true
        
      # Cost and performance monitoring
      monitoring:
        track_costs: true
        track_latency: true
        track_token_usage: true
        alert_thresholds:
          cost_spike_percentage: 50
          latency_spike_ms: 2000
          error_rate_percentage: 5
    
    # Model selection rules with business context
    model_selection:
      - condition: "dashboard_type == 'ceo' AND task_type == 'executive_summary'"
        model: "gpt-4o"
        provider: "openrouter"
        cache_ttl: 3600
        priority: "high"
        
      - condition: "dashboard_type == 'ceo' AND task_type == 'competitive_analysis'"
        model: "claude-3-opus"
        provider: "openrouter" 
        cache_ttl: 7200
        priority: "high"
        
      - condition: "task_type == 'code_generation' OR task_type == 'technical_analysis'"
        model: "deepseek-v3"
        provider: "openrouter"
        cache_ttl: 1800
        priority: "medium"
        
      - condition: "task_type == 'long_context' OR prompt_tokens > 16000"
        model: "gemini-1.5-pro"
        provider: "openrouter"
        cache_ttl: 3600
        priority: "medium"
        
      - condition: "task_type == 'chat' OR task_type == 'general'"
        model: "gpt-4o"
        provider: "openrouter"
        cache_ttl: 900
        priority: "medium"
        
      - condition: "cost_sensitive == true OR budget_constraint == true"
        model: "llama-3-70b"
        provider: "openrouter"
        cache_ttl: 7200
        priority: "low"
        
      - condition: "task_type == 'multi_modal' OR has_images == true"
        model: "gpt-4o"
        provider: "openrouter"
        cache_ttl: 1800
        priority: "high"
        
      - condition: "task_type == 'summarization' AND content_length < 10000"
        model: "claude-3-haiku"
        provider: "openrouter"
        cache_ttl: 3600
        priority: "medium"
    
    # Fallback strategy
    fallback_strategy:
      primary_fallback: "openrouter_direct"
      secondary_fallback: "openai_direct"
      fallback_endpoints:
        openrouter_direct:
          endpoint: "https://openrouter.ai/api/v1/chat/completions"
          api_key_env: "OPENROUTER_API_KEY"
        openai_direct:
          endpoint: "https://api.openai.com/v1/chat/completions"
          api_key_env: "OPENAI_API_KEY"
        anthropic_direct:
          endpoint: "https://api.anthropic.com/v1/messages"
          api_key_env: "ANTHROPIC_API_KEY"
    
    # Unified Dashboard specific configurations
    ceo_dashboard_config:
      # Model performance tracking
      performance_metrics:
        - response_quality_score
        - business_relevance_score
        - cost_efficiency_ratio
        - user_satisfaction_rating
        
      # Strategic model assignments
      strategic_model_assignments:
        executive_insights: "gpt-4o"
        competitive_intelligence: "claude-3-opus"
        financial_analysis: "gpt-4o"
        market_analysis: "gemini-1.5-pro"
        operational_efficiency: "claude-3-haiku"
        
      # Cost management
      cost_controls:
        monthly_budget_usd: 2000
        alert_at_percentage: 75
        auto_downgrade_at_percentage: 90
        emergency_fallback_model: "llama-3-70b"
        
      # A/B testing for model optimization
      ab_testing:
        enabled: true
        test_percentage: 10
        metrics_tracked: ["quality", "cost", "latency"]
        test_duration_days: 7

# Data Source Selection
data_source_selection:
  - condition: "data_type == 'structured' AND size < '1GB'"
    source: "snowflake"
    query_engine: "standard"

  - condition: "data_type == 'embeddings'"
    source: "pinecone"
    index: "sophia-main"

  - condition: "data_type == 'web_content'"
    source: "apify"
    scraper: "universal"

# Feature Flags
feature_flags:
  enable_semantic_caching: true
  enable_auto_scaling: true
  enable_cost_alerts: true
  enable_performance_monitoring: true
  enable_security_scanning: true
  enable_automated_optimization: false
  enable_predictive_scaling: false
  enable_multi_region: false

# Version
version: "1.0.0"
last_updated: "2025-01-21"
