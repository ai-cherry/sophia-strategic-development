#!/usr/bin/env python3
"""
from backend.core.auto_esc_config import get_config_value
Estuary Flow Manager for Sophia AI Platform
Comprehensive integration replacing Estuary with Estuary Flow
"""

"""
File Decomposition Plan (auto-generated by Phase 3)
Current size: 802 lines

Recommended decomposition:
- estuary_flow_manager_core.py - Core functionality
- estuary_flow_manager_utils.py - Utility functions
- estuary_flow_manager_models.py - Data models
- estuary_flow_manager_handlers.py - Request handlers

"""

import json
import logging
import os
import subprocess
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any

import yaml

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

class EstuaryConnectorType(Enum):
    """Supported Estuary connector types"""

    GITHUB = "ghcr.io/estuary/source-github:dev"
    HUBSPOT = "ghcr.io/estuary/source-hubspot:dev"
    SLACK = "ghcr.io/estuary/source-slack:dev"
    qdrant = "ghcr.io/estuary/materialize-qdrant:dev"
    PINECONE = "ghcr.io/estuary/materialize-pinecone:dev"
    HTTP_INBOUND = "ghcr.io/estuary/source-http-inbound:dev"
    WEBHOOK = "ghcr.io/estuary/source-webhook:dev"

@dataclass
class EstuaryCredentials:
    """Estuary authentication credentials"""

    access_token: str
    refresh_token: str
    tenant: str = "Pay_Ready"

    @classmethod
    def from_pulumi_esc(cls) -> "EstuaryCredentials":
        """Load credentials from Pulumi ESC secrets"""
        try:
            # Use Pulumi ESC to get secrets
            result = subprocess.run(
                [
                    "pulumi",
                    "config",
                    "get",
                    "estuary:access_token",
                    "--stack",
                    "sophia-ai-prod",
                ],
                check=False,
                capture_output=True,
                text=True,
            )

            if result.returncode != 0:
                # Fallback to environment variables
                access_token = get_config_value("estuary_access_token")
                refresh_token = get_config_value("estuary_refresh_token")

                if not access_token or not refresh_token:
                    raise ValueError(
                        "Estuary credentials not found in Pulumi ESC or environment"
                    )

                return cls(access_token=access_token, refresh_token=refresh_token)

            access_token = result.stdout.strip()

            # Get refresh token
            result = subprocess.run(
                [
                    "pulumi",
                    "config",
                    "get",
                    "estuary:refresh_token",
                    "--stack",
                    "sophia-ai-prod",
                ],
                check=False,
                capture_output=True,
                text=True,
            )

            refresh_token = (
                result.stdout.strip()
                if result.returncode == 0
                else get_config_value("estuary_refresh_token")
            )

            # Ensure refresh_token is not None
            if not refresh_token:
                raise ValueError("Refresh token is required but not found")

            # Ensure refresh_token is str (not None) to satisfy type checker
            assert refresh_token is not None, "Refresh token must not be None"
            refresh_token_str: str = refresh_token

            return cls(access_token=access_token, refresh_token=refresh_token_str)

        except Exception as e:
            logger.exception(f"Failed to load Estuary credentials: {e}")
            raise

@dataclass
class EstuaryCapture:
    """Estuary capture configuration"""

    name: str
    connector_image: str
    config: dict[str, Any]
    bindings: list[dict[str, Any]]
    tenant: str = "Pay_Ready"

    def to_flow_yaml(self) -> dict[str, Any]:
        """Convert to Flow YAML format"""
        return {
            "captures": {
                f"{self.tenant}/{self.name}": {
                    "endpoint": {
                        "connector": {
                            "image": self.connector_image,
                            "config": self.config,
                        }
                    },
                    "bindings": self.bindings,
                }
            }
        }

@dataclass
class EstuaryMaterialization:
    """Estuary materialization configuration"""

    name: str
    connector_image: str
    config: dict[str, Any]
    bindings: list[dict[str, Any]]
    tenant: str = "Pay_Ready"

    def to_flow_yaml(self) -> dict[str, Any]:
        """Convert to Flow YAML format"""
        return {
            "materializations": {
                f"{self.tenant}/{self.name}": {
                    "endpoint": {
                        "connector": {
                            "image": self.connector_image,
                            "config": self.config,
                        }
                    },
                    "bindings": self.bindings,
                }
            }
        }

class EstuaryFlowManager:
    """Comprehensive Estuary Flow management for Sophia AI"""

    def __init__(self, credentials: EstuaryCredentials | None = None):
        self.credentials = credentials or EstuaryCredentials.from_pulumi_esc()
        self.flowctl_path = self._ensure_flowctl_installed()
        self.project_root = Path(__file__).parent.parent.parent
        self.config_dir = self.project_root / "config" / "estuary"
        self.config_dir.mkdir(parents=True, exist_ok=True)

        # Initialize flowctl authentication
        self._authenticate_flowctl()

    def _ensure_flowctl_installed(self) -> str:
        """Ensure flowctl CLI is installed and available"""
        try:
            # Check if flowctl is already available
            result = subprocess.run(
                ["which", "flowctl"], check=False, capture_output=True, text=True
            )
            if result.returncode == 0:
                logger.info(f"âœ… flowctl found at: {result.stdout.strip()}")
                return result.stdout.strip()

            # Install flowctl if not found
            logger.info("ðŸ“¦ Installing flowctl CLI...")

            # Download flowctl binary securely (without shell=True)
            download_cmd = [
                "curl",
                "-L",
                "https://github.com/estuary/flow/releases/download/v0.5.15/flowctl-x86_64-linux",
                "-o",
                "/tmp/flowctl",
            ]
            subprocess.run(download_cmd, check=True)

            # Make the binary executable
            chmod_cmd = ["chmod", "+x", "/tmp/flowctl"]
            subprocess.run(chmod_cmd, check=True)

            # Move the binary to /usr/local/bin (requires sudo)
            move_cmd = ["sudo", "mv", "/tmp/flowctl", "/usr/local/bin/flowctl"]
            subprocess.run(move_cmd, check=True)

            logger.info("âœ… flowctl CLI installed successfully")
            return "/usr/local/bin/flowctl"

        except Exception as e:
            logger.exception(f"âŒ Failed to install flowctl: {e}")
            raise

    def _authenticate_flowctl(self):
        """Authenticate flowctl with Estuary credentials"""
        try:
            logger.info("ðŸ” Authenticating flowctl with Estuary...")

            # Use access token for authentication
            result = subprocess.run(
                ["flowctl", "auth", "token", "--token", self.credentials.access_token],
                check=False,
                capture_output=True,
                text=True,
            )

            if result.returncode == 0:
                logger.info("âœ… flowctl authentication successful")
            else:
                logger.error(f"âŒ flowctl authentication failed: {result.stderr}")
                raise Exception(f"Authentication failed: {result.stderr}")

        except Exception as e:
            logger.exception(f"âŒ Failed to authenticate flowctl: {e}")
            raise

    def run_flowctl_command(
        self, command: list[str], description: str = ""
    ) -> dict | None:
        """Execute a flowctl command with error handling"""
        try:
            if command[0] != "flowctl":
                command = ["flowctl", *command]

            logger.info(f"ðŸ”§ Executing: {' '.join(command)}")
            if description:
                logger.info(f"   Purpose: {description}")

            result = subprocess.run(
                command,
                check=False,
                capture_output=True,
                text=True,
                timeout=120,
                cwd=str(self.project_root),
            )

            if result.returncode == 0:
                logger.info(f"âœ… Command successful: {' '.join(command)}")
                try:
                    if result.stdout.strip():
                        return json.loads(result.stdout)
                    else:
                        return {"output": result.stdout, "stderr": result.stderr}
                except json.JSONDecodeError:
                    return {"output": result.stdout, "stderr": result.stderr}
            else:
                logger.error(f"âŒ Command failed: {' '.join(command)} - {result.stderr}")
                return None

        except subprocess.TimeoutExpired:
            logger.exception(f"âŒ Command timeout: {' '.join(command)}")
            return None
        except Exception as e:
            logger.exception(f"âŒ Command exception: {' '.join(command)} - {e!s}")
            return None

    def create_github_capture(
        self, repository: str, access_token: str
    ) -> EstuaryCapture:
        """Create GitHub capture configuration"""
        config = {
            "access_token": access_token,
            "repository": repository,
            "start_date": "2024-01-01T00:00:00Z",
        }

        bindings = [
            {
                "resource": {"stream": "commits"},
                "target": f"{self.credentials.tenant}/github-commits",
            },
            {
                "resource": {"stream": "pull_requests"},
                "target": f"{self.credentials.tenant}/github-pull-requests",
            },
            {
                "resource": {"stream": "issues"},
                "target": f"{self.credentials.tenant}/github-issues",
            },
            {
                "resource": {"stream": "repositories"},
                "target": f"{self.credentials.tenant}/github-repositories",
            },
        ]

        return EstuaryCapture(
            name="github-capture",
            connector_image=EstuaryConnectorType.GITHUB.value,
            config=config,
            bindings=bindings,
            tenant=self.credentials.tenant,
        )

    def create_hubspot_capture(
        self, client_id: str, client_secret: str, refresh_token: str
    ) -> EstuaryCapture:
        """Create HubSpot capture configuration"""
        config = {
            "credentials": {
                "credentials_title": "OAuth Credentials",
                "client_id": client_id,
                "client_secret": client_secret,
                "refresh_token": refresh_token,
            },
            "start_date": "2024-01-01T00:00:00Z",
        }

        bindings = [
            {
                "resource": {"stream": "contacts"},
                "target": f"{self.credentials.tenant}/hubspot-contacts",
            },
            {
                "resource": {"stream": "deals"},
                "target": f"{self.credentials.tenant}/hubspot-deals",
            },
            {
                "resource": {"stream": "companies"},
                "target": f"{self.credentials.tenant}/hubspot-companies",
            },
            {
                "resource": {"stream": "tickets"},
                "target": f"{self.credentials.tenant}/hubspot-tickets",
            },
        ]

        return EstuaryCapture(
            name="hubspot-capture",
            connector_image=EstuaryConnectorType.HUBSPOT.value,
            config=config,
            bindings=bindings,
            tenant=self.credentials.tenant,
        )

    def create_slack_capture(
        self, api_token: str, channels: list[str]
    ) -> EstuaryCapture:
        """Create Slack capture configuration"""
        config = {
            "api_token": api_token,
            "start_date": "2024-01-01T00:00:00Z",
            "channels": channels,
        }

        bindings = [
            {
                "resource": {"stream": "messages"},
                "target": f"{self.credentials.tenant}/slack-messages",
            },
            {
                "resource": {"stream": "channels"},
                "target": f"{self.credentials.tenant}/slack-channels",
            },
            {
                "resource": {"stream": "users"},
                "target": f"{self.credentials.tenant}/slack-users",
            },
        ]

        return EstuaryCapture(
            name="slack-capture",
            connector_image=EstuaryConnectorType.SLACK.value,
            config=config,
            bindings=bindings,
            tenant=self.credentials.tenant,
        )

    def create_QDRANT_materialization(

    ) -> EstuaryMaterialization:

        config = {

            "advanced": {
                "updateDelay": "0s",  # Real-time processing
                "deltaUpdates": True,
            },
        }

        # Bindings will be added dynamically based on collections
        bindings = []

        return EstuaryMaterialization(
            name="qdrant-sophia-ai",
            connector_image=EstuaryConnectorType.self.QDRANT_service.value,
            config=config,
            bindings=bindings,
            tenant=self.credentials.tenant,
        )

    def create_custom_connector(
        self, name: str, api_config: dict[str, Any]
    ) -> EstuaryCapture:
        """Create custom connector using HTTP inbound"""
        config = {
            "base_url": api_config["base_url"],
            "authentication": api_config.get("authentication", {}),
            "endpoints": api_config.get("endpoints", []),
        }

        bindings = []
        for endpoint in api_config.get("endpoints", []):
            bindings.append(
                {
                    "resource": {"endpoint": endpoint["name"]},
                    "target": f"{self.credentials.tenant}/{name}-{endpoint['name']}",
                }
            )

        return EstuaryCapture(
            name=f"{name}-capture",
            connector_image=EstuaryConnectorType.HTTP_INBOUND.value,
            config=config,
            bindings=bindings,
            tenant=self.credentials.tenant,
        )

    def deploy_capture(self, capture: EstuaryCapture) -> bool:
        """Deploy a capture to Estuary Flow"""
        try:
            logger.info(f"ðŸš€ Deploying capture: {capture.name}")

            # Save configuration to file
            config_file = self.config_dir / f"{capture.name}.flow.yaml"
            with open(config_file, "w") as f:
                yaml.dump(capture.to_flow_yaml(), f, default_flow_style=False)

            # Draft the capture
            result = self.run_flowctl_command(
                ["catalog", "draft", "--source", str(config_file)],
                f"Draft {capture.name}",
            )

            if not result:
                return False

            # Publish the capture
            publish_result = self.run_flowctl_command(
                ["catalog", "publish", "--source", str(config_file)],
                f"Publish {capture.name}",
            )

            if publish_result:
                logger.info(f"âœ… Successfully deployed capture: {capture.name}")
                return True
            else:
                logger.error(f"âŒ Failed to publish capture: {capture.name}")
                return False

        except Exception as e:
            logger.exception(f"âŒ Failed to deploy capture {capture.name}: {e}")
            return False

    def deploy_materialization(self, materialization: EstuaryMaterialization) -> bool:
        """Deploy a materialization to Estuary Flow"""
        try:
            logger.info(f"ðŸš€ Deploying materialization: {materialization.name}")

            # Save configuration to file
            config_file = self.config_dir / f"{materialization.name}.flow.yaml"
            with open(config_file, "w") as f:
                yaml.dump(materialization.to_flow_yaml(), f, default_flow_style=False)

            # Draft the materialization
            result = self.run_flowctl_command(
                ["catalog", "draft", "--source", str(config_file)],
                f"Draft {materialization.name}",
            )

            if not result:
                return False

            # Publish the materialization
            publish_result = self.run_flowctl_command(
                ["catalog", "publish", "--source", str(config_file)],
                f"Publish {materialization.name}",
            )

            if publish_result:
                logger.info(
                    f"âœ… Successfully deployed materialization: {materialization.name}"
                )
                return True
            else:
                logger.error(
                    f"âŒ Failed to publish materialization: {materialization.name}"
                )
                return False

        except Exception as e:
            logger.exception(
                f"âŒ Failed to deploy materialization {materialization.name}: {e}"
            )
            return False

    def list_captures(self) -> list[dict[str, Any]]:
        """List all captures in the tenant"""
        result = self.run_flowctl_command(
            [
                "catalog",
                "list",
                "--captures=true",
                "--collections=false",
                "--materializations=false",
                "--tests=false",
            ],
            "List all captures",
        )

        if result and "output" in result:
            # Parse the output to extract capture information
            captures = []
            for line in result["output"].split("\n"):
                if line.strip() and self.credentials.tenant in line:
                    captures.append({"name": line.strip()})
            return captures

        return []

    def list_materializations(self) -> list[dict[str, Any]]:
        """List all materializations in the tenant"""
        result = self.run_flowctl_command(
            [
                "catalog",
                "list",
                "--captures=false",
                "--collections=false",
                "--materializations=true",
                "--tests=false",
            ],
            "List all materializations",
        )

        if result and "output" in result:
            # Parse the output to extract materialization information
            materializations = []
            for line in result["output"].split("\n"):
                if line.strip() and self.credentials.tenant in line:
                    materializations.append({"name": line.strip()})
            return materializations

        return []

    def get_capture_status(self, capture_name: str) -> dict[str, Any] | None:
        """Get status of a specific capture"""
        full_name = f"{self.credentials.tenant}/{capture_name}"
        result = self.run_flowctl_command(
            ["catalog", "stats", "--name", full_name], f"Get status for {capture_name}"
        )

        return result

    def pause_capture(self, capture_name: str) -> bool:
        """Pause a capture"""
        full_name = f"{self.credentials.tenant}/{capture_name}"
        result = self.run_flowctl_command(
            ["catalog", "disable", "--name", full_name], f"Pause {capture_name}"
        )

        return result is not None

    def resume_capture(self, capture_name: str) -> bool:
        """Resume a capture"""
        full_name = f"{self.credentials.tenant}/{capture_name}"
        result = self.run_flowctl_command(
            ["catalog", "enable", "--name", full_name], f"Resume {capture_name}"
        )

        return result is not None

    def delete_capture(self, capture_name: str) -> bool:
        """Delete a capture"""
        full_name = f"{self.credentials.tenant}/{capture_name}"
        result = self.run_flowctl_command(
            ["catalog", "delete", "--name", full_name], f"Delete {capture_name}"
        )

        return result is not None

    def create_sophia_ai_foundation(self) -> dict[str, Any]:
        """Create complete Sophia AI foundation with Estuary Flow"""
        logger.info("ðŸ—ï¸ Creating Sophia AI foundation with Estuary Flow...")

        deployment_results = {
            "timestamp": datetime.now().isoformat(),
            "captures_deployed": [],
            "materializations_deployed": [],
            "errors": [],
            "success": False,
        }

        try:

                "account": "ZNB04675.us-east-1",
                "user": "SCOOBYJAVA15",
                "password": "${QDRANT_PAT_TOKEN}",  # Will be replaced with actual token
                "role": "ACCOUNTADMIN",
                "warehouse": "CORTEX_SOPHIA_AI_WH",
                "database": "SOPHIA_AI",
                "schema": "ESTUARY_STAGING",
            }

            # Save configuration for manual deployment
            config_file = self.config_dir / "qdrant-materialization.flow.yaml"
            with open(config_file, "w") as f:
                yaml.dump(

            deployment_results["materializations_deployed"].append(
                "qdrant-sophia-ai"
            )

            # Create capture configurations (will require API keys for deployment)
            capture_configs = {
                "github": {
                    "repository": "ai-cherry/sophia-main",
                    "access_token": "${GITHUB_ACCESS_TOKEN}",
                },
                "hubspot": {
                    "client_id": "${HUBSPOT_CLIENT_ID}",
                    "client_secret": "${HUBSPOT_CLIENT_SECRET}",
                    "refresh_token": "${HUBSPOT_REFRESH_TOKEN}",
                },
                "slack": {
                    "api_token": "${SLACK_API_TOKEN}",
                    "channels": ["general", "development", "sales", "ai-alerts"],
                },
            }

            # Save capture configurations
            for name, config in capture_configs.items():
                capture = None  # Initialize capture to avoid unbound variable error

                if name == "github":
                    capture = self.create_github_capture(
                        config["repository"], config["access_token"]
                    )
                elif name == "hubspot":
                    capture = self.create_hubspot_capture(
                        config["client_id"],
                        config["client_secret"],
                        config["refresh_token"],
                    )
                elif name == "slack":
                    capture = self.create_slack_capture(
                        config["api_token"], config["channels"]
                    )

                if capture:  # Only proceed if we have a valid capture
                    config_file = self.config_dir / f"{capture.name}.flow.yaml"
                    with open(config_file, "w") as f:
                        yaml.dump(capture.to_flow_yaml(), f, default_flow_style=False)

                    deployment_results["captures_deployed"].append(capture.name)

            # Create custom connectors for missing tools
            custom_connectors = {
                "usergems": {
                    "base_url": "https://api.usergems.com/v1",
                    "authentication": {
                        "type": "bearer",
                        "token": "${USERGEMS_API_KEY}",
                    },
                    "endpoints": [
                        {"name": "contacts", "path": "/contacts"},
                        {"name": "tracking", "path": "/tracking"},
                    ],
                },
                "apollo": {
                    "base_url": "https://api.apollo.io/v1",
                    "authentication": {
                        "type": "api_key",
                        "api_key": "${APOLLO_API_KEY}",
                    },
                    "endpoints": [
                        {"name": "contacts", "path": "/contacts/search"},
                        {"name": "opportunities", "path": "/opportunities"},
                    ],
                },
            }

            for name, config in custom_connectors.items():
                capture = self.create_custom_connector(name, config)
                config_file = self.config_dir / f"{capture.name}.flow.yaml"
                with open(config_file, "w") as f:
                    yaml.dump(capture.to_flow_yaml(), f, default_flow_style=False)

                deployment_results["captures_deployed"].append(capture.name)

            deployment_results["success"] = True
            logger.info("âœ… Sophia AI foundation configurations created successfully")

        except Exception as e:
            logger.exception(f"âŒ Failed to create Sophia AI foundation: {e}")
            deployment_results["errors"].append(str(e))

        return deployment_results

    def generate_deployment_script(self) -> str:
        """Generate deployment script for Sophia AI Estuary integration"""
        script_content = f"""#!/bin/bash
# Sophia AI Estuary Flow Deployment Script
# Generated on {datetime.now().isoformat()}

set -e

echo "ðŸš€ Starting Sophia AI Estuary Flow deployment..."

# Ensure flowctl is authenticated
flowctl auth token --token "$ESTUARY_ACCESS_TOKEN"

# Deploy Qdrant materialization
echo "â„ï¸ Deploying Qdrant materialization..."
flowctl catalog publish --source config/estuary/qdrant-materialization.flow.yaml

# Deploy GitHub capture
echo "ðŸ™ Deploying GitHub capture..."
flowctl catalog publish --source config/estuary/github-capture.flow.yaml

# Deploy HubSpot capture
echo "ðŸŽ¯ Deploying HubSpot capture..."
flowctl catalog publish --source config/estuary/hubspot-capture.flow.yaml

# Deploy Slack capture
echo "ðŸ’¬ Deploying Slack capture..."
flowctl catalog publish --source config/estuary/slack-capture.flow.yaml

# Deploy custom connectors
echo "ðŸ”§ Deploying custom connectors..."
flowctl catalog publish --source config/estuary/usergems-capture.flow.yaml
flowctl catalog publish --source config/estuary/apollo-capture.flow.yaml

echo "âœ… Sophia AI Estuary Flow deployment completed!"
echo "ðŸ“Š Check status with: flowctl catalog list"
"""

        script_path = self.project_root / "scripts" / "deploy_estuary_foundation.sh"
        script_path.parent.mkdir(parents=True, exist_ok=True)

        with open(script_path, "w") as f:
            f.write(script_content)

        # Make script executable
        os.chmod(script_path, 0o644)  # SECURITY FIX: Reduced permissions

        logger.info(f"ðŸ“œ Deployment script created: {script_path}")
        return str(script_path)

# Convenience functions for easy import
def get_estuary_manager() -> EstuaryFlowManager:
    """Get configured Estuary Flow manager"""
    return EstuaryFlowManager()

def create_sophia_ai_foundation() -> dict[str, Any]:
    """Create complete Sophia AI foundation"""
    manager = get_estuary_manager()
    return manager.create_sophia_ai_foundation()

if __name__ == "__main__":
    # Example usage
    manager = EstuaryFlowManager()
    results = manager.create_sophia_ai_foundation()
