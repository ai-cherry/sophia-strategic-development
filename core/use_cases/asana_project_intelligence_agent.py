"""
File Decomposition Plan (auto-generated by Phase 3)
Current size: 1021 lines

Recommended decomposition:
- asana_project_intelligence_agent_core.py - Core functionality
- asana_project_intelligence_agent_utils.py - Utility functions
- asana_project_intelligence_agent_models.py - Data models
- asana_project_intelligence_agent_handlers.py - Request handlers

TODO: Implement file decomposition (Plan created: 2025-07-13)
"""

from __future__ import annotations

import asyncio
import json
import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any

from core.agents.langgraph_agent_base import LangGraphAgentBase
from infrastructure.mcp_servers.enhanced_ai_memory_mcp_server import (
    EnhancedAiMemoryMCPServer,
)
from infrastructure.services.llm_router import TaskType, llm_router
from backend.services.unified_memory_service_v2 import UnifiedMemoryServiceV2

logger = logging.getLogger(__name__)


class ProjectHealthStatus(Enum):
    """Project health status levels"""

    EXCELLENT = "excellent"
    GOOD = "good"
    FAIR = "fair"
    POOR = "poor"
    CRITICAL = "critical"


class RiskLevel(Enum):
    """Risk assessment levels"""

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class MemoryCategory:
    """Memory categories for AI storage"""

    ASANA_PROJECT_ANALYSIS = "asana_project_analysis"
    ASANA_TEAM_INSIGHTS = "asana_team_insights"
    ASANA_RISK_ASSESSMENT = "asana_risk_assessment"


@dataclass
class AsanaProjectMetrics:
    """Comprehensive project metrics from Asana"""

    project_gid: str
    project_name: str
    completion_percentage: float
    task_count: int
    completed_task_count: int
    overdue_task_count: int
    team_name: str | None
    owner_name: str | None
    due_date: datetime | None
    created_at: datetime
    modified_at: datetime
    health_score: float = 0.0
    risk_level: RiskLevel = RiskLevel.LOW
    ai_insights: dict[str, Any] = field(default_factory=dict)


@dataclass
class TeamProductivityMetrics:
    """Team productivity analysis"""

    team_name: str
    total_projects: int
    active_projects: int
    completed_projects: int
    average_completion_rate: float
    overdue_tasks_ratio: float
    team_velocity: float
    member_count: int
    productivity_score: float = 0.0


@dataclass
class ProjectRiskAssessment:
    """Comprehensive project risk assessment"""

    project_gid: str
    project_name: str
    overall_risk: RiskLevel
    schedule_risk: RiskLevel
    resource_risk: RiskLevel
    scope_risk: RiskLevel
    quality_risk: RiskLevel
    risk_factors: list[str] = field(default_factory=list)
    mitigation_suggestions: list[str] = field(default_factory=list)
    predicted_completion_date: datetime | None = None


class AsanaProjectIntelligenceAgent(LangGraphAgentBase):
    """Advanced Asana project intelligence and analytics agent"""

    def __init__(self, config: dict[str, Any]):
        super().__init__(config)
        self.cortex_service = None
        self.ai_memory_service = None
        self.llm_service = None

    async def initialize(self) -> None:
        """Initialize the Asana intelligence agent"""
        try:
            await super().initialize()
            self.cortex_service = UnifiedMemoryServiceV2()
            await self.cortex_service.initialize()
            self.ai_memory_service = EnhancedAiMemoryMCPServer()
            await self.ai_memory_service.initialize()
            logger.info("‚úÖ Asana Project Intelligence Agent initialized")
        except Exception as e:
            logger.exception(f"‚ùå Failed to initialize Asana intelligence agent: {e}")
            raise

    async def get_project_metrics(
        self, project_gid: str | None = None
    ) -> list[AsanaProjectMetrics]:
        """Get comprehensive project metrics from Asana data"""
        try:
            where_clause = (
                f"WHERE PROJECT_GID = '{project_gid}'"
                if project_gid
                else "WHERE IS_ARCHIVED = FALSE"
            )
            query = f"\n            WITH project_task_summary AS (\n                SELECT\n                    p.PROJECT_GID,\n                    COUNT(t.TASK_GID) as total_tasks,\n                    COUNT(CASE WHEN t.IS_COMPLETED = TRUE THEN 1 END) as completed_tasks,\n                    COUNT(CASE WHEN t.TASK_STATUS = 'OVERDUE' THEN 1 END) as overdue_tasks,\n                    AVG(CASE WHEN t.AI_URGENCY_SCORE IS NOT NULL THEN t.AI_URGENCY_SCORE ELSE 0.5 END) as avg_urgency\n                FROM STG_ESTUARY.STG_ASANA_PROJECTS p\n                LEFT JOIN STG_ESTUARY.STG_ASANA_TASKS t ON p.PROJECT_GID = t.PROJECT_GID\n                GROUP BY p.PROJECT_GID\n            )\n            SELECT\n                p.PROJECT_GID,\n                p.PROJECT_NAME,\n                p.COMPLETION_PERCENTAGE,\n                p.TEAM_NAME,\n                p.OWNER_NAME,\n                p.DUE_DATE,\n                p.CREATED_AT,\n                p.MODIFIED_AT,\n                p.AI_HEALTH_SCORE,\n                p.AI_RISK_ASSESSMENT,\n                pts.total_tasks,\n                pts.completed_tasks,\n                pts.overdue_tasks,\n                pts.avg_urgency,\n                p.AI_MEMORY_METADATA\n            FROM STG_ESTUARY.STG_ASANA_PROJECTS p\n            LEFT JOIN project_task_summary pts ON p.PROJECT_GID = pts.PROJECT_GID\n            {where_clause}\n            ORDER BY p.MODIFIED_AT DESC\n            "
            result = await self.cortex_service.execute_query(query)
            metrics = []
            for _, row in result.iterrows():
                health_score = self._calculate_project_health_score(row)
                risk_level = self._assess_project_risk_level(row)
                ai_metadata = (
                    json.loads(row.get("AI_MEMORY_METADATA", "{}"))
                    if row.get("AI_MEMORY_METADATA")
                    else {}
                )
                metrics.append(
                    AsanaProjectMetrics(
                        project_gid=row["PROJECT_GID"],
                        project_name=row["PROJECT_NAME"],
                        completion_percentage=row.get("COMPLETION_PERCENTAGE", 0.0),
                        task_count=row.get("TOTAL_TASKS", 0),
                        completed_task_count=row.get("COMPLETED_TASKS", 0),
                        overdue_task_count=row.get("OVERDUE_TASKS", 0),
                        team_name=row.get("TEAM_NAME"),
                        owner_name=row.get("OWNER_NAME"),
                        due_date=row.get("DUE_DATE"),
                        created_at=row["CREATED_AT"],
                        modified_at=row["MODIFIED_AT"],
                        health_score=health_score,
                        risk_level=risk_level,
                        ai_insights=ai_metadata,
                    )
                )
            return metrics
        except Exception as e:
            logger.exception(f"‚ùå Failed to get project metrics: {e}")
            return []

    def _calculate_project_health_score(self, project_data: dict[str, Any]) -> float:
        """Calculate comprehensive project health score"""
        try:
            score = 0.0
            completion = project_data.get("COMPLETION_PERCENTAGE", 0.0)
            score += completion / 100.0 * 0.4
            total_tasks = project_data.get("TOTAL_TASKS", 0)
            completed_tasks = project_data.get("COMPLETED_TASKS", 0)
            if total_tasks > 0:
                task_completion_ratio = completed_tasks / total_tasks
                score += task_completion_ratio * 0.3
            overdue_tasks = project_data.get("OVERDUE_TASKS", 0)
            if total_tasks > 0:
                overdue_ratio = overdue_tasks / total_tasks
                score += (1.0 - overdue_ratio) * 0.2
            else:
                score += 0.2
            due_date = project_data.get("DUE_DATE")
            if due_date:
                days_to_due = (due_date - datetime.now()).days
                if days_to_due > 0:
                    score += 0.1
                elif days_to_due >= -7:
                    score += 0.05
            else:
                score += 0.1
            return min(1.0, max(0.0, score))
        except Exception as e:
            logger.exception(f"‚ùå Error calculating health score: {e}")
            return 0.5

    def _assess_project_risk_level(self, project_data: dict[str, Any]) -> RiskLevel:
        """Assess project risk level based on multiple factors"""
        try:
            risk_score = 0.0
            total_tasks = project_data.get("TOTAL_TASKS", 0)
            overdue_tasks = project_data.get("OVERDUE_TASKS", 0)
            if total_tasks > 0:
                overdue_ratio = overdue_tasks / total_tasks
                risk_score += overdue_ratio * 0.4
            completion = project_data.get("COMPLETION_PERCENTAGE", 0.0)
            due_date = project_data.get("DUE_DATE")
            if due_date:
                days_to_due = (due_date - datetime.now()).days
                if days_to_due > 0:
                    expected_completion = 100.0 - days_to_due / 30.0 * 20.0
                    if completion < expected_completion:
                        risk_score += 0.3
                elif days_to_due <= 0:
                    risk_score += 0.5
            avg_urgency = project_data.get("AVG_URGENCY", 0.5)
            risk_score += avg_urgency * 0.3
            if risk_score >= 0.8:
                return RiskLevel.CRITICAL
            elif risk_score >= 0.6:
                return RiskLevel.HIGH
            elif risk_score >= 0.4:
                return RiskLevel.MEDIUM
            else:
                return RiskLevel.LOW
        except Exception as e:
            logger.exception(f"‚ùå Error assessing risk level: {e}")
            return RiskLevel.MEDIUM

    async def analyze_team_productivity(
        self, team_name: str | None = None
    ) -> list[TeamProductivityMetrics]:
        """Analyze team productivity across projects"""
        try:
            where_clause = f"WHERE p.TEAM_NAME = '{team_name}'" if team_name else ""
            query = f"\n            WITH team_metrics AS (\n                SELECT\n                    p.TEAM_NAME,\n                    COUNT(DISTINCT p.PROJECT_GID) as total_projects,\n                    COUNT(DISTINCT CASE WHEN p.IS_ARCHIVED = FALSE THEN p.PROJECT_GID END) as active_projects,\n                    COUNT(DISTINCT CASE WHEN p.COMPLETION_PERCENTAGE = 100 THEN p.PROJECT_GID END) as completed_projects,\n                    AVG(p.COMPLETION_PERCENTAGE) as avg_completion_rate,\n                    COUNT(DISTINCT u.USER_GID) as member_count\n                FROM STG_ESTUARY.STG_ASANA_PROJECTS p\n                LEFT JOIN STG_ESTUARY.STG_ASANA_TASKS t ON p.PROJECT_GID = t.PROJECT_GID\n                LEFT JOIN STG_ESTUARY.STG_ASANA_USERS u ON p.TEAM_NAME = u.DEPARTMENT\n                {where_clause}\n                GROUP BY p.TEAM_NAME\n            ),\n            task_metrics AS (\n                SELECT\n                    p.TEAM_NAME,\n                    COUNT(t.TASK_GID) as total_tasks,\n                    COUNT(CASE WHEN t.IS_COMPLETED = TRUE THEN 1 END) as completed_tasks,\n                    COUNT(CASE WHEN t.TASK_STATUS = 'OVERDUE' THEN 1 END) as overdue_tasks,\n                    COUNT(CASE WHEN t.COMPLETED_AT >= CURRENT_DATE - 30 THEN 1 END) as tasks_completed_last_30d\n                FROM STG_ESTUARY.STG_ASANA_PROJECTS p\n                LEFT JOIN STG_ESTUARY.STG_ASANA_TASKS t ON p.PROJECT_GID = t.PROJECT_GID\n                {where_clause}\n                GROUP BY p.TEAM_NAME\n            )\n            SELECT\n                tm.TEAM_NAME,\n                tm.total_projects,\n                tm.active_projects,\n                tm.completed_projects,\n                tm.avg_completion_rate,\n                tm.member_count,\n                COALESCE(tkm.total_tasks, 0) as total_tasks,\n                COALESCE(tkm.overdue_tasks, 0) as overdue_tasks,\n                COALESCE(tkm.tasks_completed_last_30d, 0) as recent_completions\n            FROM team_metrics tm\n            LEFT JOIN task_metrics tkm ON tm.TEAM_NAME = tkm.TEAM_NAME\n            WHERE tm.TEAM_NAME IS NOT NULL\n            ORDER BY tm.avg_completion_rate DESC\n            "
            result = await self.cortex_service.execute_query(query)
            team_metrics = []
            for _, row in result.iterrows():
                total_tasks = row.get("TOTAL_TASKS", 0)
                overdue_tasks = row.get("OVERDUE_TASKS", 0)
                overdue_ratio = overdue_tasks / total_tasks if total_tasks > 0 else 0.0
                member_count = row.get("MEMBER_COUNT", 1)
                recent_completions = row.get("RECENT_COMPLETIONS", 0)
                velocity = (
                    recent_completions / member_count if member_count > 0 else 0.0
                )
                productivity_score = self._calculate_team_productivity_score(
                    row, overdue_ratio, velocity
                )
                team_metrics.append(
                    TeamProductivityMetrics(
                        team_name=row["TEAM_NAME"],
                        total_projects=row.get("TOTAL_PROJECTS", 0),
                        active_projects=row.get("ACTIVE_PROJECTS", 0),
                        completed_projects=row.get("COMPLETED_PROJECTS", 0),
                        average_completion_rate=row.get("AVG_COMPLETION_RATE", 0.0),
                        overdue_tasks_ratio=overdue_ratio,
                        team_velocity=velocity,
                        member_count=member_count,
                        productivity_score=productivity_score,
                    )
                )
            return team_metrics
        except Exception as e:
            logger.exception(f"‚ùå Failed to analyze team productivity: {e}")
            return []

    def _calculate_team_productivity_score(
        self, team_data: dict[str, Any], overdue_ratio: float, velocity: float
    ) -> float:
        """Calculate team productivity score"""
        try:
            score = 0.0
            completion_rate = team_data.get("AVG_COMPLETION_RATE", 0.0)
            score += completion_rate / 100.0 * 0.4
            score += (1.0 - overdue_ratio) * 0.3
            normalized_velocity = min(1.0, velocity / 5.0)
            score += normalized_velocity * 0.2
            total_projects = team_data.get("TOTAL_PROJECTS", 0)
            completed_projects = team_data.get("COMPLETED_PROJECTS", 0)
            if total_projects > 0:
                completion_ratio = completed_projects / total_projects
                score += completion_ratio * 0.1
            return min(1.0, max(0.0, score))
        except Exception as e:
            logger.exception(f"‚ùå Error calculating team productivity score: {e}")
            return 0.5

    async def perform_risk_assessment(
        self, project_gid: str | None = None
    ) -> list[ProjectRiskAssessment]:
        """Perform comprehensive risk assessment for projects"""
        try:
            projects = await self.get_project_metrics(project_gid)
            risk_assessments = []
            for project in projects:
                task_query = f"\n                SELECT\n                    COUNT(*) as total_tasks,\n                    COUNT(CASE WHEN TASK_STATUS = 'OVERDUE' THEN 1 END) as overdue_tasks,\n                    COUNT(CASE WHEN ASSIGNEE_GID IS NULL THEN 1 END) as unassigned_tasks,\n                    COUNT(CASE WHEN DEPENDENCY_COUNT > 0 THEN 1 END) as dependent_tasks,\n                    AVG(AI_URGENCY_SCORE) as avg_urgency,\n                    COUNT(CASE WHEN ESTIMATED_HOURS IS NULL THEN 1 END) as unestimated_tasks\n                FROM STG_ESTUARY.STG_ASANA_TASKS\n                WHERE PROJECT_GID = '{project.project_gid}'\n                "
                task_result = await self.cortex_service.execute_query(task_query)
                task_data = task_result.iloc[0] if not task_result.empty else {}
                schedule_risk = self._assess_schedule_risk(project, task_data)
                resource_risk = self._assess_resource_risk(project, task_data)
                scope_risk = self._assess_scope_risk(project, task_data)
                quality_risk = self._assess_quality_risk(project, task_data)
                risk_scores = [schedule_risk, resource_risk, scope_risk, quality_risk]
                overall_risk_score = max(risk_scores)
                overall_risk = RiskLevel.LOW
                if overall_risk_score >= 0.8:
                    overall_risk = RiskLevel.CRITICAL
                elif overall_risk_score >= 0.6:
                    overall_risk = RiskLevel.HIGH
                elif overall_risk_score >= 0.4:
                    overall_risk = RiskLevel.MEDIUM
                (
                    risk_factors,
                    mitigation_suggestions,
                ) = await self._generate_risk_insights(
                    project,
                    task_data,
                    schedule_risk,
                    resource_risk,
                    scope_risk,
                    quality_risk,
                )
                predicted_completion = self._predict_completion_date(project, task_data)
                risk_assessments.append(
                    ProjectRiskAssessment(
                        project_gid=project.project_gid,
                        project_name=project.project_name,
                        overall_risk=overall_risk,
                        schedule_risk=self._score_to_risk_level(schedule_risk),
                        resource_risk=self._score_to_risk_level(resource_risk),
                        scope_risk=self._score_to_risk_level(scope_risk),
                        quality_risk=self._score_to_risk_level(quality_risk),
                        risk_factors=risk_factors,
                        mitigation_suggestions=mitigation_suggestions,
                        predicted_completion_date=predicted_completion,
                    )
                )
            return risk_assessments
        except Exception as e:
            logger.exception(f"‚ùå Failed to perform risk assessment: {e}")
            return []

    def _assess_schedule_risk(
        self, project: AsanaProjectMetrics, task_data: dict[str, Any]
    ) -> float:
        """Assess schedule-related risks"""
        risk_score = 0.0
        total_tasks = task_data.get("TOTAL_TASKS", 0)
        overdue_tasks = task_data.get("OVERDUE_TASKS", 0)
        if total_tasks > 0:
            risk_score += overdue_tasks / total_tasks * 0.5
        if project.due_date:
            days_to_due = (project.due_date - datetime.now()).days
            if days_to_due < 0:
                risk_score += 0.4
            elif days_to_due < 7:
                risk_score += 0.3
            elif days_to_due < 30:
                risk_score += 0.2
        if project.due_date and project.created_at:
            total_duration = (project.due_date - project.created_at).days
            elapsed_duration = (datetime.now() - project.created_at).days
            if total_duration > 0:
                expected_completion = elapsed_duration / total_duration * 100
                if project.completion_percentage < expected_completion:
                    risk_score += 0.1
        return min(1.0, risk_score)

    def _assess_resource_risk(
        self, project: AsanaProjectMetrics, task_data: dict[str, Any]
    ) -> float:
        """Assess resource-related risks"""
        risk_score = 0.0
        total_tasks = task_data.get("TOTAL_TASKS", 0)
        unassigned_tasks = task_data.get("UNASSIGNED_TASKS", 0)
        if total_tasks > 0:
            risk_score += unassigned_tasks / total_tasks * 0.6
        avg_urgency = task_data.get("AVG_URGENCY", 0.5)
        if avg_urgency > 0.7:
            risk_score += 0.4
        return min(1.0, risk_score)

    def _assess_scope_risk(
        self, project: AsanaProjectMetrics, task_data: dict[str, Any]
    ) -> float:
        """Assess scope-related risks"""
        risk_score = 0.0
        total_tasks = task_data.get("TOTAL_TASKS", 0)
        unestimated_tasks = task_data.get("UNESTIMATED_TASKS", 0)
        if total_tasks > 0:
            risk_score += unestimated_tasks / total_tasks * 0.5
        dependent_tasks = task_data.get("DEPENDENT_TASKS", 0)
        if total_tasks > 0:
            dependency_ratio = dependent_tasks / total_tasks
            if dependency_ratio > 0.5:
                risk_score += 0.3
        return min(1.0, risk_score)

    def _assess_quality_risk(
        self, project: AsanaProjectMetrics, task_data: dict[str, Any]
    ) -> float:
        """Assess quality-related risks"""
        risk_score = 0.0
        avg_urgency = task_data.get("AVG_URGENCY", 0.5)
        if avg_urgency > 0.8:
            risk_score += 0.4
        if project.completion_percentage > 80:
            days_since_start = (datetime.now() - project.created_at).days
            if days_since_start < 7:
                risk_score += 0.2
        return min(1.0, risk_score)

    def _score_to_risk_level(self, score: float) -> RiskLevel:
        """Convert risk score to risk level"""
        if score >= 0.8:
            return RiskLevel.CRITICAL
        elif score >= 0.6:
            return RiskLevel.HIGH
        elif score >= 0.4:
            return RiskLevel.MEDIUM
        else:
            return RiskLevel.LOW

    async def _generate_risk_insights(
        self,
        project: AsanaProjectMetrics,
        task_data: dict[str, Any],
        schedule_risk: float,
        resource_risk: float,
        scope_risk: float,
        quality_risk: float,
    ) -> tuple[list[str], list[str]]:
        """Generate AI-powered risk insights and mitigation suggestions"""
        try:
            context = f"""
            Project: {project.project_name}
            Completion: {project.completion_percentage}%
            Total Tasks: {task_data.get('TOTAL_TASKS', 0)}
            Overdue Tasks: {task_data.get('OVERDUE_TASKS', 0)}
            Unassigned Tasks: {task_data.get('UNASSIGNED_TASKS', 0)}
            Schedule Risk: {schedule_risk:.2f}
            Resource Risk: {resource_risk:.2f}
            Scope Risk: {scope_risk:.2f}
            Quality Risk: {quality_risk:.2f}
            """
            insights_prompt = f"\n            Analyze this project data and identify the top 3 risk factors and 3 mitigation strategies:\n\n            {context}\n\n            Provide:\n            1. Risk factors (specific, actionable insights)\n            2. Mitigation suggestions (concrete next steps)\n\n            Format as JSON with 'risk_factors' and 'mitigation_suggestions' arrays.\n            "
            ai_response = ""
            async for chunk in llm_router.complete(
                prompt=insights_prompt,
                task=TaskType.BUSINESS_INTELLIGENCE,
                temperature=0.3,
                max_tokens=500,
            ):
                ai_response += chunk
            try:
                insights = json.loads(ai_response)
                risk_factors = insights.get("risk_factors", [])
                mitigation_suggestions = insights.get("mitigation_suggestions", [])
            except json.JSONDecodeError:
                risk_factors, mitigation_suggestions = self._generate_fallback_insights(
                    project,
                    task_data,
                    schedule_risk,
                    resource_risk,
                    scope_risk,
                    quality_risk,
                )
            return (risk_factors, mitigation_suggestions)
        except Exception as e:
            logger.exception(f"‚ùå Error generating risk insights: {e}")
            return self._generate_fallback_insights(
                project,
                task_data,
                schedule_risk,
                resource_risk,
                scope_risk,
                quality_risk,
            )

    def _generate_fallback_insights(
        self,
        project: AsanaProjectMetrics,
        task_data: dict[str, Any],
        schedule_risk: float,
        resource_risk: float,
        scope_risk: float,
        quality_risk: float,
    ) -> tuple[list[str], list[str]]:
        """Generate fallback insights using rule-based logic"""
        risk_factors = []
        mitigation_suggestions = []
        if schedule_risk > 0.6:
            risk_factors.append("Project timeline is at risk due to overdue tasks")
            mitigation_suggestions.append(
                "Prioritize overdue tasks and consider deadline extension"
            )
        if resource_risk > 0.6:
            unassigned_ratio = task_data.get("UNASSIGNED_TASKS", 0) / max(
                task_data.get("TOTAL_TASKS", 1), 1
            )
            if unassigned_ratio > 0.3:
                risk_factors.append(f"{unassigned_ratio:.0%} of tasks are unassigned")
                mitigation_suggestions.append(
                    "Assign owners to unassigned tasks immediately"
                )
        if scope_risk > 0.6:
            risk_factors.append("Project scope may be unclear due to unestimated tasks")
            mitigation_suggestions.append(
                "Conduct estimation session for remaining tasks"
            )
        return (risk_factors, mitigation_suggestions)

    def _predict_completion_date(
        self, project: AsanaProjectMetrics, task_data: dict[str, Any]
    ) -> datetime | None:
        """Predict project completion date based on current progress"""
        try:
            if project.completion_percentage >= 100:
                return datetime.now()
            days_since_start = (datetime.now() - project.created_at).days
            if days_since_start <= 0:
                return None
            completed_tasks = project.completed_task_count
            velocity = completed_tasks / days_since_start
            if velocity <= 0:
                return None
            remaining_tasks = project.task_count - completed_tasks
            estimated_days_remaining = remaining_tasks / velocity
            risk_buffer = 1.0
            total_tasks = task_data.get("TOTAL_TASKS", 0)
            if total_tasks > 0:
                overdue_ratio = task_data.get("OVERDUE_TASKS", 0) / total_tasks
                unassigned_ratio = task_data.get("UNASSIGNED_TASKS", 0) / total_tasks
                risk_buffer += (overdue_ratio + unassigned_ratio) * 0.5
            adjusted_days = estimated_days_remaining * risk_buffer
            predicted_date = datetime.now() + timedelta(days=adjusted_days)
            return predicted_date
        except Exception as e:
            logger.exception(f"‚ùå Error predicting completion date: {e}")
            return None

    async def generate_project_intelligence_report(
        self, project_gid: str | None = None
    ) -> dict[str, Any]:
        """Generate comprehensive project intelligence report"""
        try:
            logger.info(
                f"üß† Generating project intelligence report for {project_gid or 'all projects'}"
            )
            projects = await self.get_project_metrics(project_gid)
            teams = await self.analyze_team_productivity()
            risks = await self.perform_risk_assessment(project_gid)
            await self._store_intelligence_insights(projects, teams, risks)
            summary = await self._generate_summary_insights(projects, teams, risks)
            report = {
                "generated_at": datetime.now().isoformat(),
                "scope": "single_project" if project_gid else "all_projects",
                "project_metrics": [
                    {
                        "project_gid": p.project_gid,
                        "project_name": p.project_name,
                        "health_score": p.health_score,
                        "completion_percentage": p.completion_percentage,
                        "risk_level": p.risk_level.value,
                        "task_count": p.task_count,
                        "overdue_tasks": p.overdue_task_count,
                        "team_name": p.team_name,
                        "owner_name": p.owner_name,
                    }
                    for p in projects
                ],
                "team_productivity": [
                    {
                        "team_name": t.team_name,
                        "productivity_score": t.productivity_score,
                        "active_projects": t.active_projects,
                        "completion_rate": t.average_completion_rate,
                        "team_velocity": t.team_velocity,
                        "member_count": t.member_count,
                    }
                    for t in teams
                ],
                "risk_assessments": [
                    {
                        "project_gid": r.project_gid,
                        "project_name": r.project_name,
                        "overall_risk": r.overall_risk.value,
                        "risk_factors": r.risk_factors,
                        "mitigation_suggestions": r.mitigation_suggestions,
                        "predicted_completion": (
                            r.predicted_completion_date.isoformat()
                            if r.predicted_completion_date
                            else None
                        ),
                    }
                    for r in risks
                ],
                "summary": summary,
            }
            logger.info(f"‚úÖ Generated intelligence report for {len(projects)} projects")
            return report
        except Exception as e:
            logger.exception(f"‚ùå Failed to generate intelligence report: {e}")
            return {"error": str(e), "generated_at": datetime.now().isoformat()}

    async def _store_intelligence_insights(
        self,
        projects: list[AsanaProjectMetrics],
        teams: list[TeamProductivityMetrics],
        risks: list[ProjectRiskAssessment],
    ) -> None:
        """Store intelligence insights in AI Memory for future reference"""
        try:
            for project in projects:
                insight_content = f"\n                Project Intelligence: {project.project_name}\n                Health Score: {project.health_score:.2f}\n                Completion: {project.completion_percentage}%\n                Risk Level: {project.risk_level.value}\n                Team: {project.team_name}\n                Owner: {project.owner_name}\n                Tasks: {project.completed_task_count}/{project.task_count} completed\n                "
                await self.ai_memory_service.store_memory(
                    content=insight_content,
                    category="asana_project_intelligence",
                    tags=["project_analysis", "health_score", project.project_gid],
                    metadata={
                        "project_gid": project.project_gid,
                        "health_score": project.health_score,
                        "risk_level": project.risk_level.value,
                        "analysis_date": datetime.now().isoformat(),
                    },
                )
            for team in teams:
                team_insight = f"\n                Team Productivity Analysis: {team.team_name}\n                Productivity Score: {team.productivity_score:.2f}\n                Active Projects: {team.active_projects}\n                Completion Rate: {team.average_completion_rate:.1f}%\n                Team Velocity: {team.team_velocity:.1f} tasks/member/month\n                "
                await self.ai_memory_service.store_memory(
                    content=team_insight,
                    category="asana_team_productivity",
                    tags=[
                        "team_analysis",
                        "productivity",
                        team.team_name.lower().replace(" ", "_"),
                    ],
                    metadata={
                        "team_name": team.team_name,
                        "productivity_score": team.productivity_score,
                        "analysis_date": datetime.now().isoformat(),
                    },
                )
        except Exception as e:
            logger.exception(f"‚ùå Failed to store intelligence insights: {e}")

    async def _generate_summary_insights(
        self,
        projects: list[AsanaProjectMetrics],
        teams: list[TeamProductivityMetrics],
        risks: list[ProjectRiskAssessment],
    ) -> dict[str, Any]:
        """Generate high-level summary insights"""
        try:
            if not projects:
                return {"message": "No projects found for analysis"}
            avg_health_score = sum(p.health_score for p in projects) / len(projects)
            avg_completion = sum(p.completion_percentage for p in projects) / len(
                projects
            )
            total_overdue_tasks = sum(p.overdue_task_count for p in projects)
            risk_distribution = {}
            for risk in risks:
                risk_level = risk.overall_risk.value
                risk_distribution[risk_level] = risk_distribution.get(risk_level, 0) + 1
            top_teams = sorted(teams, key=lambda t: t.productivity_score, reverse=True)[
                :3
            ]
            at_risk_projects = [
                p
                for p in projects
                if p.health_score < 0.6
                or p.risk_level in [RiskLevel.HIGH, RiskLevel.CRITICAL]
            ]
            summary = {
                "overall_health_score": round(avg_health_score, 2),
                "average_completion": round(avg_completion, 1),
                "total_projects": len(projects),
                "total_overdue_tasks": total_overdue_tasks,
                "risk_distribution": risk_distribution,
                "top_performing_teams": [
                    {"name": t.team_name, "score": round(t.productivity_score, 2)}
                    for t in top_teams
                ],
                "projects_needing_attention": [
                    {
                        "name": p.project_name,
                        "health_score": round(p.health_score, 2),
                        "risk_level": p.risk_level.value,
                    }
                    for p in at_risk_projects[:5]
                ],
                "key_insights": [
                    f"Portfolio health score: {avg_health_score:.1%}",
                    f"Average project completion: {avg_completion:.1f}%",
                    f"{len(at_risk_projects)} projects need immediate attention",
                    (
                        f"Top team: {top_teams[0].team_name}"
                        if top_teams
                        else "No team data available"
                    ),
                ],
            }
            return summary
        except Exception as e:
            logger.exception(f"‚ùå Failed to generate summary insights: {e}")
            return {"error": str(e)}

    async def close(self) -> None:
        """Clean up resources"""
        try:
            if self.cortex_service:
                await self.cortex_service.close()
            if self.ai_memory_service:
                await self.ai_memory_service.close()
            if self.llm_service:
                await self.llm_service.close()
            await super().close()
        except Exception as e:
            logger.exception(f"‚ùå Error closing Asana intelligence agent: {e}")


async def main():
    """Test the Asana Project Intelligence Agent"""
    config = {
        "agent_id": "asana_project_intelligence",
        "performance_target_ms": 200,
        "cache_ttl_seconds": 300,
    }
    agent = AsanaProjectIntelligenceAgent(config)
    try:
        await agent.initialize()
        report = await agent.generate_project_intelligence_report()
        if report["summary"]["projects_needing_attention"]:
            for _project in report["summary"]["projects_needing_attention"]:
                pass
    except Exception:
        pass
    finally:
        await agent.close()


if __name__ == "__main__":
    asyncio.run(main())
