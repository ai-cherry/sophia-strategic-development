#!/usr/bin/env python3
"""
"""
"""
"""
    """Project health status levels"""
    HEALTHY = "healthy"
    AT_RISK = "at_risk"
    CRITICAL = "critical"
    BLOCKED = "blocked"
    """Types of project risks"""
    SCHEDULE_DELAY = "schedule_delay"
    SCOPE_CREEP = "scope_creep"
    RESOURCE_CONSTRAINT = "resource_constraint"
    TECHNICAL_DEBT = "technical_debt"
    DEPENDENCY_ISSUE = "dependency_issue"
    QUALITY_CONCERN = "quality_concern"
    """Linear issue data structure"""
    """Project risk assessment"""
    """Project health metrics"""
    """Comprehensive project health report"""
    """
    """
        self.name = "linear_project_health"
            "AI-driven Linear project health monitoring and risk detection"
            "completion_rate_healthy"
            "completion_rate_at_risk"
            "overdue_threshold"
            "velocity_decline_threshold"
            "cycle_time_increase_threshold"
        """Initialize Linear Project Health Agent"""
            logger.info("âœ… Linear Project Health Agent initialized"
            logger.exception(f"Failed to initialize Linear Project Health Agent: {e}"
        """
        """
            logger.exception(f"Error assessing project health: {e}"
        """
        """
                    "project_id"
                    "period_days"
                    "message": "Insufficient historical data for trend analysis"
                "project_id"
                "period_days"
                "trends"
                "insights"
                "recommendations"
            logger.exception(f"Error monitoring project trends: {e}"
        """
        """
                < baseline_metrics.get("completion_rate"
                        "type": "velocity_drop"
                        "severity": "high"
                        "description": f"Completion rate dropped to {current_metrics.completion_rate:.1%}"
                        "impact": "Project delivery at risk"
            baseline_cycle_time = baseline_metrics.get("avg_cycle_time"
                        "type": "cycle_time_increase"
                        "severity": "medium"
                        "description": f"Average cycle time increased to {current_metrics.avg_cycle_time:.1f} days"
                        "impact": "Slower delivery velocity"
                        "type": "overdue_spike"
                        "severity": "critical"
                        "description": f"{current_metrics.overdue_issues} issues are overdue"
                        "impact": "Schedule adherence compromised"
            logger.exception(f"Error detecting anomalies: {e}"
        """Calculate basic project metrics by orchestrating helper methods."""
            return ProjectHealthMetrics(0, 0, 0, 0, 0, 0.0, "stable"
            issues, status_counts["in_progress"
            completed_issues=status_counts["completed"
            in_progress_issues=status_counts["in_progress"
            blocked_issues=status_counts["blocked"
            overdue_issues=status_counts["overdue"
                status_counts["completed"
            velocity_trend="stable"
        """Counts issues based on their status and labels."""
            [i for i in issues if i.status.lower() in ["done", "completed", "closed"
            [i for i in issues if i.status.lower() in ["in progress", "in review"
                if "blocked"
                or "blocked"
                and i.status.lower() not in ["done", "completed", "closed"
            "completed"
            "in_progress"
            "blocked"
            "overdue"
        """Calculates the average cycle time for completed issues."""
            if i.status.lower() in ["done", "completed", "closed"
        """Calculates team utilization based on assigned in-progress issues."""
        """Calculate quality score based on issue documentation"""
        """Assess project risks"""
                        "high"
                        else "medium"
                    description=f"{metrics.overdue_issues} issues are overdue ({metrics.overdue_issues / metrics.total_issues:.1%} of total)"
                    impact_assessment="Project delivery timeline at risk"
                        "Prioritize overdue issues"
                        "Reassess scope and deadlines"
                        "Add resources to critical path items"
                    severity="medium"
                    description=f"Team utilization at {metrics.team_utilization:.1%}"
                        if i.status.lower() in ["in progress", "todo"
                    impact_assessment="Team burnout and quality degradation risk"
                        "Balance workload across team"
                        "Consider additional resources"
                        "Prioritize critical features"
                    severity="medium"
                    description=f"Quality score below threshold ({metrics.quality_score:.1f})"
                    impact_assessment="Technical debt and maintenance burden increase"
                        "Improve issue documentation"
                        "Implement code review processes"
                        "Add quality gates"
        """Use AI to assess additional project risks"""
                summary = f"Issue: {issue.title}, Status: {issue.status}, Priority: {issue.priority}"
                    summary += f", Description: {issue.description[:200]}"
                risk_prompt = f"""
                """
for risk_data in ai_risks_data.get("risks"
                        risk_type_str = risk_data.get("risk_type", "technical_debt"
                                severity=risk_data.get("severity", "medium"
                                    "description", "AI-identified risk"
                                    "impact", "Potential project impact"
                                    "mitigation", ["Monitor closely"
                    logger.warning("Failed to parse AI risk assessment"
            logger.exception(f"Error in AI risk assessment: {e}"
        """Calculate overall project health score and status"""
            [r for r in risks if r.severity in ["high", "critical"
        """Generate AI-powered project insights"""
                f"Strong project momentum with {metrics.completion_rate:.1%} completion rate"
                f"Project velocity concerns with only {metrics.completion_rate:.1%} completion rate"
                f"{metrics.blocked_issues} blocked issues may impact delivery timeline"
        high_priority_risks = [r for r in risks if r.severity in ["high", "critical"
                f"{len(high_priority_risks)} critical risks require immediate attention"
                insight_prompt = f"""
                """
                    line.strip() for line in ai_insights.split("\n"
            logger.exception(f"Error generating AI insights: {e}"
        """Generate actionable recommendations"""
                "Focus on completing in-progress issues before starting new work"
                "Prioritize overdue issues and reassess their scope and deadlines"
                "Consider redistributing workload to prevent team burnout"
                "Team has capacity for additional work or faster delivery"
            if risk.severity in ["high", "critical"
        """Analyze team performance metrics"""
                    "total_issues"
                    "completed_issues"
                    "in_progress_issues"
                    "overdue_issues"
            stats["total_issues"
if issue.status.lower() in ["done", "completed", "closed"
                stats["completed_issues"
            elif issue.status.lower() in ["in progress", "in review"
                stats["in_progress_issues"
                and issue.status.lower() not in ["done", "completed", "closed"
                stats["overdue_issues"
            if stats["total_issues"
                stats["completion_rate"
                    stats["completed_issues"] / stats["total_issues"
                stats["completion_rate"
            "team_members"
            "individual_performance"
            "top_performers"
                key=lambda x: x[1]["completion_rate"
        """Get historical health reports (placeholder implementation)"""
        """Analyze health trends from historical reports"""
            return {"message": "Insufficient data for trend analysis"
            "health_score_trend"
                "improving" if health_scores[-1] > health_scores[0] else "declining"
            "completion_rate_trend"
                "improving"
                else "declining"
            "average_health_score"
            "health_score_variance"
        """Generate insights from trend analysis"""
if trends.get("health_score_trend") == "improving"
            insights.append("Project health is trending positively"
        elif trends.get("health_score_trend") == "declining"
            insights.append("Project health shows concerning decline"
if trends.get("completion_rate_trend") == "improving"
            insights.append("Team velocity is accelerating"
        """Generate recommendations based on trends"""
if trends.get("health_score_trend") == "declining"
            recommendations.append("Investigate root causes of health decline"
            recommendations.append("Implement corrective measures immediately"
if trends.get("health_score_variance"
                "Project health is volatile - establish more consistent processes"
        """Store health report in AI Memory"""
memory_content = f"""
            """
                category="linear_project_health"
                tags=["linear", "project", "health", "monitoring"
                    "project_id"
                    "project_name"
                    "health_status"
                    "health_score"
                    "total_issues"
                    "completion_rate"
            logger.exception(f"Error storing health report in AI Memory: {e}"