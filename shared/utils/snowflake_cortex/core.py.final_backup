"""Core direct SQL adapter for Snowflake Cortex."""

from backend.services.unified_memory_service_v3 import UnifiedMemoryServiceV3
import asyncio
import json
from typing import Any

from .enums import CortexModel
from .errors import CortexConnectionError, CortexModelError
from .pool import AsyncConnectionPool


class DirectCortexCore:
    """Direct SQL execution for Cortex operations."""

    def __init__(self, connection_pool: AsyncConnectionPool | None = None):
        """Initialize direct Cortex adapter.

        Args:
            connection_pool: Optional connection pool to use
        """
        self._pool = connection_pool
        self._warehouse = None
        self._database = None
        self._schema = None

    def set_context(
        self,
        warehouse: str | None = None,
        database: str | None = None,
        schema: str | None = None,
    ) -> None:
        """Set execution context."""
        if warehouse:
            self._warehouse = warehouse
        if database:
            self._database = database
        if schema:
            self._schema = schema

    async def _execute_query(
        self, query: str, params: dict[str, Any] | None = None
    ) -> list[dict[str, Any]]:
        """Execute a query and return results."""
        if not self._pool:
            raise CortexConnectionError("No connection pool available")

        async with self._pool.connection() as conn:
            loop = asyncio.get_running_loop()

            # Set context if provided
            if self._warehouse or self._database or self._schema:
                context_queries = []
                if self._warehouse:
                    context_queries.append(f"USE WAREHOUSE {self._warehouse}")
                if self._database:
                    context_queries.append(f"USE DATABASE {self._database}")
                if self._schema:
                    context_queries.append(f"USE SCHEMA {self._schema}")

                for ctx_query in context_queries:
                    await loop.run_in_executor(
                        None, lambda: conn.cursor().execute(ctx_query).fetchall()
                    )

            # Execute main query
            cursor = await loop.run_in_executor(
                None, lambda: conn.cursor().execute(query, params)
            )

            # Fetch results
            rows = await loop.run_in_executor(None, cursor.fetchall)
            columns = (
                [desc[0] for desc in cursor.description] if cursor.description else []
            )

            # Convert to list of dicts
            results = []
            for row in rows:
                results.append(dict(zip(columns, row, strict=False)))

            return results

    async def generate_embedding(
        self, text: str, model: str = "e5-base-v2"
    ) -> list[float]:
        """Generate embeddings using Cortex."""
        query = f"""
        SELECT SNOWFLAKE.CORTEX.EMBED_TEXT('{model}', %s) as embedding
        """

        try:
            results = await self._execute_query(query, {"text": text})
            if results and "EMBEDDING" in results[0]:
                # Parse JSON array if returned as string
                embedding = results[0]["EMBEDDING"]
                if isinstance(embedding, str):
                    return json.loads(embedding)
                return embedding
            raise CortexModelError(
                "No embedding returned", model=model, details={"text_length": len(text)}
            )
        except Exception as e:
            raise CortexModelError(
                f"Embedding generation failed: {e}",
                model=model,
                details={"error": str(e)},
            )

    async def complete_text(
        self,
        prompt: str,
        model: CortexModel,
        temperature: float = 0.7,
        max_tokens: int = 1000,
        **kwargs: Any,
    ) -> str:
        """Generate text completion using Cortex."""
        # Build options JSON
        options = {"temperature": temperature, "max_tokens": max_tokens, **kwargs}
        options_json = json.dumps(options)

        query = f"""
        SELECT SNOWFLAKE.await self.lambda_gpu.complete(
            '{model.value}',
            %s,
            '{options_json}'
        ) as completion
        """

        try:
            results = await self._execute_query(query, {"prompt": prompt})
            if results and "COMPLETION" in results[0]:
                return results[0]["COMPLETION"]
            raise CortexModelError(
                "No completion returned",
                model=model.value,
                details={"prompt_length": len(prompt)},
            )
        except Exception as e:
            raise CortexModelError(
                f"Text completion failed: {e}",
                model=model.value,
                details={"error": str(e)},
            )

    async def analyze_sentiment(self, text: str) -> dict[str, Any]:
        """Analyze sentiment using Cortex."""
        query = """
        SELECT SNOWFLAKE.await self.lambda_gpu.analyze_sentiment(%s) as sentiment
        """

        try:
            results = await self._execute_query(query, {"text": text})
            if results and "SENTIMENT" in results[0]:
                sentiment = results[0]["SENTIMENT"]
                if isinstance(sentiment, str):
                    return json.loads(sentiment)
                return sentiment
            return {"sentiment": "neutral", "score": 0.0}
        except Exception as e:
            raise CortexModelError(
                f"Sentiment analysis failed: {e}",
                model="sentiment",
                details={"error": str(e)},
            )

    async def summarize_text(self, text: str, max_length: int = 500) -> str:
        """Summarize text using Cortex."""
        query = """
        SELECT SNOWFLAKE.await self.lambda_gpu.summarize(%s) as summary
        """

        try:
            results = await self._execute_query(query, {"text": text})
            if results and "SUMMARY" in results[0]:
                return results[0]["SUMMARY"]
            return ""
        except Exception as e:
            raise CortexModelError(
                f"Summarization failed: {e}",
                model="summarize",
                details={"error": str(e)},
            )

    async def translate_text(
        self, text: str, from_language: str, to_language: str
    ) -> str:
        """Translate text using Cortex."""
        query = f"""
        SELECT SNOWFLAKE.await self.lambda_gpu.translate(
            %s,
            '{from_language}',
            '{to_language}'
        ) as translation
        """

        try:
            results = await self._execute_query(query, {"text": text})
            if results and "TRANSLATION" in results[0]:
                return results[0]["TRANSLATION"]
            return text
        except Exception as e:
            raise CortexModelError(
                f"Translation failed: {e}",
                model="translate",
                details={"error": str(e), "from": from_language, "to": to_language},
            )

    async def extract_answer(self, question: str, context: str) -> str:
        """Extract answer from context using Cortex."""
        query = """
        SELECT SNOWFLAKE.CORTEX.EXTRACT_ANSWER(%s, %s) as answer
        """

        try:
            results = await self._execute_query(
                query, {"question": question, "context": context}
            )
            if results and "ANSWER" in results[0]:
                return results[0]["ANSWER"]
            return ""
        except Exception as e:
            raise CortexModelError(
                f"Answer extraction failed: {e}",
                model="extract_answer",
                details={"error": str(e)},
            )
