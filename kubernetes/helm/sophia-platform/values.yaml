# Sophia AI Platform - Unified Helm Values
# Optimized for Lambda Labs Kubernetes with GPU support

global:
  # Lambda Labs Configuration
  lambdaLabs:
    cluster: sophia-cloud
    region: us-west
    nodeGroups:
      - name: control-plane
        instance: sophia-production-instance
        ip: 104.171.202.103
        gpu: RTX6000
        role: master
      - name: ai-core
        instance: sophia-ai-core
        ip: 192.222.58.232
        gpu: GH200
        role: worker
      - name: mcp-orchestrator
        instance: sophia-mcp-orchestrator
        ip: 104.171.202.117
        gpu: A6000
        role: worker
      - name: data-pipeline
        instance: sophia-data-pipeline
        ip: 104.171.202.134
        gpu: A100
        role: worker
      - name: development
        instance: sophia-development
        ip: 155.248.194.183
        gpu: A10
        role: worker

  # Docker Registry
  imageRegistry: docker.io/scoobyjava15
  imagePullPolicy: IfNotPresent
  imageTag: latest

  # Security Context (non-root)
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    fsGroup: 1000
    seccompProfile:
      type: RuntimeDefault

  # Environment
  environment: production
  logLevel: INFO

  # Domain Configuration
  domain: sophia-ai.lambda-labs.cloud
  tls:
    enabled: true
    issuer: letsencrypt-prod

# Core Services
sophiaBackend:
  enabled: true
  name: sophia-backend
  replicaCount: 3
  image:
    repository: sophia-backend
    tag: latest
  service:
    type: ClusterIP
    port: 8000
  ingress:
    enabled: true
    host: api.sophia-ai.lambda-labs.cloud
  resources:
    requests:
      memory: "2Gi"
      cpu: "1000m"
    limits:
      memory: "4Gi"
      cpu: "2000m"
  nodeSelector:
    gpu-type: RTX6000
  env:
    ENVIRONMENT: prod
    PULUMI_ORG: scoobyjava-org
    REDIS_URL: redis://redis:6379
    POSTGRES_URL: postgresql://sophia:$(POSTGRES_PASSWORD)@postgres:5432/sophia

sophiaFrontend:
  enabled: true
  name: sophia-frontend
  replicaCount: 2
  image:
    repository: sophia-frontend
    tag: latest
  service:
    type: ClusterIP
    port: 3000
  ingress:
    enabled: true
    host: sophia-ai.lambda-labs.cloud
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# LLM Gateway Configuration (Portkey + OpenRouter)
llmGateway:
  enabled: true
  name: llm-gateway
  provider: portkey
  portkey:
    endpoint: https://api.portkey.ai/v1
    configPath: /config/portkey-config.json
  openrouter:
    endpoint: https://openrouter.ai/api/v1
    defaultModel: gpt-4o
    models:
      - name: gpt-4o
        provider: openai
        costPer1kTokens: 0.015
      - name: claude-3-5-sonnet-20241022
        provider: anthropic
        costPer1kTokens: 0.003
      - name: deepseek-v3
        provider: deepseek
        costPer1kTokens: 0.001
      - name: gemini-2.0-flash-exp
        provider: google
        costPer1kTokens: 0.0001
      - name: llama-3.1-70b
        provider: meta
        costPer1kTokens: 0.0008
  routing:
    codeGeneration: claude-3-5-sonnet-20241022
    analysis: gpt-4o
    bulkProcessing: deepseek-v3
    creative: gemini-2.0-flash-exp
    costOptimized: llama-3.1-70b

# MCP Servers Configuration
mcpServers:
  # AI Memory Server (Primary)
  aiMemory:
    enabled: true
    name: ai-memory
    port: 9000
    tier: PRIMARY
    image:
      repository: sophia-mcp-ai-memory
      tag: v2.1.0
    resources:
      requests:
        memory: "4Gi"
        cpu: "2000m"
      limits:
        memory: "8Gi"
        cpu: "4000m"
    nodeSelector:
      gpu-type: GH200
    gpuRequired: true
    gpuCount: 1

  # Snowflake Cortex
  snowflakeCortex:
    enabled: true
    name: snowflake-cortex
    port: 9001
    tier: PRIMARY
    resources:
      requests:
        memory: "4Gi"
        cpu: "2000m"
        nvidia.com/gpu: 1
      limits:
        memory: "8Gi"
        cpu: "4000m"
        nvidia.com/gpu: 1
    nodeSelector:
      gpu-type: A100

  # Gong Integration
  gong:
    enabled: true
    name: gong
    port: 9002
    tier: PRIMARY
    nodeSelector:
      gpu-type: A6000

  # HubSpot Integration
  hubspot:
    enabled: true
    name: hubspot
    port: 9003
    tier: PRIMARY
    nodeSelector:
      gpu-type: A6000

  # Slack Integration
  slack:
    enabled: true
    name: slack
    port: 9004
    tier: PRIMARY
    nodeSelector:
      gpu-type: A6000

  # GitHub Integration
  github:
    enabled: true
    name: github
    port: 9005
    tier: SECONDARY
    nodeSelector:
      gpu-type: A6000

  # Linear Integration
  linear:
    enabled: true
    name: linear
    port: 9006
    tier: SECONDARY
    nodeSelector:
      gpu-type: A6000

  # Codacy Integration
  codacy:
    enabled: true
    name: codacy
    port: 3008
    tier: SECONDARY
    nodeSelector:
      gpu-type: A10

# Data Services
postgresql:
  enabled: true
  auth:
    postgresPassword: changeme
    database: sophia_ai
  primary:
    persistence:
      enabled: true
      size: 100Gi
      storageClass: fast-ssd
  metrics:
    enabled: true

redis:
  enabled: true
  auth:
    enabled: true
    password: changeme
  master:
    persistence:
      enabled: true
      size: 10Gi
  replica:
    replicaCount: 2
    persistence:
      enabled: true
      size: 10Gi

# Monitoring Stack
monitoring:
  prometheus:
    enabled: true
    serverFiles:
      prometheus.yml:
        scrape_configs:
          - job_name: 'kubernetes-pods'
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: true
    nodeSelector:
      gpu-type: A10

  grafana:
    enabled: true
    adminPassword: changeme
    dashboards:
      default:
        sophia-overview:
          url: https://grafana.com/api/dashboards/12345
        gpu-monitoring:
          url: https://grafana.com/api/dashboards/12114
    nodeSelector:
      gpu-type: A10

# Ingress Configuration
ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/proxy-body-size: "100m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
  tls:
    enabled: true

# GPU Configuration
gpu:
  nvidia:
    enabled: true
    devicePlugin:
      enabled: true
    dcgmExporter:
      enabled: true
      port: 9400

# Autoscaling
autoscaling:
  enabled: true
  hpa:
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
  vpa:
    enabled: true
    updateMode: Auto

# Network Policies
networkPolicies:
  enabled: true
  policyTypes:
    - Ingress
    - Egress
  defaultDeny: false

# PodDisruptionBudgets
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# Service Mesh (optional)
serviceMesh:
  enabled: false
  provider: istio  # or linkerd

# Backup Configuration
backup:
  enabled: true
  schedule: "0 2 * * *"  # 2 AM daily
  retention: 30  # days
  storageLocation: s3://sophia-backups/

# Cost Optimization
costOptimization:
  enabled: true
  spotInstances:
    enabled: false  # Lambda Labs doesn't support spot
  resourceQuotas:
    enabled: true
    limits:
      requests.cpu: "100"
      requests.memory: "200Gi"
      requests.nvidia.com/gpu: "10"

# Security Policies
security:
  podSecurityPolicy:
    enabled: true
  networkSegmentation:
    enabled: true
  secrets:
    provider: pulumi-esc
    autoRotation: true
    rotationDays: 90 