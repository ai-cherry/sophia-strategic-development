#!/usr/bin/env python3
"""
Enhanced MCP Orchestration Service
==================================

Centralized orchestration system for all MCP servers in the Sophia AI platform.
Provides intelligent task distribution, health monitoring, and performance optimization.
"""

"""
File Decomposition Plan (auto-generated by Phase 3)
Current size: 732 lines

Recommended decomposition:
- enhanced_mcp_orchestration_service_core.py - Core functionality
- enhanced_mcp_orchestration_service_utils.py - Utility functions
- enhanced_mcp_orchestration_service_models.py - Data models
- enhanced_mcp_orchestration_service_handlers.py - Request handlers

TODO: Implement file decomposition
"""

import asyncio
import logging
import time
from dataclasses import dataclass
from datetime import UTC, datetime
from enum import Enum
from typing import Any

from prometheus_client import Counter, Gauge, Histogram

from backend.services.mcp_orchestration_service import (
    BusinessTask,
    MCPOrchestrationService,
    OrchestrationResult,
    TaskPriority,
)

logger = logging.getLogger(__name__)


class ServerGroup(Enum):
    """MCP Server groups for intelligent routing"""

    CORE_AI = "core_ai"
    BUSINESS_INTELLIGENCE = "business_intelligence"
    DATA_INFRASTRUCTURE = "data_infrastructure"
    INTEGRATIONS = "integrations"
    QUALITY_SECURITY = "quality_security"


@dataclass
class ServerPerformanceMetrics:
    """Performance metrics for an MCP server"""

    server_name: str
    avg_response_time_ms: float
    success_rate: float
    requests_per_minute: float
    last_failure_time: datetime | None = None
    consecutive_failures: int = 0
    health_score: float = 100.0


@dataclass
class OrchestrationPolicy:
    """Policy for orchestrating tasks across servers"""

    name: str
    description: str
    server_groups: list[ServerGroup]
    execution_mode: str  # "parallel", "sequential", "failover"
    timeout_seconds: int = 300
    retry_count: int = 3
    cache_results: bool = True
    priority_boost: int = 0


class EnhancedMCPOrchestrationService(MCPOrchestrationService):
    """
    Enhanced orchestration service with performance optimization,
    intelligent routing, and comprehensive monitoring.
    """

    def __init__(self):
        super().__init__()

        # Performance tracking
        self.performance_metrics: dict[str, ServerPerformanceMetrics] = {}
        self.orchestration_policies: dict[str, OrchestrationPolicy] = {}

        # Enhanced metrics
        self.metrics_enhanced = self._initialize_enhanced_metrics()

        # Server groups
        self.server_groups = self._initialize_server_groups()

        # Cache for orchestration results
        self.result_cache: dict[str, OrchestrationResult] = {}
        self.cache_timestamps: dict[str, float] = {}

        # Initialize policies
        self._initialize_orchestration_policies()

    def _initialize_enhanced_metrics(self):
        """Initialize enhanced Prometheus metrics"""
        return {
            "orchestration_latency": Histogram(
                "mcp_orchestration_latency_seconds",
                "Orchestration latency by task type",
                ["task_type"],
            ),
            "server_utilization": Gauge(
                "mcp_server_utilization_percent",
                "Server utilization percentage",
                ["server_name"],
            ),
            "cache_efficiency": Gauge(
                "mcp_cache_efficiency_percent",
                "Cache hit rate for orchestration results",
            ),
            "policy_executions": Counter(
                "mcp_policy_executions_total",
                "Total policy executions",
                ["policy_name", "status"],
            ),
            "intelligent_routing": Counter(
                "mcp_intelligent_routing_total",
                "Intelligent routing decisions",
                ["from_server", "to_server", "reason"],
            ),
        }

    def _initialize_server_groups(self) -> dict[ServerGroup, list[str]]:
        """Initialize server groups for intelligent routing"""
        return {
            ServerGroup.CORE_AI: [
                "ai_memory",
                "enhanced_ai_memory",
                "sophia_ai_orchestrator",
                "code_intelligence",
            ],
            ServerGroup.BUSINESS_INTELLIGENCE: [
                "business_intelligence",
                "portkey_admin_official",
                "openrouter_search_official",
                "hubspot",
                "gong",
            ],
            ServerGroup.DATA_INFRASTRUCTURE: [
                "snowflake",
                "snowflake_cortex",
                "snowflake_admin",
                "postgres",
                "redis",
            ],
            ServerGroup.INTEGRATIONS: ["slack", "linear", "notion", "github", "asana"],
            ServerGroup.QUALITY_SECURITY: ["codacy", "bright_data", "apollo"],
        }

    def _initialize_orchestration_policies(self):
        """Initialize intelligent orchestration policies"""
        policies = [
            OrchestrationPolicy(
                name="executive_intelligence",
                description="High-priority executive queries with parallel execution",
                server_groups=[ServerGroup.BUSINESS_INTELLIGENCE, ServerGroup.CORE_AI],
                execution_mode="parallel",
                timeout_seconds=60,
                priority_boost=10,
            ),
            OrchestrationPolicy(
                name="data_pipeline",
                description="Sequential data processing pipeline",
                server_groups=[ServerGroup.DATA_INFRASTRUCTURE],
                execution_mode="sequential",
                timeout_seconds=600,
                cache_results=False,
            ),
            OrchestrationPolicy(
                name="code_quality",
                description="Code analysis with failover support",
                server_groups=[ServerGroup.QUALITY_SECURITY],
                execution_mode="failover",
                timeout_seconds=120,
                retry_count=2,
            ),
            OrchestrationPolicy(
                name="integration_sync",
                description="Synchronize data across integrations",
                server_groups=[ServerGroup.INTEGRATIONS],
                execution_mode="parallel",
                timeout_seconds=300,
                cache_results=True,
            ),
            OrchestrationPolicy(
                name="ai_synthesis",
                description="AI-powered synthesis across all data sources",
                server_groups=[
                    ServerGroup.CORE_AI,
                    ServerGroup.BUSINESS_INTELLIGENCE,
                    ServerGroup.DATA_INFRASTRUCTURE,
                ],
                execution_mode="parallel",
                timeout_seconds=180,
                priority_boost=5,
            ),
        ]

        for policy in policies:
            self.orchestration_policies[policy.name] = policy

    async def start_all_servers(self) -> dict[str, Any]:
        """Start all MCP servers with health monitoring"""
        logger.info("ðŸš€ Starting all MCP servers with enhanced orchestration...")

        start_results = {
            "started": [],
            "failed": [],
            "already_running": [],
            "total_time_ms": 0,
        }

        start_time = time.time()

        # Group servers by priority
        priority_groups = {
            "critical": ["ai_memory", "snowflake", "snowflake_cortex"],
            "high": ["business_intelligence", "hubspot", "gong", "slack"],
            "medium": ["linear", "notion", "asana", "github"],
            "low": ["codacy", "bright_data", "apollo"],
        }

        # Start servers by priority
        for priority, servers in priority_groups.items():
            logger.info(f"Starting {priority} priority servers...")

            tasks = []
            for server_name in servers:
                if server_name in self.servers:
                    tasks.append(self._start_and_monitor_server(server_name))

            results = await asyncio.gather(*tasks, return_exceptions=True)

            for i, result in enumerate(results):
                server_name = servers[i] if i < len(servers) else "unknown"

                if isinstance(result, Exception):
                    start_results["failed"].append(
                        {"server": server_name, "error": str(result)}
                    )
                elif result == "already_running":
                    start_results["already_running"].append(server_name)
                else:
                    start_results["started"].append(server_name)

        # Update metrics
        total_servers = len(self.servers)
        started_count = len(start_results["started"]) + len(
            start_results["already_running"]
        )

        if self.metrics:
            self.metrics.health_status.set(started_count / max(total_servers, 1))

        start_results["total_time_ms"] = (time.time() - start_time) * 1000
        start_results["success_rate"] = (started_count / max(total_servers, 1)) * 100

        logger.info(
            f"âœ… Server startup complete: {started_count}/{total_servers} servers running"
        )

        return start_results

    async def _start_and_monitor_server(self, server_name: str) -> str:
        """Start a server and monitor its health"""
        try:
            # Check if already running
            if await self._check_server_health(server_name):
                return "already_running"

            # Start the server
            success = await self._start_mcp_server(server_name)

            if success:
                # Initialize performance metrics
                self.performance_metrics[server_name] = ServerPerformanceMetrics(
                    server_name=server_name,
                    avg_response_time_ms=0,
                    success_rate=100.0,
                    requests_per_minute=0,
                )

                return "started"
            else:
                return "failed"

        except Exception as e:
            logger.error(f"Failed to start {server_name}: {e}")
            raise

    async def execute_with_policy(
        self, task: BusinessTask, policy_name: str
    ) -> OrchestrationResult:
        """Execute a task using a specific orchestration policy"""
        start_time = time.time()

        # Check cache first
        cache_key = f"{policy_name}:{task.task_id}:{hash(str(task.context_data))}"
        cached_result = self._get_cached_result(cache_key)
        if cached_result:
            logger.info(f"Cache hit for task {task.task_id}")
            if self.metrics_enhanced:
                self.metrics_enhanced["cache_efficiency"].set(
                    self._calculate_cache_efficiency()
                )
            return cached_result

        # Get policy
        policy = self.orchestration_policies.get(policy_name)
        if not policy:
            return OrchestrationResult(
                task_id=task.task_id,
                success=False,
                results={},
                execution_time_ms=0,
                servers_used=[],
                error_message=f"Unknown policy: {policy_name}",
            )

        # Apply priority boost
        task.priority = TaskPriority(
            min(
                TaskPriority.CRITICAL.value, task.priority.value + policy.priority_boost
            )
        )

        # Get relevant servers
        relevant_servers = self._get_servers_for_groups(policy.server_groups)

        # Execute based on policy mode
        try:
            if policy.execution_mode == "parallel":
                results = await self._execute_parallel_with_monitoring(
                    relevant_servers, task, policy
                )
            elif policy.execution_mode == "sequential":
                results = await self._execute_sequential_with_monitoring(
                    relevant_servers, task, policy
                )
            elif policy.execution_mode == "failover":
                results = await self._execute_failover_with_monitoring(
                    relevant_servers, task, policy
                )
            else:
                raise ValueError(f"Unknown execution mode: {policy.execution_mode}")

            # Create orchestration result
            execution_time = (time.time() - start_time) * 1000

            result = OrchestrationResult(
                task_id=task.task_id,
                success=True,
                results=results,
                execution_time_ms=execution_time,
                servers_used=list(results.keys()),
                synthesis_applied=task.requires_synthesis,
                metadata={"policy": policy_name, "cache_key": cache_key},
            )

            # Cache result if policy allows
            if policy.cache_results:
                self._cache_result(cache_key, result)

            # Update metrics
            if self.metrics_enhanced:
                self.metrics_enhanced["orchestration_latency"].labels(
                    task_type=task.task_type
                ).observe(execution_time / 1000)

                self.metrics_enhanced["policy_executions"].labels(
                    policy_name=policy_name, status="success"
                ).inc()

            return result

        except Exception as e:
            logger.error(f"Policy execution failed: {e}")

            if self.metrics_enhanced:
                self.metrics_enhanced["policy_executions"].labels(
                    policy_name=policy_name, status="failure"
                ).inc()

            return OrchestrationResult(
                task_id=task.task_id,
                success=False,
                results={},
                execution_time_ms=(time.time() - start_time) * 1000,
                servers_used=[],
                error_message=str(e),
            )

    def _get_servers_for_groups(self, groups: list[ServerGroup]) -> dict[str, Any]:
        """Get servers belonging to specified groups"""
        relevant_servers = {}

        for group in groups:
            server_names = self.server_groups.get(group, [])
            for server_name in server_names:
                if server_name in self.servers:
                    relevant_servers[server_name] = self.servers[server_name]

        return relevant_servers

    async def _execute_parallel_with_monitoring(
        self, servers: dict[str, Any], task: BusinessTask, policy: OrchestrationPolicy
    ) -> dict[str, Any]:
        """Execute task in parallel with performance monitoring"""
        tasks = []

        for server_name, server in servers.items():
            # Check server health and performance
            if self._should_use_server(server_name):
                tasks.append(
                    self._execute_with_timeout(
                        server_name, server, task, policy.timeout_seconds
                    )
                )

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Process results
        processed_results = {}
        for i, result in enumerate(results):
            server_name = list(servers.keys())[i]

            if isinstance(result, Exception):
                logger.error(f"Server {server_name} failed: {result}")
                self._update_server_metrics(server_name, success=False)
            else:
                processed_results[server_name] = result
                self._update_server_metrics(server_name, success=True)

        return processed_results

    async def _execute_sequential_with_monitoring(
        self, servers: dict[str, Any], task: BusinessTask, policy: OrchestrationPolicy
    ) -> dict[str, Any]:
        """Execute task sequentially with monitoring"""
        results = {}

        for server_name, server in servers.items():
            if not self._should_use_server(server_name):
                continue

            try:
                result = await self._execute_with_timeout(
                    server_name, server, task, policy.timeout_seconds
                )
                results[server_name] = result
                self._update_server_metrics(server_name, success=True)

                # Pass result to next server in context
                task.context_data[f"{server_name}_result"] = result

            except Exception as e:
                logger.error(f"Sequential execution failed at {server_name}: {e}")
                self._update_server_metrics(server_name, success=False)

                if policy.retry_count > 0:
                    # Retry logic
                    for retry in range(policy.retry_count):
                        try:
                            result = await self._execute_with_timeout(
                                server_name, server, task, policy.timeout_seconds
                            )
                            results[server_name] = result
                            self._update_server_metrics(server_name, success=True)
                            break
                        except Exception:
                            if retry == policy.retry_count - 1:
                                raise

        return results

    async def _execute_failover_with_monitoring(
        self, servers: dict[str, Any], task: BusinessTask, policy: OrchestrationPolicy
    ) -> dict[str, Any]:
        """Execute task with failover support"""
        # Sort servers by health score
        sorted_servers = sorted(
            servers.items(),
            key=lambda x: self._get_server_health_score(x[0]),
            reverse=True,
        )

        for server_name, server in sorted_servers:
            try:
                result = await self._execute_with_timeout(
                    server_name, server, task, policy.timeout_seconds
                )

                self._update_server_metrics(server_name, success=True)

                # Log intelligent routing decision
                if self.metrics_enhanced and server_name != sorted_servers[0][0]:
                    self.metrics_enhanced["intelligent_routing"].labels(
                        from_server=sorted_servers[0][0],
                        to_server=server_name,
                        reason="failover",
                    ).inc()

                return {server_name: result}

            except Exception as e:
                logger.warning(f"Server {server_name} failed, trying next: {e}")
                self._update_server_metrics(server_name, success=False)
                continue

        raise RuntimeError("All servers failed in failover execution")

    async def _execute_with_timeout(
        self, server_name: str, server: Any, task: BusinessTask, timeout: int
    ) -> Any:
        """Execute task with timeout"""
        try:
            return await asyncio.wait_for(
                self._execute_on_server(server_name, server, task), timeout=timeout
            )
        except TimeoutError:
            raise TimeoutError(f"Server {server_name} timed out after {timeout}s")

    def _should_use_server(self, server_name: str) -> bool:
        """Determine if server should be used based on health"""
        metrics = self.performance_metrics.get(server_name)
        if not metrics:
            return True  # Use by default if no metrics

        # Don't use if too many consecutive failures
        if metrics.consecutive_failures > 3:
            return False

        # Don't use if health score too low
        if metrics.health_score < 50:
            return False

        return True

    def _get_server_health_score(self, server_name: str) -> float:
        """Get health score for a server"""
        metrics = self.performance_metrics.get(server_name)
        return metrics.health_score if metrics else 75.0  # Default score

    def _update_server_metrics(
        self, server_name: str, success: bool, response_time_ms: float = 0
    ):
        """Update server performance metrics"""
        if server_name not in self.performance_metrics:
            self.performance_metrics[server_name] = ServerPerformanceMetrics(
                server_name=server_name,
                avg_response_time_ms=0,
                success_rate=100.0,
                requests_per_minute=0,
            )

        metrics = self.performance_metrics[server_name]

        if success:
            metrics.consecutive_failures = 0
            # Update rolling average response time
            metrics.avg_response_time_ms = (
                metrics.avg_response_time_ms * 0.9 + response_time_ms * 0.1
            )
        else:
            metrics.consecutive_failures += 1
            metrics.last_failure_time = datetime.now(UTC)

        # Update success rate (rolling average)
        current_rate = 100.0 if success else 0.0
        metrics.success_rate = metrics.success_rate * 0.95 + current_rate * 0.05

        # Calculate health score
        metrics.health_score = self._calculate_health_score(metrics)

        # Update Prometheus metrics
        if self.metrics_enhanced:
            self.metrics_enhanced["server_utilization"].labels(
                server_name=server_name
            ).set(
                100 - metrics.health_score
            )  # Inverse for utilization

    def _calculate_health_score(self, metrics: ServerPerformanceMetrics) -> float:
        """Calculate health score for a server"""
        score = 100.0

        # Penalize for low success rate
        score *= metrics.success_rate / 100.0

        # Penalize for consecutive failures
        score *= 1.0 - min(metrics.consecutive_failures * 0.1, 0.5)

        # Penalize for slow response times
        if metrics.avg_response_time_ms > 1000:
            score *= 0.8
        elif metrics.avg_response_time_ms > 500:
            score *= 0.9

        return max(0.0, min(100.0, score))

    def _get_cached_result(self, cache_key: str) -> OrchestrationResult | None:
        """Get cached orchestration result"""
        if cache_key in self.result_cache:
            # Check if cache is still valid (5 minutes)
            if time.time() - self.cache_timestamps[cache_key] < 300:
                return self.result_cache[cache_key]
            else:
                # Expired
                del self.result_cache[cache_key]
                del self.cache_timestamps[cache_key]

        return None

    def _cache_result(self, cache_key: str, result: OrchestrationResult):
        """Cache orchestration result"""
        self.result_cache[cache_key] = result
        self.cache_timestamps[cache_key] = time.time()

        # Limit cache size
        if len(self.result_cache) > 1000:
            # Remove oldest entries
            oldest_keys = sorted(
                self.cache_timestamps.keys(), key=lambda k: self.cache_timestamps[k]
            )[:100]

            for key in oldest_keys:
                del self.result_cache[key]
                del self.cache_timestamps[key]

    def _calculate_cache_efficiency(self) -> float:
        """Calculate cache hit rate"""
        # This would need actual tracking of hits/misses
        # For now, return estimate based on cache size
        if not self.result_cache:
            return 0.0

        return min(len(self.result_cache) / 10.0, 100.0)

    async def get_performance_dashboard(self) -> dict[str, Any]:
        """Get comprehensive performance dashboard"""
        dashboard = {
            "timestamp": datetime.now(UTC).isoformat(),
            "overall_health": self._calculate_overall_health(),
            "server_groups": {},
            "performance_metrics": {},
            "orchestration_policies": {},
            "recommendations": [],
        }

        # Server group health
        for group in ServerGroup:
            servers_in_group = self.server_groups.get(group, [])
            group_health = []

            for server in servers_in_group:
                if server in self.performance_metrics:
                    metrics = self.performance_metrics[server]
                    group_health.append(metrics.health_score)

            dashboard["server_groups"][group.value] = {
                "servers": servers_in_group,
                "average_health": (
                    sum(group_health) / len(group_health) if group_health else 0
                ),
                "operational_count": len(group_health),
            }

        # Individual server metrics
        for server_name, metrics in self.performance_metrics.items():
            dashboard["performance_metrics"][server_name] = {
                "health_score": metrics.health_score,
                "avg_response_time_ms": metrics.avg_response_time_ms,
                "success_rate": metrics.success_rate,
                "consecutive_failures": metrics.consecutive_failures,
                "last_failure": (
                    metrics.last_failure_time.isoformat()
                    if metrics.last_failure_time
                    else None
                ),
            }

        # Policy execution stats
        for policy_name, policy in self.orchestration_policies.items():
            dashboard["orchestration_policies"][policy_name] = {
                "description": policy.description,
                "execution_mode": policy.execution_mode,
                "timeout_seconds": policy.timeout_seconds,
            }

        # Generate recommendations
        dashboard["recommendations"] = self._generate_performance_recommendations()

        return dashboard

    def _generate_performance_recommendations(self) -> list[str]:
        """Generate performance optimization recommendations"""
        recommendations = []

        # Check for unhealthy servers
        for server_name, metrics in self.performance_metrics.items():
            if metrics.health_score < 70:
                recommendations.append(
                    f"Consider restarting {server_name} (health: {metrics.health_score:.1f}%)"
                )

            if metrics.avg_response_time_ms > 1000:
                recommendations.append(
                    f"Optimize {server_name} performance (avg response: {metrics.avg_response_time_ms:.0f}ms)"
                )

        # Check cache efficiency
        cache_efficiency = self._calculate_cache_efficiency()
        if cache_efficiency < 50:
            recommendations.append(
                f"Consider increasing cache size (current efficiency: {cache_efficiency:.1f}%)"
            )

        # Check server group balance
        for group in ServerGroup:
            servers_in_group = self.server_groups.get(group, [])
            operational_count = sum(
                1
                for s in servers_in_group
                if s in self.performance_metrics
                and self.performance_metrics[s].health_score > 50
            )

            if operational_count < len(servers_in_group) * 0.5:
                recommendations.append(
                    f"Critical: Less than 50% of {group.value} servers are healthy"
                )

        return recommendations
