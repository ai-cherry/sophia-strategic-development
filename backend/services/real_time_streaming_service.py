#!/usr/bin/env python3
"""
Real-Time Streaming Service
HIGH PRIORITY: Implements Snowflake Streams and WebSocket updates
Addresses: Real-time processing gap identified in observations
"""

"""
File Decomposition Plan (auto-generated by Phase 3)
Current size: 719 lines

Recommended decomposition:
- real_time_streaming_service_core.py - Core functionality
- real_time_streaming_service_utils.py - Utility functions
- real_time_streaming_service_models.py - Data models
- real_time_streaming_service_handlers.py - Request handlers

TODO: Implement file decomposition
"""

import asyncio
import json
import logging
from dataclasses import dataclass
from datetime import datetime, timedelta
from enum import Enum
from typing import Any

import snowflake.connector
import websockets
from snowflake.connector import DictCursor
from websockets.server import WebSocketServerProtocol

logger = logging.getLogger(__name__)


class StreamType(str, Enum):
    KNOWLEDGE_UPDATE = "knowledge_update"
    USER_ACTIVITY = "user_activity"
    SYSTEM_METRIC = "system_metric"
    CONVERSATION = "conversation"
    ANALYTICS = "analytics"
    SEARCH = "search"


class EventType(str, Enum):
    INSERT = "INSERT"
    UPDATE = "UPDATE"
    DELETE = "DELETE"


@dataclass
class StreamEvent:
    """Real-time stream event structure"""

    stream_id: str
    event_type: EventType
    table_name: str
    schema_name: str
    record_id: str
    data: dict[str, Any]
    timestamp: datetime
    metadata: dict[str, Any] = None


@dataclass
class WebSocketClient:
    """WebSocket client tracking"""

    client_id: str
    websocket: WebSocketServerProtocol
    user_id: str
    subscriptions: set[str]
    connected_at: datetime
    last_activity: datetime


class RealTimeStreamingService:
    """
    Real-Time Streaming Service with Snowflake Streams and WebSocket updates
    Addresses high priority requirement for real-time processing
    """

    def __init__(self, snowflake_config: dict[str, str], websocket_port: int = 8765):
        self.snowflake_config = snowflake_config
        self.websocket_port = websocket_port
        self.connection = None

        # WebSocket management
        self.websocket_clients: dict[str, WebSocketClient] = {}
        self.websocket_server = None

        # Stream management
        self.active_streams: dict[str, dict[str, Any]] = {}
        self.stream_processors: dict[StreamType, list] = {}

        # Event queues for processing
        self.event_queue = asyncio.Queue()
        self.notification_queue = asyncio.Queue()

        # Performance monitoring
        self.performance_metrics = {
            "events_processed": 0,
            "websocket_messages_sent": 0,
            "stream_lag_seconds": {},
            "error_count": 0,
            "average_processing_time_ms": 0.0,
        }

        logger.info("✅ Real-Time Streaming Service initialized")

    async def initialize(self):
        """Initialize Snowflake connection and WebSocket server"""
        try:
            # Connect to Snowflake
            await self._connect_snowflake()

            # Create or verify streams
            await self._setup_snowflake_streams()

            # Start WebSocket server
            await self._start_websocket_server()

            # Start background processors
            asyncio.create_task(self._stream_processor())
            asyncio.create_task(self._event_processor())
            asyncio.create_task(self._notification_processor())
            asyncio.create_task(self._health_monitor())

            logger.info("✅ Real-Time Streaming Service fully initialized")

        except Exception as e:
            logger.error(f"❌ Failed to initialize streaming service: {e}")
            raise

    async def _connect_snowflake(self):
        """Connect to Snowflake for stream management"""
        try:
            self.connection = snowflake.connector.connect(**self.snowflake_config)
            logger.info("✅ Connected to Snowflake for streaming")
        except Exception as e:
            logger.error(f"❌ Snowflake connection failed: {e}")
            raise

    async def _setup_snowflake_streams(self):
        """Create and manage Snowflake streams for real-time processing"""
        cursor = self.connection.cursor()

        try:
            # Knowledge Base Updates Stream
            cursor.execute(
                """
            CREATE STREAM IF NOT EXISTS KNOWLEDGE_UPDATES_STREAM
            ON TABLE UNIVERSAL_CHAT.KNOWLEDGE_BASE_ENTRIES
            COMMENT = 'Real-time stream for knowledge base changes'
            """
            )

            # Conversation Updates Stream
            cursor.execute(
                """
            CREATE STREAM IF NOT EXISTS CONVERSATION_UPDATES_STREAM
            ON TABLE UNIVERSAL_CHAT.CONVERSATION_MESSAGES
            COMMENT = 'Real-time stream for conversation changes'
            """
            )

            # System Analytics Stream
            cursor.execute(
                """
            CREATE STREAM IF NOT EXISTS SYSTEM_ANALYTICS_STREAM
            ON TABLE UNIVERSAL_CHAT.SYSTEM_ANALYTICS
            COMMENT = 'Real-time stream for system metrics'
            """
            )

            # User Activity Stream
            cursor.execute(
                """
            CREATE STREAM IF NOT EXISTS USER_ACTIVITY_STREAM
            ON TABLE UNIVERSAL_CHAT.KNOWLEDGE_USAGE_ANALYTICS
            COMMENT = 'Real-time stream for user activity'
            """
            )

            # Ingestion Jobs Stream (for our new table)
            cursor.execute(
                """
            CREATE STREAM IF NOT EXISTS INGESTION_JOBS_STREAM
            ON TABLE UNIVERSAL_CHAT.INGESTION_JOBS
            COMMENT = 'Real-time stream for ingestion job status'
            """
            )

            # Search Analytics Stream
            cursor.execute(
                """
            CREATE STREAM IF NOT EXISTS SEARCH_ANALYTICS_STREAM
            ON TABLE UNIVERSAL_CHAT.SEARCH_ANALYTICS
            COMMENT = 'Real-time stream for search analytics'
            """
            )

            cursor.close()

            # Register active streams
            self.active_streams = {
                "knowledge_updates": {
                    "stream_name": "KNOWLEDGE_UPDATES_STREAM",
                    "table_name": "KNOWLEDGE_BASE_ENTRIES",
                    "schema_name": "UNIVERSAL_CHAT",
                    "type": StreamType.KNOWLEDGE_UPDATE,
                    "last_processed": datetime.now(),
                },
                "conversation_updates": {
                    "stream_name": "CONVERSATION_UPDATES_STREAM",
                    "table_name": "CONVERSATION_MESSAGES",
                    "schema_name": "UNIVERSAL_CHAT",
                    "type": StreamType.CONVERSATION,
                    "last_processed": datetime.now(),
                },
                "system_analytics": {
                    "stream_name": "SYSTEM_ANALYTICS_STREAM",
                    "table_name": "SYSTEM_ANALYTICS",
                    "schema_name": "UNIVERSAL_CHAT",
                    "type": StreamType.SYSTEM_METRIC,
                    "last_processed": datetime.now(),
                },
                "user_activity": {
                    "stream_name": "USER_ACTIVITY_STREAM",
                    "table_name": "KNOWLEDGE_USAGE_ANALYTICS",
                    "schema_name": "UNIVERSAL_CHAT",
                    "type": StreamType.USER_ACTIVITY,
                    "last_processed": datetime.now(),
                },
                "ingestion_jobs": {
                    "stream_name": "INGESTION_JOBS_STREAM",
                    "table_name": "INGESTION_JOBS",
                    "schema_name": "UNIVERSAL_CHAT",
                    "type": StreamType.ANALYTICS,
                    "last_processed": datetime.now(),
                },
                "search_analytics": {
                    "stream_name": "SEARCH_ANALYTICS_STREAM",
                    "table_name": "SEARCH_ANALYTICS",
                    "schema_name": "UNIVERSAL_CHAT",
                    "type": StreamType.SEARCH,
                    "last_processed": datetime.now(),
                },
            }

            logger.info(f"✅ Created {len(self.active_streams)} Snowflake streams")

        except Exception as e:
            logger.error(f"❌ Failed to setup Snowflake streams: {e}")
            raise

    async def _start_websocket_server(self):
        """Start WebSocket server for real-time client connections"""
        try:
            self.websocket_server = await websockets.serve(
                self._handle_websocket_connection, "localhost", self.websocket_port
            )
            logger.info(f"✅ WebSocket server started on port {self.websocket_port}")
        except Exception as e:
            logger.error(f"❌ Failed to start WebSocket server: {e}")
            raise

    async def _handle_websocket_connection(
        self, websocket: WebSocketServerProtocol, path: str
    ):
        """Handle new WebSocket client connections"""
        client_id = None
        try:
            # Wait for client authentication message
            auth_message = await asyncio.wait_for(websocket.recv(), timeout=30.0)
            auth_data = json.loads(auth_message)

            client_id = auth_data.get("client_id")
            user_id = auth_data.get("user_id")
            subscriptions = set(auth_data.get("subscriptions", []))

            if not client_id or not user_id:
                await websocket.send(
                    json.dumps(
                        {
                            "type": "error",
                            "message": "Authentication required: client_id and user_id",
                        }
                    )
                )
                return

            # Register client
            client = WebSocketClient(
                client_id=client_id,
                websocket=websocket,
                user_id=user_id,
                subscriptions=subscriptions,
                connected_at=datetime.now(),
                last_activity=datetime.now(),
            )

            self.websocket_clients[client_id] = client

            # Send confirmation
            await websocket.send(
                json.dumps(
                    {
                        "type": "connection_established",
                        "client_id": client_id,
                        "subscriptions": list(subscriptions),
                        "server_time": datetime.now().isoformat(),
                    }
                )
            )

            logger.info(f"✅ WebSocket client connected: {client_id} (user: {user_id})")

            # Handle ongoing messages
            async for message in websocket:
                await self._handle_websocket_message(client, message)

        except websockets.exceptions.ConnectionClosed:
            logger.info(f"🔌 WebSocket client disconnected: {client_id}")
        except Exception as e:
            logger.error(f"❌ WebSocket connection error: {e}")
        finally:
            # Clean up client
            if client_id and client_id in self.websocket_clients:
                del self.websocket_clients[client_id]

    async def _handle_websocket_message(self, client: WebSocketClient, message: str):
        """Handle messages from WebSocket clients"""
        try:
            data = json.loads(message)
            message_type = data.get("type")

            client.last_activity = datetime.now()

            if message_type == "subscribe":
                # Add new subscriptions
                new_subscriptions = set(data.get("subscriptions", []))
                client.subscriptions.update(new_subscriptions)

                await client.websocket.send(
                    json.dumps(
                        {
                            "type": "subscription_updated",
                            "subscriptions": list(client.subscriptions),
                        }
                    )
                )

            elif message_type == "unsubscribe":
                # Remove subscriptions
                remove_subscriptions = set(data.get("subscriptions", []))
                client.subscriptions -= remove_subscriptions

                await client.websocket.send(
                    json.dumps(
                        {
                            "type": "subscription_updated",
                            "subscriptions": list(client.subscriptions),
                        }
                    )
                )

            elif message_type == "ping":
                # Health check
                await client.websocket.send(
                    json.dumps(
                        {"type": "pong", "timestamp": datetime.now().isoformat()}
                    )
                )

        except Exception as e:
            logger.error(f"Error handling WebSocket message: {e}")

    async def _stream_processor(self):
        """Main stream processor - polls Snowflake streams for changes"""
        while True:
            try:
                for stream_id, stream_config in self.active_streams.items():
                    await self._process_stream(stream_id, stream_config)

                # Process every 5 seconds
                await asyncio.sleep(5)

            except Exception as e:
                logger.error(f"Error in stream processor: {e}")
                await asyncio.sleep(10)

    async def _process_stream(self, stream_id: str, stream_config: dict[str, Any]):
        """Process individual Snowflake stream for changes"""
        try:
            cursor = self.connection.cursor(DictCursor)

            # Query stream for changes - SECURE: Use validated identifiers
            from backend.core.sql_security_validator import validate_schema_name

            safe_schema = validate_schema_name(stream_config["schema_name"])
            safe_stream = stream_config[
                "stream_name"
            ]  # Stream names are controlled internally

            stream_query = f"""
            SELECT
                METADATA$ACTION as ACTION,
                METADATA$ISUPDATE as IS_UPDATE,
                METADATA$ROW_ID as ROW_ID,
                *
            FROM {safe_schema}.{safe_stream}
            LIMIT 100
            """

            cursor.execute(stream_query)
            changes = cursor.fetchall()

            if changes:
                logger.info(f"📊 Processing {len(changes)} changes from {stream_id}")

                for change in changes:
                    # Create stream event
                    event = StreamEvent(
                        stream_id=stream_id,
                        event_type=EventType(change["ACTION"]),
                        table_name=stream_config["table_name"],
                        schema_name=stream_config["schema_name"],
                        record_id=str(change.get("ROW_ID", "")),
                        data=change,
                        timestamp=datetime.now(),
                        metadata={
                            "is_update": change.get("IS_UPDATE", False),
                            "stream_type": stream_config["type"].value,
                        },
                    )

                    # Add to event queue
                    await self.event_queue.put(event)

                # Update last processed time
                stream_config["last_processed"] = datetime.now()

                # Calculate stream lag
                self.performance_metrics["stream_lag_seconds"][stream_id] = (
                    datetime.now() - stream_config["last_processed"]
                ).total_seconds()

            cursor.close()

        except Exception as e:
            logger.error(f"Error processing stream {stream_id}: {e}")
            self.performance_metrics["error_count"] += 1

    async def _event_processor(self):
        """Process stream events and create notifications"""
        while True:
            try:
                # Get event from queue
                event = await self.event_queue.get()

                start_time = datetime.now()

                # Process event based on type
                notifications = await self._create_notifications_for_event(event)

                # Add notifications to notification queue
                for notification in notifications:
                    await self.notification_queue.put(notification)

                # Update performance metrics
                processing_time = (datetime.now() - start_time).total_seconds() * 1000
                self.performance_metrics["events_processed"] += 1

                # Update average processing time
                current_avg = self.performance_metrics["average_processing_time_ms"]
                events_count = self.performance_metrics["events_processed"]
                self.performance_metrics["average_processing_time_ms"] = (
                    current_avg * (events_count - 1) + processing_time
                ) / events_count

                self.event_queue.task_done()

            except Exception as e:
                logger.error(f"Error in event processor: {e}")
                await asyncio.sleep(1)

    async def _create_notifications_for_event(
        self, event: StreamEvent
    ) -> list[dict[str, Any]]:
        """Create notifications based on stream event"""
        notifications = []

        try:
            if event.stream_id == "knowledge_updates":
                notifications.extend(await self._create_knowledge_notifications(event))
            elif event.stream_id == "conversation_updates":
                notifications.extend(
                    await self._create_conversation_notifications(event)
                )
            elif event.stream_id == "system_analytics":
                notifications.extend(await self._create_analytics_notifications(event))
            elif event.stream_id == "user_activity":
                notifications.extend(await self._create_activity_notifications(event))
            elif event.stream_id == "ingestion_jobs":
                notifications.extend(await self._create_ingestion_notifications(event))
            elif event.stream_id == "search_analytics":
                notifications.extend(await self._create_search_notifications(event))

        except Exception as e:
            logger.error(f"Error creating notifications for event: {e}")

        return notifications

    async def _create_knowledge_notifications(
        self, event: StreamEvent
    ) -> list[dict[str, Any]]:
        """Create notifications for knowledge base updates"""
        notifications = []

        if event.event_type == EventType.INSERT:
            notifications.append(
                {
                    "type": "knowledge_added",
                    "subscription": "knowledge_updates",
                    "data": {
                        "entry_id": event.data.get("ENTRY_ID"),
                        "title": event.data.get("TITLE"),
                        "category": event.data.get("CATEGORY_ID"),
                        "is_foundational": event.data.get("IS_FOUNDATIONAL", False),
                        "chunk_info": {
                            "chunk_index": event.data.get("CHUNK_INDEX", 0),
                            "total_chunks": event.data.get("TOTAL_CHUNKS", 1),
                        },
                    },
                    "timestamp": event.timestamp.isoformat(),
                }
            )

        elif event.event_type == EventType.UPDATE:
            notifications.append(
                {
                    "type": "knowledge_updated",
                    "subscription": "knowledge_updates",
                    "data": {
                        "entry_id": event.data.get("ENTRY_ID"),
                        "title": event.data.get("TITLE"),
                        "changes": "Content or metadata updated",
                    },
                    "timestamp": event.timestamp.isoformat(),
                }
            )

        return notifications

    async def _create_conversation_notifications(
        self, event: StreamEvent
    ) -> list[dict[str, Any]]:
        """Create notifications for conversation updates"""
        notifications = []

        if event.event_type == EventType.INSERT:
            notifications.append(
                {
                    "type": "new_message",
                    "subscription": "conversations",
                    "data": {
                        "message_id": event.data.get("MESSAGE_ID"),
                        "session_id": event.data.get("SESSION_ID"),
                        "user_id": event.data.get("USER_ID"),
                        "message_type": event.data.get("MESSAGE_TYPE"),
                        "knowledge_entries_used": event.data.get(
                            "KNOWLEDGE_ENTRIES_USED"
                        ),
                        "processing_time_ms": event.data.get("PROCESSING_TIME_MS"),
                    },
                    "timestamp": event.timestamp.isoformat(),
                }
            )

        return notifications

    async def _create_ingestion_notifications(
        self, event: StreamEvent
    ) -> list[dict[str, Any]]:
        """Create notifications for ingestion job updates"""
        notifications = []

        if event.event_type == EventType.UPDATE:
            job_data = event.data
            status = job_data.get("STATUS")

            if status in ["completed", "failed", "processing"]:
                notifications.append(
                    {
                        "type": "ingestion_status_update",
                        "subscription": "ingestion_jobs",
                        "data": {
                            "job_id": job_data.get("JOB_ID"),
                            "user_id": job_data.get("USER_ID"),
                            "filename": job_data.get("FILENAME"),
                            "status": status,
                            "progress": job_data.get("PROGRESS_PERCENTAGE", 0),
                            "chunks_processed": job_data.get("CHUNKS_PROCESSED", 0),
                            "total_chunks": job_data.get("TOTAL_CHUNKS", 0),
                            "error_message": job_data.get("ERROR_MESSAGE"),
                        },
                        "timestamp": event.timestamp.isoformat(),
                    }
                )

        return notifications

    async def _notification_processor(self):
        """Process and send notifications to WebSocket clients"""
        while True:
            try:
                # Get notification from queue
                notification = await self.notification_queue.get()

                # Find subscribed clients
                subscription_type = notification.get("subscription")
                clients_to_notify = []

                for client in self.websocket_clients.values():
                    if (
                        subscription_type in client.subscriptions
                        or "all" in client.subscriptions
                    ):
                        clients_to_notify.append(client)

                # Send to subscribed clients
                if clients_to_notify:
                    message = json.dumps(notification)

                    for client in clients_to_notify:
                        try:
                            await client.websocket.send(message)
                            self.performance_metrics["websocket_messages_sent"] += 1
                        except Exception as e:
                            logger.warning(
                                f"Failed to send to client {client.client_id}: {e}"
                            )
                            # Remove failed client
                            if client.client_id in self.websocket_clients:
                                del self.websocket_clients[client.client_id]

                self.notification_queue.task_done()

            except Exception as e:
                logger.error(f"Error in notification processor: {e}")
                await asyncio.sleep(1)

    async def _health_monitor(self):
        """Monitor streaming service health"""
        while True:
            try:
                # Check Snowflake connection
                if self.connection:
                    try:
                        cursor = self.connection.cursor()
                        cursor.execute("SELECT CURRENT_TIMESTAMP()")
                        cursor.close()
                    except Exception as e:
                        logger.warning(f"Snowflake connection issue: {e}")
                        await self._reconnect_snowflake()

                # Check WebSocket server
                if not self.websocket_server:
                    logger.warning("WebSocket server not running")

                # Log performance metrics
                logger.info(f"📊 Streaming metrics: {self.performance_metrics}")

                # Clean up inactive clients
                inactive_clients = []
                for client_id, client in self.websocket_clients.items():
                    if (datetime.now() - client.last_activity) > timedelta(minutes=30):
                        inactive_clients.append(client_id)

                for client_id in inactive_clients:
                    logger.info(f"🧹 Cleaning up inactive client: {client_id}")
                    del self.websocket_clients[client_id]

                await asyncio.sleep(60)  # Health check every minute

            except Exception as e:
                logger.error(f"Error in health monitor: {e}")
                await asyncio.sleep(60)

    async def _reconnect_snowflake(self):
        """Reconnect to Snowflake if connection fails"""
        try:
            if self.connection:
                self.connection.close()

            self.connection = snowflake.connector.connect(**self.snowflake_config)
            logger.info("✅ Reconnected to Snowflake")
        except Exception as e:
            logger.error(f"❌ Failed to reconnect to Snowflake: {e}")

    async def get_streaming_status(self) -> dict[str, Any]:
        """Get current streaming service status"""
        return {
            "active_streams": len(self.active_streams),
            "connected_clients": len(self.websocket_clients),
            "performance_metrics": self.performance_metrics,
            "stream_health": {
                stream_id: {
                    "last_processed": config["last_processed"].isoformat(),
                    "lag_seconds": self.performance_metrics["stream_lag_seconds"].get(
                        stream_id, 0
                    ),
                }
                for stream_id, config in self.active_streams.items()
            },
            "websocket_server_running": self.websocket_server is not None,
            "snowflake_connected": self.connection is not None,
        }

    async def stop(self):
        """Stop the streaming service"""
        try:
            # Stop WebSocket server
            if self.websocket_server:
                self.websocket_server.close()
                await self.websocket_server.wait_closed()

            # Close Snowflake connection
            if self.connection:
                self.connection.close()

            logger.info("✅ Real-Time Streaming Service stopped")

        except Exception as e:
            logger.error(f"Error stopping streaming service: {e}")


# Factory function
async def create_streaming_service(
    snowflake_config: dict[str, str], websocket_port: int = 8765
) -> RealTimeStreamingService:
    """Create and initialize streaming service"""
    service = RealTimeStreamingService(snowflake_config, websocket_port)
    await service.initialize()
    return service
