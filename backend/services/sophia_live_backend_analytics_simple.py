#!/usr/bin/env python3
"""
üî• Sophia AI Live Data Backend - ANALYTICS ENHANCED VERSION (SIMPLIFIED)
=========================================================================
Enhanced with comprehensive monitoring, error handling, and cross-platform analytics
(Without sklearn dependencies for compatibility)
"""

import asyncio
import json
import logging
import time
import csv
import base64
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import os
import sys

import uvicorn
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import aiohttp

# Import enhanced monitoring and analytics systems
sys.path.append('/home/ubuntu')
from enhanced_monitoring_system_fixed import (
    health_monitor, error_recovery, alerting_system,
    monitor_platform_call, get_monitoring_dashboard
)
from cross_platform_analytics_simple import (
    analytics_engine, get_comprehensive_analytics, get_analytics_dashboard
)

# Enhanced logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/home/ubuntu/sophia_backend_analytics.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ChatRequest(BaseModel):
    message: str

class LiveDataIntegration:
    """Real API integration service with enhanced monitoring and analytics"""
    
    def __init__(self):
        self.session = None
        self.credentials = self._load_credentials()
        self.employees = self._load_pay_ready_data()
        self.live_data = {
            'gong': {'status': 'connecting...', 'data': []},
            'slack': {'status': 'connecting...', 'data': []},
            'asana': {'status': 'connecting...', 'data': []},
            'notion': {'status': 'connecting...', 'data': []},
            'linear': {'status': 'connecting...', 'data': []}
        }
        logger.info("üöÄ LiveDataIntegration initialized with monitoring and analytics (simplified)")
    
    def _load_credentials(self) -> Dict[str, str]:
        """Load credentials from environment"""
        credentials = {
            'gong_access_key': os.getenv('GONG_ACCESS_KEY', ''),
            'gong_access_key_secret': os.getenv('GONG_ACCESS_KEY_SECRET', ''),
            'slack_bot_token': os.getenv('SLACK_BOT_TOKEN', ''),
            'asana_api_token': os.getenv('ASANA_API_TOKEN', ''),
            'notion_api_key': os.getenv('NOTION_API_KEY', ''),
            'linear_api_key': os.getenv('LINEAR_API_KEY', ''),
            'openai_api_key': os.getenv('OPENAI_API_KEY', '')
        }
        
        # Log credential status (safely)
        for key, value in credentials.items():
            status = "‚úÖ FOUND" if value else "‚ùå MISSING"
            logger.info(f"{key}: {status}")
            
        return credentials
    
    def _load_pay_ready_data(self) -> List[Dict]:
        """Load Pay Ready employee data"""
        try:
            csv_path = Path("data/pay_ready_employees_2025_07_15.csv")
            if csv_path.exists():
                return self._parse_csv_data(csv_path)
            else:
                return self._create_pay_ready_structure()
        except Exception as e:
            logger.error(f"Error loading Pay Ready data: {e}")
            return self._create_pay_ready_structure()
    
    def _parse_csv_data(self, csv_path: Path) -> List[Dict]:
        """Parse the actual Pay Ready CSV file"""
        employees = []
        
        with open(csv_path, 'r') as file:
            reader = csv.DictReader(file)
            
            for i, row in enumerate(reader, 1):
                name_parts = row.get('Preferred full name', '').split(' ', 1)
                first_name = name_parts[0] if name_parts else f'Employee'
                last_name = name_parts[1] if len(name_parts) > 1 else f'{i}'
                
                employee = {
                    'id': f"PR{i:03d}",
                    'full_name': row.get('Preferred full name', ''),
                    'first_name': first_name,
                    'last_name': last_name,
                    'department': row.get('Department', ''),
                    'job_title': row.get('Job title', ''),
                    'manager': row.get('Manager Name', ''),
                    'employment_type': row.get('Employment type', ''),
                    'status': 'active' if not row.get('Deactivation date', '') else 'inactive',
                    'email': f"{first_name.lower()}.{last_name.lower()}@payready.com".replace(' ', '')
                }
                employees.append(employee)
        
        logger.info(f"‚úÖ Loaded {len(employees)} real Pay Ready employees from CSV")
        return employees
    
    def _create_pay_ready_structure(self) -> List[Dict]:
        """Create Pay Ready structure based on known real departments"""
        real_departments = {
            'Support Team': 20, 'Engineering': 16, 'Account Management': 11,
            'AI': 8, 'Finance': 8, 'Sales': 8, 'Product': 7,
            'Operational Excellence': 6, 'Eviction Center': 5, 'Executive': 3,
            'Human Resources': 3, 'Implementation': 3, 'Compliance': 2,
            'Marketing': 2, 'Payment Operations': 2
        }
        
        employees = []
        employee_id = 1
        
        for dept, count in real_departments.items():
            for i in range(count):
                employees.append({
                    'id': f"PR{employee_id:03d}",
                    'full_name': f"Employee {employee_id}",
                    'first_name': f"Employee",
                    'last_name': f"{employee_id}",
                    'department': dept,
                    'job_title': f"{dept} Professional",
                    'manager': f"Manager {(employee_id % 5) + 1}",
                    'employment_type': 'Full-time',
                    'status': 'active',
                    'email': f"employee{employee_id}@payready.com"
                })
                employee_id += 1
        
        logger.info(f"Created Pay Ready structure: {len(employees)} employees")
        return employees
    
    async def initialize_session(self):
        """Initialize HTTP session for API calls"""
        if not self.session:
            self.session = aiohttp.ClientSession(
                timeout=aiohttp.ClientTimeout(total=30)  # 30 second timeout
            )
    
    async def close_session(self):
        """Close HTTP session"""
        if self.session:
            await self.session.close()
    
    async def _fetch_gong_data_raw(self) -> Dict[str, Any]:
        """Raw Gong data fetch (for monitoring wrapper)"""
        if not self.credentials.get('gong_access_key'):
            return {'status': '‚ùå No credentials', 'data': [], 'calls': 0, 'has_credentials': False}
        
        await self.initialize_session()
        
        # Proper Base64 encoding for Gong API
        access_key = self.credentials['gong_access_key']
        access_secret = self.credentials['gong_access_key_secret']
        
        auth_string = f"{access_key}:{access_secret}"
        auth_bytes = auth_string.encode('ascii')
        auth_b64 = base64.b64encode(auth_bytes).decode('ascii')
        
        headers = {
            'Authorization': f"Basic {auth_b64}",
            'Content-Type': 'application/json'
        }
        
        # Use users endpoint for reliable data
        users_url = "https://us-70092.api.gong.io/v2/users"
        
        async with self.session.get(users_url, headers=headers) as response:
            if response.status == 200:
                users_data = await response.json()
                users = users_data.get('users', [])
                
                return {
                    'status': '‚úÖ Connected',
                    'data': users[:5],  # First 5 users
                    'total_users': len(users),
                    'last_updated': datetime.now().isoformat(),
                    'has_credentials': True
                }
            else:
                response_text = await response.text()
                raise Exception(f"API Error {response.status}: {response_text[:100]}")
    
    async def fetch_gong_data(self) -> Dict[str, Any]:
        """Fetch Gong data with monitoring"""
        return await monitor_platform_call('gong', self._fetch_gong_data_raw)
    
    async def _fetch_slack_data_raw(self) -> Dict[str, Any]:
        """Raw Slack data fetch (for monitoring wrapper)"""
        if not self.credentials.get('slack_bot_token'):
            return {'status': '‚ùå No credentials', 'data': [], 'channels': 0, 'has_credentials': False}
        
        await self.initialize_session()
        
        # Test auth first
        auth_url = "https://slack.com/api/auth.test"
        headers = {
            'Authorization': f"Bearer {self.credentials['slack_bot_token']}",
            'Content-Type': 'application/json'
        }
        
        async with self.session.get(auth_url, headers=headers) as auth_response:
            auth_data = await auth_response.json()
            
            if not auth_data.get('ok'):
                error = auth_data.get('error', 'unknown')
                raise Exception(f"Auth failed: {error}")
        
        # Get conversations
        url = "https://slack.com/api/conversations.list"
        
        async with self.session.get(url, headers=headers) as response:
            if response.status == 200:
                data = await response.json()
                if data.get('ok'):
                    channels = data.get('channels', [])
                    
                    return {
                        'status': '‚úÖ Connected',
                        'data': channels[:10],
                        'total_channels': len(channels),
                        'last_updated': datetime.now().isoformat(),
                        'has_credentials': True
                    }
                else:
                    raise Exception(f"API Error: {data.get('error')}")
            else:
                raise Exception(f"HTTP Error {response.status}")
    
    async def fetch_slack_data(self) -> Dict[str, Any]:
        """Fetch Slack data with monitoring"""
        return await monitor_platform_call('slack', self._fetch_slack_data_raw)
    
    async def _fetch_asana_data_raw(self) -> Dict[str, Any]:
        """Raw Asana data fetch (for monitoring wrapper)"""
        if not self.credentials.get('asana_api_token'):
            return {'status': '‚ùå No credentials', 'data': [], 'projects': 0, 'has_credentials': False}
        
        await self.initialize_session()
        
        headers = {
            'Authorization': f"Bearer {self.credentials['asana_api_token']}",
            'Content-Type': 'application/json'
        }
        
        # Get workspaces first
        workspaces_url = "https://app.asana.com/api/1.0/workspaces"
        
        async with self.session.get(workspaces_url, headers=headers) as workspace_response:
            if workspace_response.status != 200:
                response_text = await workspace_response.text()
                raise Exception(f"Workspace Error {workspace_response.status}: {response_text[:100]}")
            
            workspace_data = await workspace_response.json()
            workspaces = workspace_data.get('data', [])
            
            if not workspaces:
                raise Exception("No workspaces found")
            
            workspace_gid = workspaces[0]['gid']
            workspace_name = workspaces[0].get('name', 'Unknown')
        
        # Get projects for workspace
        projects_url = "https://app.asana.com/api/1.0/projects"
        params = {
            'workspace': workspace_gid,
            'limit': 10,
            'opt_fields': 'name,created_at,modified_at,owner,team'
        }
        
        async with self.session.get(projects_url, headers=headers, params=params) as response:
            if response.status == 200:
                data = await response.json()
                projects = data.get('data', [])
                
                return {
                    'status': '‚úÖ Connected',
                    'data': projects,
                    'total_projects': len(projects),
                    'workspace_name': workspace_name,
                    'workspace_gid': workspace_gid,
                    'last_updated': datetime.now().isoformat(),
                    'has_credentials': True
                }
            else:
                response_text = await response.text()
                raise Exception(f"Projects Error {response.status}: {response_text[:100]}")
    
    async def fetch_asana_data(self) -> Dict[str, Any]:
        """Fetch Asana data with monitoring"""
        return await monitor_platform_call('asana', self._fetch_asana_data_raw)
    
    async def _fetch_notion_data_raw(self) -> Dict[str, Any]:
        """Raw Notion data fetch (for monitoring wrapper)"""
        if not self.credentials.get('notion_api_key'):
            return {'status': '‚ùå No credentials', 'data': [], 'pages': 0, 'has_credentials': False}
        
        await self.initialize_session()
        
        url = "https://api.notion.com/v1/search"
        headers = {
            'Authorization': f"Bearer {self.credentials['notion_api_key']}",
            'Content-Type': 'application/json',
            'Notion-Version': '2022-06-28'
        }
        
        payload = {
            "filter": {
                "property": "object",
                "value": "page"
            },
            "page_size": 10
        }
        
        async with self.session.post(url, headers=headers, json=payload) as response:
            if response.status == 200:
                data = await response.json()
                pages = data.get('results', [])
                
                return {
                    'status': '‚úÖ Connected',
                    'data': pages,
                    'total_pages': len(pages),
                    'last_updated': datetime.now().isoformat(),
                    'has_credentials': True
                }
            else:
                response_text = await response.text()
                raise Exception(f"API Error {response.status}: {response_text[:100]}")
    
    async def fetch_notion_data(self) -> Dict[str, Any]:
        """Fetch Notion data with monitoring"""
        return await monitor_platform_call('notion', self._fetch_notion_data_raw)
    
    async def _fetch_linear_data_raw(self) -> Dict[str, Any]:
        """Raw Linear data fetch (for monitoring wrapper)"""
        if not self.credentials.get('linear_api_key'):
            return {'status': '‚ùå No credentials', 'data': [], 'issues': 0, 'has_credentials': False}
        
        await self.initialize_session()
        
        url = "https://api.linear.app/graphql"
        headers = {
            'Authorization': f"{self.credentials['linear_api_key']}",
            'Content-Type': 'application/json'
        }
        
        query = """
        query {
            issues(first: 10) {
                nodes {
                    id
                    title
                    state {
                        name
                    }
                    createdAt
                    updatedAt
                }
            }
        }
        """
        
        payload = {"query": query}
        
        async with self.session.post(url, headers=headers, json=payload) as response:
            if response.status == 200:
                data = await response.json()
                
                if 'errors' in data:
                    raise Exception(f"GraphQL Error: {data['errors']}")
                
                issues = data.get('data', {}).get('issues', {}).get('nodes', [])
                
                return {
                    'status': '‚úÖ Connected',
                    'data': issues,
                    'total_issues': len(issues),
                    'last_updated': datetime.now().isoformat(),
                    'has_credentials': True
                }
            else:
                response_text = await response.text()
                raise Exception(f"API Error {response.status}: {response_text[:100]}")
    
    async def fetch_linear_data(self) -> Dict[str, Any]:
        """Fetch Linear data with monitoring"""
        return await monitor_platform_call('linear', self._fetch_linear_data_raw)
    
    async def refresh_all_data(self):
        """Refresh data from all platforms with enhanced monitoring"""
        logger.info("üîÑ Refreshing all live data with monitoring and analytics...")
        
        # Send system alert
        await alerting_system.send_alert(
            'system_refresh',
            'Starting platform data refresh cycle',
            'info'
        )
        
        tasks = [
            self.fetch_gong_data(),
            self.fetch_slack_data(),
            self.fetch_asana_data(),
            self.fetch_notion_data(),
            self.fetch_linear_data()
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        self.live_data.update({
            'gong': results[0] if not isinstance(results[0], Exception) else {'status': '‚ùå Error', 'data': [], 'has_credentials': True},
            'slack': results[1] if not isinstance(results[1], Exception) else {'status': '‚ùå Error', 'data': [], 'has_credentials': True},
            'asana': results[2] if not isinstance(results[2], Exception) else {'status': '‚ùå Error', 'data': [], 'has_credentials': True},
            'notion': results[3] if not isinstance(results[3], Exception) else {'status': '‚ùå Error', 'data': [], 'has_credentials': True},
            'linear': results[4] if not isinstance(results[4], Exception) else {'status': '‚ùå Error', 'data': [], 'has_credentials': True}
        })
        
        # Generate system health report
        platform_statuses = self.get_integration_status()
        system_health = health_monitor.get_system_health(platform_statuses)
        
        # Send alerts for critical issues
        if system_health.connected_platforms < 3:
            await alerting_system.send_alert(
                'system_critical',
                f'Only {system_health.connected_platforms}/5 platforms connected',
                'critical'
            )
        
        logger.info("‚úÖ Live data refresh complete with monitoring and analytics")
    
    def get_integration_status(self) -> Dict[str, Any]:
        """Get status of all integrations"""
        return {
            'gong': {
                'status': self.live_data['gong']['status'],
                'data_count': len(self.live_data['gong'].get('data', [])),
                'has_credentials': self.live_data['gong'].get('has_credentials', bool(self.credentials.get('gong_access_key')))
            },
            'slack': {
                'status': self.live_data['slack']['status'],
                'data_count': len(self.live_data['slack'].get('data', [])),
                'has_credentials': self.live_data['slack'].get('has_credentials', bool(self.credentials.get('slack_bot_token')))
            },
            'asana': {
                'status': self.live_data['asana']['status'],
                'data_count': len(self.live_data['asana'].get('data', [])),
                'has_credentials': self.live_data['asana'].get('has_credentials', bool(self.credentials.get('asana_api_token')))
            },
            'notion': {
                'status': self.live_data['notion']['status'],
                'data_count': len(self.live_data['notion'].get('data', [])),
                'has_credentials': self.live_data['notion'].get('has_credentials', bool(self.credentials.get('notion_api_key')))
            },
            'linear': {
                'status': self.live_data['linear']['status'],
                'data_count': len(self.live_data['linear'].get('data', [])),
                'has_credentials': self.live_data['linear'].get('has_credentials', bool(self.credentials.get('linear_api_key')))
            }
        }
    
    def generate_live_response(self, message: str) -> str:
        """Generate response with real live data, monitoring info, and analytics"""
        message_lower = message.lower()
        
        # Enhanced responses with monitoring and analytics data
        if any(word in message_lower for word in ["analytics", "insights", "intelligence", "analysis"]):
            # Get comprehensive analytics
            platform_data = {
                'data': {
                    'live_platforms': self.get_integration_status(),
                    'pay_ready': {
                        'employees': len(self.employees),
                        'status': '‚úÖ Connected'
                    }
                }
            }
            
            analytics_results = get_comprehensive_analytics(platform_data)
            insights = analytics_results.get('cross_platform_insights', [])
            
            response = "üß† **Sophia AI Advanced Analytics Report**\n\n"
            
            if insights:
                response += "**üîç Key Insights:**\n"
                for insight in insights[:3]:  # Top 3 insights
                    response += f"‚Ä¢ {insight['title']}: {insight['description']}\n"
                
                response += f"\n**üìä Business Intelligence:**\n"
                bi = analytics_results.get('business_intelligence', {})
                if 'operational_efficiency' in bi:
                    eff = bi['operational_efficiency']
                    response += f"‚Ä¢ Operational Efficiency: {eff['efficiency_score']:.1f}% ({eff['efficiency_level']})\n"
                
                if 'digital_transformation' in bi:
                    dt = bi['digital_transformation']
                    response += f"‚Ä¢ Digital Transformation: {dt['transformation_score']:.1f}% ({dt['maturity_level']})\n"
            
            return response
        
        elif any(word in message_lower for word in ["status", "health", "monitoring"]):
            health_report = health_monitor.get_health_report()
            
            return f"""üìä **Sophia AI System Health Report**

**üîó Platform Status ({health_report['connected_platforms']}/{health_report['total_platforms']} Connected):**
‚Ä¢ Overall Status: {health_report['overall_status']}
‚Ä¢ System Uptime: {health_report['system_uptime_hours']:.1f} hours
‚Ä¢ Overall Uptime: {health_report['uptime_percentage']:.1f}%

**üìà Platform Details:**
‚Ä¢ Gong: {health_report['platforms']['gong']['status']} ({health_report['platforms']['gong']['uptime_percentage']:.1f}% uptime)
‚Ä¢ Slack: {health_report['platforms']['slack']['status']} ({health_report['platforms']['slack']['uptime_percentage']:.1f}% uptime)
‚Ä¢ Asana: {health_report['platforms']['asana']['status']} ({health_report['platforms']['asana']['uptime_percentage']:.1f}% uptime)
‚Ä¢ Notion: {health_report['platforms']['notion']['status']} ({health_report['platforms']['notion']['uptime_percentage']:.1f}% uptime)
‚Ä¢ Linear: {health_report['platforms']['linear']['status']} ({health_report['platforms']['linear']['uptime_percentage']:.1f}% uptime)

**üö® Active Alerts:** {health_report['alert_count']}
{chr(10).join(f"‚Ä¢ {alert}" for alert in health_report['active_alerts'][:3])}

*Enhanced monitoring, error recovery, and analytics active*"""
        
        # Default platform responses (simplified for brevity)
        elif any(word in message_lower for word in ["gong", "calls", "sales"]):
            gong_data = self.live_data['gong']
            return f"üéôÔ∏è **Gong.io**: {gong_data['status']} - {len(gong_data.get('data', []))} items"
        
        elif any(word in message_lower for word in ["slack", "channels"]):
            slack_data = self.live_data['slack']
            return f"üí¨ **Slack**: {slack_data['status']} - {len(slack_data.get('data', []))} items"
        
        elif any(word in message_lower for word in ["asana", "projects"]):
            asana_data = self.live_data['asana']
            return f"üìã **Asana**: {asana_data['status']} - {len(asana_data.get('data', []))} items"
        
        elif any(word in message_lower for word in ["notion", "pages"]):
            notion_data = self.live_data['notion']
            return f"üìö **Notion**: {notion_data['status']} - {len(notion_data.get('data', []))} items"
        
        elif any(word in message_lower for word in ["linear", "issues"]):
            linear_data = self.live_data['linear']
            return f"‚ö° **Linear**: {linear_data['status']} - {len(linear_data.get('data', []))} items"
        
        else:
            return f"""ü§ñ **Sophia AI Enhanced Intelligence with Analytics**

I now have comprehensive monitoring, error recovery, and advanced analytics capabilities!

**Available Commands:**
‚Ä¢ "analytics" or "insights" - Advanced cross-platform analytics
‚Ä¢ "status" or "health" - System health report
‚Ä¢ Platform names (gong, slack, asana, notion, linear) - Platform details
‚Ä¢ "employees" - Pay Ready data ({len(self.employees)} employees)

**Enhanced Features:**
‚Ä¢ Real-time monitoring and alerting
‚Ä¢ Automatic error recovery
‚Ä¢ Performance tracking
‚Ä¢ Cross-platform analytics and business intelligence
‚Ä¢ Predictive insights and recommendations"""

# Initialize the live data integration
live_integration = LiveDataIntegration()

# FastAPI app setup
app = FastAPI(title="Sophia AI Live Data Backend - ANALYTICS ENHANCED (SIMPLIFIED)", version="5.1.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
async def startup_event():
    """Initialize live data on startup"""
    logger.info("üöÄ Starting Sophia AI Live Data Backend - ANALYTICS ENHANCED VERSION (SIMPLIFIED)...")
    await alerting_system.send_alert('system_startup', 'Sophia AI backend with analytics starting up', 'info')
    await live_integration.refresh_all_data()
    logger.info("‚úÖ Live data integration initialized with monitoring and analytics")

@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    await live_integration.close_session()
    await alerting_system.send_alert('system_shutdown', 'Sophia AI backend shutting down', 'info')
    logger.info("üëã Sophia AI Live Data Backend shutdown complete")

@app.get("/health")
async def health_check():
    """Enhanced health check endpoint"""
    health_report = health_monitor.get_health_report()
    
    return {
        "status": "healthy",
        "live_integrations": True,
        "employees_analyzed": len(live_integration.employees),
        "timestamp": datetime.now().isoformat(),
        "monitoring": {
            "overall_status": health_report['overall_status'],
            "connected_platforms": health_report['connected_platforms'],
            "total_platforms": health_report['total_platforms'],
            "uptime_percentage": health_report['uptime_percentage'],
            "active_alerts": len(health_report['active_alerts'])
        },
        "analytics_enabled": True
    }

@app.get("/dashboard/data")
async def get_dashboard_data():
    """Get live dashboard data with monitoring and analytics"""
    try:
        # Refresh data before serving
        await live_integration.refresh_all_data()
        
        # Get integration status
        platform_status = live_integration.get_integration_status()
        
        # Get monitoring data
        monitoring_dashboard = get_monitoring_dashboard()
        
        # Get analytics data
        platform_data = {
            'data': {
                'live_platforms': platform_status,
                'pay_ready': {
                    'employees': len(live_integration.employees),
                    'status': '‚úÖ Connected'
                }
            }
        }
        analytics_results = get_comprehensive_analytics(platform_data)
        
        return {
            "success": True,
            "data_source": "live_platform_integration_analytics",
            "timestamp": datetime.now().isoformat(),
            "data": {
                "live_platforms": platform_status,
                "pay_ready": {
                    "employees": len(live_integration.employees),
                    "status": "‚úÖ Connected"
                },
                "summary": {
                    "total_platforms": 5,
                    "connected_platforms": sum(1 for p in platform_status.values() if '‚úÖ' in p.get('status', '')),
                    "real_data_sources": ["Gong.io", "Slack", "Asana", "Notion", "Linear", "Pay Ready"]
                },
                "monitoring": monitoring_dashboard,
                "analytics": analytics_results
            }
        }
    except Exception as e:
        logger.error(f"Dashboard data error: {e}")
        await alerting_system.send_alert('dashboard_error', f'Dashboard data error: {str(e)}', 'error')
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/monitoring/dashboard")
async def get_monitoring_dashboard_endpoint():
    """Get comprehensive monitoring dashboard"""
    try:
        return get_monitoring_dashboard()
    except Exception as e:
        logger.error(f"Monitoring dashboard error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/analytics/dashboard")
async def get_analytics_dashboard_endpoint():
    """Get comprehensive analytics dashboard"""
    try:
        return get_analytics_dashboard()
    except Exception as e:
        logger.error(f"Analytics dashboard error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/analytics/insights")
async def get_analytics_insights():
    """Get comprehensive analytics insights"""
    try:
        # Get current platform data
        platform_status = live_integration.get_integration_status()
        platform_data = {
            'data': {
                'live_platforms': platform_status,
                'pay_ready': {
                    'employees': len(live_integration.employees),
                    'status': '‚úÖ Connected'
                }
            }
        }
        
        # Generate analytics
        analytics_results = get_comprehensive_analytics(platform_data)
        
        return {
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "analytics": analytics_results
        }
    except Exception as e:
        logger.error(f"Analytics insights error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    """Chat endpoint with live data integration, monitoring, and analytics"""
    try:
        response = live_integration.generate_live_response(request.message)
        
        return {
            "success": True,
            "response": response,
            "data_source": "live_platform_integration_analytics",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Chat error: {e}")
        await alerting_system.send_alert('chat_error', f'Chat error: {str(e)}', 'error')
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/platforms/refresh")
async def refresh_platforms():
    """Manually refresh all platform data"""
    try:
        await live_integration.refresh_all_data()
        return {
            "success": True,
            "message": "All platforms refreshed with monitoring and analytics",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"Refresh error: {e}")
        await alerting_system.send_alert('refresh_error', f'Platform refresh error: {str(e)}', 'error')
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    logger.info("üî• Starting Sophia AI Live Data Backend - ANALYTICS ENHANCED VERSION (SIMPLIFIED)")
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")

