#!/usr/bin/env python3
"""
Unified FastAPI Application
===========================

Single, consolidated FastAPI application for the entire Sophia AI platform.
Integrates all routes, services, and middleware for optimal performance.
"""

import asyncio
import logging
import time
from contextlib import asynccontextmanager
from datetime import UTC, datetime
from typing import Any

import uvicorn
from fastapi import FastAPI, HTTPException, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
from prometheus_client import Counter, Gauge, Histogram, generate_latest
from pydantic import BaseModel

# Import all route modules
from backend.api import (
    asana_integration_routes,
    codacy_integration_routes,
    data_flow_routes,
    linear_integration_routes,
    llm_strategy_routes,
    mcp_integration_routes,
    notion_integration_routes,
    slack_linear_knowledge_routes,
    enhanced_unified_chat_routes as enhanced_unified_chat_routes as chat_routes,
    foundational_knowledge_routes as foundational_knowledge_routes as knowledge_base_routes,
    ceo_dashboard_routes as monitoring_routes,
)
from backend.core.auto_esc_config import get_config_value
from backend.core.config_validator import DeploymentValidator
from backend.services.enhanced_unified_chat_service import EnhancedUnifiedChatService
from backend.services.foundational_knowledge_service import FoundationalKnowledgeService
from backend.services.smart_ai_service import SmartAIService

logger = logging.getLogger(__name__)

# Prometheus metrics
REQUEST_COUNT = Counter(
    "sophia_http_requests_total",
    "Total HTTP requests",
    ["method", "endpoint", "status"],
)

REQUEST_DURATION = Histogram(
    "sophia_http_request_duration_seconds",
    "HTTP request duration",
    ["method", "endpoint"],
)

ACTIVE_REQUESTS = Gauge("sophia_http_active_requests", "Active HTTP requests")

ERROR_RATE = Gauge("sophia_http_error_rate", "HTTP error rate")


class HealthResponse(BaseModel):
    """Health check response model"""

    status: str
    timestamp: str
    version: str
    environment: str
    services: dict[str, str]
    uptime_seconds: float
    metrics: dict[str, Any] | None = None


class UnifiedFastAPIApp:
    """Unified FastAPI application manager"""

    def __init__(self):
        self.app: FastAPI | None = None
        self.start_time = datetime.now(UTC)
        self.services = {}
        self.validator = DeploymentValidator()
        self.error_count = 0
        self.request_count = 0

    @asynccontextmanager
    async def lifespan(self, app: FastAPI):
        """Manage application lifecycle"""
        logger.info("ðŸš€ Starting Sophia AI Unified Platform...")

        try:
            # Validate configuration
            await self._validate_configuration()

            # Initialize services
            await self._initialize_services()

            # Start background tasks
            await self._start_background_tasks()

            logger.info("âœ… Sophia AI Platform started successfully")

            yield

        finally:
            # Cleanup
            logger.info("ðŸ›‘ Shutting down Sophia AI Platform...")
            await self._cleanup_services()
            logger.info("âœ… Shutdown complete")

    async def _validate_configuration(self):
        """Validate deployment configuration"""
        logger.info("ðŸ” Validating configuration...")

        validation_report = await self.validator.validate_deployment()

        if not validation_report.is_valid:
            critical_errors = [
                error
                for error in validation_report.errors
                if error.severity == "critical"
            ]

            if critical_errors:
                logger.error(f"âŒ Critical configuration errors: {critical_errors}")
                raise RuntimeError("Critical configuration errors prevent startup")
            else:
                logger.warning(f"âš ï¸  Configuration warnings: {validation_report.errors}")

    async def _initialize_services(self):
        """Initialize all platform services"""
        logger.info("ðŸ”§ Initializing services...")

        # MCP Orchestration - use lazy import to prevent constructor execution at module load
        try:
            from backend.services.enhanced_mcp_orchestration_service import (
                EnhancedMCPOrchestrationService,
            )
            self.services["mcp_orchestration"] = EnhancedMCPOrchestrationService()
            await self.services["mcp_orchestration"].initialize()
        except Exception as e:
            logger.error(f"Failed to initialize MCP orchestration: {e}")
            # Fallback to basic orchestration
            from backend.services.mcp_orchestration_service import get_orchestration_service
            self.services["mcp_orchestration"] = get_orchestration_service()

        # Chat Service
        self.services["chat"] = EnhancedUnifiedChatService()

        # Knowledge Service
        self.services["knowledge"] = FoundationalKnowledgeService()

        # AI Service
        self.services["ai"] = SmartAIService()

        logger.info("âœ… All services initialized")

    async def _start_background_tasks(self):
        """Start background tasks"""
        # Start MCP servers
        asyncio.create_task(self.services["mcp_orchestration"].start_all_servers())

        # Health monitoring
        asyncio.create_task(self._monitor_health())

    async def _monitor_health(self):
        """Monitor application health"""
        while True:
            try:
                await asyncio.sleep(60)  # Check every minute

                # Update error rate
                if self.request_count > 0:
                    error_rate = (self.error_count / self.request_count) * 100
                    ERROR_RATE.set(error_rate)

            except Exception as e:
                logger.error(f"Health monitoring error: {e}")

    async def _cleanup_services(self):
        """Cleanup services on shutdown"""
        for service_name, service in self.services.items():
            try:
                if hasattr(service, "shutdown"):
                    await service.shutdown()
                elif hasattr(service, "close"):
                    await service.close()
            except Exception as e:
                logger.error(f"Error shutting down {service_name}: {e}")

    def create_app(self) -> FastAPI:
        """Create and configure the FastAPI application"""
        self.app = FastAPI(
            title="Sophia AI Unified Platform",
            description="Enterprise AI orchestrator with unified API",
            version="3.0.0",
            docs_url="/docs",
            redoc_url="/redoc",
            openapi_url="/openapi.json",
            lifespan=self.lifespan,
        )

        # Configure middleware
        self._configure_middleware()

        # Configure routes
        self._configure_routes()

        # Configure error handlers
        self._configure_error_handlers()

        return self.app

    def _configure_middleware(self):
        """Configure all middleware"""
        # CORS
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=get_config_value("cors_origins", ["*"]),
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )

        # GZip compression
        self.app.add_middleware(GZipMiddleware, minimum_size=1000)

        # Trusted host
        allowed_hosts = get_config_value("allowed_hosts", ["*"])
        if allowed_hosts != ["*"]:
            self.app.add_middleware(TrustedHostMiddleware, allowed_hosts=allowed_hosts)

        # Request tracking
        @self.app.middleware("http")
        async def track_requests(request: Request, call_next):
            start_time = time.time()

            # Track active requests
            ACTIVE_REQUESTS.inc()
            self.request_count += 1

            try:
                response = await call_next(request)

                # Track metrics
                duration = time.time() - start_time

                REQUEST_COUNT.labels(
                    method=request.method,
                    endpoint=request.url.path,
                    status=response.status_code,
                ).inc()

                REQUEST_DURATION.labels(
                    method=request.method, endpoint=request.url.path
                ).observe(duration)

                if response.status_code >= 400:
                    self.error_count += 1

                # Add custom headers
                response.headers["X-Process-Time"] = str(duration)
                response.headers["X-Server-Version"] = "3.0.0"

                return response

            except Exception:
                self.error_count += 1
                raise
            finally:
                ACTIVE_REQUESTS.dec()

        # Rate limiting
        @self.app.middleware("http")
        async def rate_limit(request: Request, call_next):
            # Simple rate limiting - enhance as needed
            # Could integrate with Redis for distributed rate limiting
            return await call_next(request)

    def _configure_routes(self):
        """Configure all API routes"""

        # Health and system routes
        @self.app.get("/health", response_model=HealthResponse, tags=["System"])
        async def health_check():
            """Comprehensive health check"""
            uptime = (datetime.now(UTC) - self.start_time).total_seconds()

            # Check service health
            service_health = {}
            for name, service in self.services.items():
                if hasattr(service, "health_check"):
                    try:
                        health = await service.health_check()
                        service_health[name] = "healthy" if health else "unhealthy"
                    except Exception:
                        service_health[name] = "error"
                else:
                    service_health[name] = "unknown"

            return HealthResponse(
                status=(
                    "healthy"
                    if all(s == "healthy" for s in service_health.values())
                    else "degraded"
                ),
                timestamp=datetime.now(UTC).isoformat(),
                version="3.0.0",
                environment=get_config_value("environment", "production"),
                services=service_health,
                uptime_seconds=uptime,
                metrics={
                    "requests_total": self.request_count,
                    "errors_total": self.error_count,
                    "error_rate": (self.error_count / max(self.request_count, 1)) * 100,
                },
            )

        @self.app.get("/metrics", tags=["System"])
        async def metrics():
            """Prometheus metrics endpoint"""
            return Response(content=generate_latest(), media_type="text/plain")

        @self.app.get("/", tags=["System"])
        async def root():
            """Root endpoint"""
            return {
                "message": "Welcome to Sophia AI Platform",
                "version": "3.0.0",
                "docs": "/docs",
                "health": "/health",
            }

        # Include all route modules
        routers = [
            (chat_routes.router, "/api/v3", ["Chat"]),
            (mcp_integration_routes.router, "/api", ["MCP"]),
            (knowledge_base_routes.router, "/api/v3", ["Knowledge Base"]),
            (slack_linear_knowledge_routes.router, "/api/v3", ["Integrations"]),
            (asana_integration_routes.router, "/api/v3", ["Integrations"]),
            (linear_integration_routes.router, "/api/v3", ["Integrations"]),
            (notion_integration_routes.router, "/api/v3", ["Integrations"]),
            (codacy_integration_routes.router, "/api/v3", ["Quality"]),
            (monitoring_routes.router, "/api/v3", ["Monitoring"]),
        ]

        for router, prefix, tags in routers:
            try:
                self.app.include_router(router, prefix=prefix, tags=tags)
                logger.info(f"âœ… Loaded router: {router}")
            except Exception as e:
                logger.error(f"Failed to load router {router}: {e}")

    def _configure_error_handlers(self):
        """Configure global error handlers"""

        @self.app.exception_handler(HTTPException)
        async def http_exception_handler(request: Request, exc: HTTPException):
            return JSONResponse(
                status_code=exc.status_code,
                content={
                    "error": exc.detail,
                    "status_code": exc.status_code,
                    "timestamp": datetime.now(UTC).isoformat(),
                    "path": request.url.path,
                },
            )

        @self.app.exception_handler(Exception)
        async def general_exception_handler(request: Request, exc: Exception):
            logger.error(f"Unhandled exception: {exc}", exc_info=True)

            return JSONResponse(
                status_code=500,
                content={
                    "error": "Internal server error",
                    "message": (
                        str(exc)
                        if logger.level <= logging.DEBUG
                        else "An error occurred"
                    ),
                    "timestamp": datetime.now(UTC).isoformat(),
                    "path": request.url.path,
                },
            )


# Create application instance
app_manager = UnifiedFastAPIApp()
app = app_manager.create_app()


if __name__ == "__main__":
    # Run with uvicorn
    uvicorn.run(
        "unified_fastapi_app:app",
        host="0.0.0.0",
        port=8000,
        reload=get_config_value("debug", False),
        log_level="info",
        access_log=True,
        workers=get_config_value("workers", 4),
    )
