#!/usr/bin/env python3\n\"\"\"\nComprehensive MCP Deep Analysis\n===============================\n\nPerforms deep-level review of all MCP servers, ports, CLI setups, and workflows\nto identify and resolve conflicts, circular references, dependencies, syntax,\nand linter issues.\n\"\"\"\n\nimport ast\nimport json\nimport os\nimport re\nimport subprocess\nimport sys\nfrom collections import defaultdict\nfrom pathlib import Path\nfrom typing import Dict, List, Set, Tuple, Any\n\n\nclass MCPAnalyzer:\n    def __init__(self):\n        self.project_root = Path(\".\")\n        self.mcp_servers_dir = self.project_root / \"mcp-servers\"\n        self.config_dir = self.project_root / \"config\"\n        self.issues = {\n            \"syntax_errors\": [],\n            \"port_conflicts\": [],\n            \"circular_dependencies\": [],\n            \"missing_dependencies\": [],\n            \"linter_issues\": [],\n            \"configuration_conflicts\": [],\n            \"cli_conflicts\": [],\n            \"workflow_issues\": []\n        }\n        self.port_assignments = {}\n        self.import_graph = defaultdict(set)\n        \n    def run_analysis(self) -> Dict[str, Any]:\n        \"\"\"Run comprehensive analysis of MCP ecosystem\"\"\"\n        print(\"🔍 Starting comprehensive MCP deep analysis...\")\n        \n        # 1. Syntax Analysis\n        self._analyze_syntax_errors()\n        \n        # 2. Port Configuration Analysis\n        self._analyze_port_configurations()\n        \n        # 3. Dependency Analysis\n        self._analyze_dependencies()\n        \n        # 4. Circular Reference Analysis\n        self._analyze_circular_references()\n        \n        # 5. Linter Analysis\n        self._analyze_linter_issues()\n        \n        # 6. Configuration Conflicts\n        self._analyze_configuration_conflicts()\n        \n        # 7. CLI Setup Analysis\n        self._analyze_cli_setups()\n        \n        # 8. Workflow Analysis\n        self._analyze_workflow_issues()\n        \n        # Generate comprehensive report\n        return self._generate_report()\n    \n    def _analyze_syntax_errors(self):\n        \"\"\"Analyze Python syntax errors in MCP servers\"\"\"\n        print(\"  📝 Analyzing syntax errors...\")\n        \n        python_files = list(self.mcp_servers_dir.rglob(\"*.py\"))\n        \n        for file_path in python_files:\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                ast.parse(content)\n            except SyntaxError as e:\n                self.issues[\"syntax_errors\"].append({\n                    \"file\": str(file_path),\n                    \"line\": e.lineno,\n                    \"error\": str(e),\n                    \"type\": \"syntax_error\"\n                })\n            except Exception as e:\n                self.issues[\"syntax_errors\"].append({\n                    \"file\": str(file_path),\n                    \"line\": None,\n                    \"error\": str(e),\n                    \"type\": \"parse_error\"\n                })\n    \n    def _analyze_port_configurations(self):\n        \"\"\"Analyze port configurations and conflicts\"\"\"\n        print(\"  🔌 Analyzing port configurations...\")\n        \n        # Load all port configuration files\n        port_configs = [\n            \"config/mcp_ports.json\",\n            \"config/consolidated_mcp_ports.json\",\n            \"config/cursor_enhanced_mcp_config.json\",\n            \"config/simplified_mcp_config.json\"\n        ]\n        \n        all_ports = defaultdict(list)\n        \n        for config_file in port_configs:\n            config_path = self.project_root / config_file\n            if config_path.exists():\n                try:\n                    with open(config_path, 'r') as f:\n                        config = json.load(f)\n                    \n                    # Extract port assignments\n                    self._extract_ports_from_config(config, config_file, all_ports)\n                    \n                except Exception as e:\n                    self.issues[\"configuration_conflicts\"].append({\n                        \"file\": config_file,\n                        \"error\": f\"Failed to parse config: {e}\",\n                        \"type\": \"config_parse_error\"\n                    })\n        \n        # Check for port conflicts\n        for port, sources in all_ports.items():\n            if len(sources) > 1:\n                self.issues[\"port_conflicts\"].append({\n                    \"port\": port,\n                    \"sources\": sources,\n                    \"type\": \"port_conflict\"\n                })\n        \n        # Check hardcoded ports in Python files\n        self._check_hardcoded_ports()\n    \n    def _extract_ports_from_config(self, config: Dict, source: str, all_ports: Dict):\n        \"\"\"Extract port assignments from configuration\"\"\"\n        if \"servers\" in config:\n            for server, port in config[\"servers\"].items():\n                if isinstance(port, int):\n                    all_ports[port].append(f\"{source}:{server}\")\n        \n        if \"active_servers\" in config:\n            for server, port in config[\"active_servers\"].items():\n                if isinstance(port, int):\n                    all_ports[port].append(f\"{source}:{server}\")\n        \n        if \"mcpServers\" in config:\n            for server, server_config in config[\"mcpServers\"].items():\n                if \"args\" in server_config:\n                    for arg in server_config[\"args\"]:\n                        if \"--port\" in str(arg) or \"port\" in str(arg):\n                            # Extract port number\n                            port_match = re.search(r'\\b(\\d{4,5})\\b', str(arg))\n                            if port_match:\n                                port = int(port_match.group(1))\n                                all_ports[port].append(f\"{source}:{server}\")\n    \n    def _check_hardcoded_ports(self):\n        \"\"\"Check for hardcoded ports in Python files\"\"\"\n        python_files = list(self.mcp_servers_dir.rglob(\"*.py\"))\n        \n        for file_path in python_files:\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                \n                # Look for port patterns\n                port_patterns = [\n                    r'port\\s*=\\s*(9\\d{3})',\n                    r'PORT\\s*=\\s*(9\\d{3})',\n                    r'listen.*:(9\\d{3})',\n                    r'bind.*:(9\\d{3})'\n                ]\n                \n                for pattern in port_patterns:\n                    matches = re.finditer(pattern, content)\n                    for match in matches:\n                        port = int(match.group(1))\n                        line_num = content[:match.start()].count('\\n') + 1\n                        \n                        self.issues[\"port_conflicts\"].append({\n                            \"file\": str(file_path),\n                            \"line\": line_num,\n                            \"port\": port,\n                            \"type\": \"hardcoded_port\"\n                        })\n                        \n            except Exception as e:\n                pass  # Skip files that can't be read\n    \n    def _analyze_dependencies(self):\n        \"\"\"Analyze import dependencies\"\"\"\n        print(\"  📦 Analyzing dependencies...\")\n        \n        python_files = list(self.mcp_servers_dir.rglob(\"*.py\"))\n        \n        for file_path in python_files:\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                \n                tree = ast.parse(content)\n                file_imports = set()\n                \n                for node in ast.walk(tree):\n                    if isinstance(node, ast.Import):\n                        for alias in node.names:\n                            file_imports.add(alias.name)\n                    elif isinstance(node, ast.ImportFrom):\n                        if node.module:\n                            file_imports.add(node.module)\n                \n                self.import_graph[str(file_path)] = file_imports\n                \n            except Exception as e:\n                self.issues[\"missing_dependencies\"].append({\n                    \"file\": str(file_path),\n                    \"error\": str(e),\n                    \"type\": \"import_analysis_error\"\n                })\n    \n    def _analyze_circular_references(self):\n        \"\"\"Analyze circular import dependencies\"\"\"\n        print(\"  🔄 Analyzing circular references...\")\n        \n        # Simple cycle detection in import graph\n        visited = set()\n        rec_stack = set()\n        \n        def has_cycle(node, path):\n            if node in rec_stack:\n                cycle_start = path.index(node)\n                cycle = path[cycle_start:] + [node]\n                self.issues[\"circular_dependencies\"].append({\n                    \"cycle\": cycle,\n                    \"type\": \"circular_import\"\n                })\n                return True\n            \n            if node in visited:\n                return False\n            \n            visited.add(node)\n            rec_stack.add(node)\n            \n            # Check dependencies\n            for dep in self.import_graph.get(node, set()):\n                # Find files that import this dependency\n                for file_path, imports in self.import_graph.items():\n                    if dep in imports:\n                        if has_cycle(file_path, path + [node]):\n                            rec_stack.remove(node)\n                            return True\n            \n            rec_stack.remove(node)\n            return False\n        \n        for file_path in self.import_graph:\n            if file_path not in visited:\n                has_cycle(file_path, [])\n    \n    def _analyze_linter_issues(self):\n        \"\"\"Analyze linter issues using ruff\"\"\"\n        print(\"  🔍 Analyzing linter issues...\")\n        \n        try:\n            # Run ruff on mcp-servers directory\n            result = subprocess.run(\n                [\"ruff\", \"check\", \"mcp-servers/\", \"--output-format=json\"],\n                capture_output=True,\n                text=True\n            )\n            \n            if result.stdout:\n                linter_output = json.loads(result.stdout)\n                for issue in linter_output:\n                    self.issues[\"linter_issues\"].append({\n                        \"file\": issue.get(\"filename\"),\n                        \"line\": issue.get(\"location\", {}).get(\"row\"),\n                        \"column\": issue.get(\"location\", {}).get(\"column\"),\n                        \"code\": issue.get(\"code\"),\n                        \"message\": issue.get(\"message\"),\n                        \"severity\": issue.get(\"severity\", \"error\")\n                    })\n                    \n        except subprocess.CalledProcessError:\n            # Ruff not available or failed\n            pass\n        except json.JSONDecodeError:\n            # Ruff output not JSON\n            pass\n    \n    def _analyze_configuration_conflicts(self):\n        \"\"\"Analyze configuration file conflicts\"\"\"\n        print(\"  ⚙️ Analyzing configuration conflicts...\")\n        \n        # Check for duplicate MCP server definitions\n        all_servers = defaultdict(list)\n        \n        config_files = list(self.config_dir.glob(\"*mcp*.json\"))\n        \n        for config_file in config_files:\n            try:\n                with open(config_file, 'r') as f:\n                    config = json.load(f)\n                \n                # Extract server names\n                servers = set()\n                if \"mcpServers\" in config:\n                    servers.update(config[\"mcpServers\"].keys())\n                if \"servers\" in config:\n                    servers.update(config[\"servers\"].keys())\n                if \"active_servers\" in config:\n                    servers.update(config[\"active_servers\"].keys())\n                \n                for server in servers:\n                    all_servers[server].append(str(config_file))\n                    \n            except Exception as e:\n                self.issues[\"configuration_conflicts\"].append({\n                    \"file\": str(config_file),\n                    \"error\": str(e),\n                    \"type\": \"config_parse_error\"\n                })\n        \n        # Check for conflicts\n        for server, files in all_servers.items():\n            if len(files) > 1:\n                self.issues[\"configuration_conflicts\"].append({\n                    \"server\": server,\n                    \"files\": files,\n                    \"type\": \"duplicate_server_definition\"\n                })\n    \n    def _analyze_cli_setups(self):\n        \"\"\"Analyze CLI setup conflicts\"\"\"\n        print(\"  💻 Analyzing CLI setups...\")\n        \n        cli_dirs = [\n            \"claude-cli-integration\",\n            \"gemini-cli-integration\"\n        ]\n        \n        for cli_dir in cli_dirs:\n            cli_path = self.project_root / cli_dir\n            if cli_path.exists():\n                # Check for configuration conflicts\n                config_files = list(cli_path.glob(\"*.json\"))\n                \n                for config_file in config_files:\n                    try:\n                        with open(config_file, 'r') as f:\n                            config = json.load(f)\n                        \n                        # Check for port conflicts with MCP servers\n                        if \"port\" in config:\n                            port = config[\"port\"]\n                            if port in self.port_assignments:\n                                self.issues[\"cli_conflicts\"].append({\n                                    \"file\": str(config_file),\n                                    \"port\": port,\n                                    \"conflict_with\": self.port_assignments[port],\n                                    \"type\": \"cli_port_conflict\"\n                                })\n                                \n                    except Exception as e:\n                        self.issues[\"cli_conflicts\"].append({\n                            \"file\": str(config_file),\n                            \"error\": str(e),\n                            \"type\": \"cli_config_error\"\n                        })\n    \n    def _analyze_workflow_issues(self):\n        \"\"\"Analyze GitHub Actions workflow issues\"\"\"\n        print(\"  🔄 Analyzing workflow issues...\")\n        \n        workflow_dir = self.project_root / \".github\" / \"workflows\"\n        if workflow_dir.exists():\n            workflow_files = list(workflow_dir.glob(\"*.yml\"))\n            \n            for workflow_file in workflow_files:\n                try:\n                    with open(workflow_file, 'r') as f:\n                        content = f.read()\n                    \n                    # Check for common issues\n                    issues = []\n                    \n                    # Check for hardcoded ports\n                    port_matches = re.finditer(r'(9\\d{3})', content)\n                    for match in port_matches:\n                        line_num = content[:match.start()].count('\\n') + 1\n                        issues.append({\n                            \"line\": line_num,\n                            \"issue\": f\"Hardcoded port {match.group(1)}\",\n                            \"type\": \"hardcoded_port\"\n                        })\n                    \n                    # Check for missing environment variables\n                    env_patterns = [\n                        r'\\$\\{\\{\\s*secrets\\.([A-Z_]+)\\s*\\}\\}',\n                        r'\\$\\{\\{\\s*env\\.([A-Z_]+)\\s*\\}\\}'\n                    ]\n                    \n                    for pattern in env_patterns:\n                        matches = re.finditer(pattern, content)\n                        for match in matches:\n                            var_name = match.group(1)\n                            if var_name.endswith('_URL') and 'DATABASE' in var_name:\n                                line_num = content[:match.start()].count('\\n') + 1\n                                issues.append({\n                                    \"line\": line_num,\n                                    \"issue\": f\"Deprecated DATABASE_URL usage: {var_name}\",\n                                    \"type\": \"deprecated_env_var\"\n                                })\n                    \n                    if issues:\n                        self.issues[\"workflow_issues\"].append({\n                            \"file\": str(workflow_file),\n                            \"issues\": issues\n                        })\n                        \n                except Exception as e:\n                    self.issues[\"workflow_issues\"].append({\n                        \"file\": str(workflow_file),\n                        \"error\": str(e),\n                        \"type\": \"workflow_parse_error\"\n                    })\n    \n    def _generate_report(self) -> Dict[str, Any]:\n        \"\"\"Generate comprehensive analysis report\"\"\"\n        print(\"  📊 Generating comprehensive report...\")\n        \n        total_issues = sum(len(issues) for issues in self.issues.values())\n        \n        report = {\n            \"summary\": {\n                \"total_issues\": total_issues,\n                \"syntax_errors\": len(self.issues[\"syntax_errors\"]),\n                \"port_conflicts\": len(self.issues[\"port_conflicts\"]),\n                \"circular_dependencies\": len(self.issues[\"circular_dependencies\"]),\n                \"missing_dependencies\": len(self.issues[\"missing_dependencies\"]),\n                \"linter_issues\": len(self.issues[\"linter_issues\"]),\n                \"configuration_conflicts\": len(self.issues[\"configuration_conflicts\"]),\n                \"cli_conflicts\": len(self.issues[\"cli_conflicts\"]),\n                \"workflow_issues\": len(self.issues[\"workflow_issues\"])\n            },\n            \"details\": self.issues,\n            \"recommendations\": self._generate_recommendations()\n        }\n        \n        return report\n    \n    def _generate_recommendations(self) -> List[str]:\n        \"\"\"Generate fix recommendations\"\"\"\n        recommendations = []\n        \n        if self.issues[\"syntax_errors\"]:\n            recommendations.append(\"Fix syntax errors in MCP server files\")\n        \n        if self.issues[\"port_conflicts\"]:\n            recommendations.append(\"Resolve port conflicts by updating configuration files\")\n        \n        if self.issues[\"circular_dependencies\"]:\n            recommendations.append(\"Refactor code to eliminate circular import dependencies\")\n        \n        if self.issues[\"linter_issues\"]:\n            recommendations.append(\"Run 'ruff --fix' to resolve linter issues\")\n        \n        if self.issues[\"configuration_conflicts\"]:\n            recommendations.append(\"Consolidate MCP server configurations into single source of truth\")\n        \n        return recommendations\n\n\ndef main():\n    \"\"\"Main function to run comprehensive MCP analysis\"\"\"\n    analyzer = MCPAnalyzer()\n    report = analyzer.run_analysis()\n    \n    # Save report to file\n    report_file = \"MCP_COMPREHENSIVE_DEEP_ANALYSIS_REPORT.md\"\n    \n    with open(report_file, 'w') as f:\n        f.write(\"# MCP Comprehensive Deep Analysis Report\\n\\n\")\n        f.write(f\"**Generated:** {__import__('datetime').datetime.now().isoformat()}\\n\\n\")\n        \n        # Summary\n        f.write(\"## 📊 Summary\\n\\n\")\n        summary = report[\"summary\"]\n        f.write(f\"- **Total Issues Found:** {summary['total_issues']}\\n\")\n        f.write(f\"- **Syntax Errors:** {summary['syntax_errors']}\\n\")\n        f.write(f\"- **Port Conflicts:** {summary['port_conflicts']}\\n\")\n        f.write(f\"- **Circular Dependencies:** {summary['circular_dependencies']}\\n\")\n        f.write(f\"- **Linter Issues:** {summary['linter_issues']}\\n\")\n        f.write(f\"- **Configuration Conflicts:** {summary['configuration_conflicts']}\\n\")\n        f.write(f\"- **CLI Conflicts:** {summary['cli_conflicts']}\\n\")\n        f.write(f\"- **Workflow Issues:** {summary['workflow_issues']}\\n\\n\")\n        \n        # Detailed issues\n        for category, issues in report[\"details\"].items():\n            if issues:\n                f.write(f\"## ❌ {category.replace('_', ' ').title()}\\n\\n\")\n                for i, issue in enumerate(issues[:10], 1):  # Limit to first 10\n                    f.write(f\"### {i}. \")\n                    if \"file\" in issue:\n                        f.write(f\"**File:** `{issue['file']}`\\n\")\n                    if \"line\" in issue and issue[\"line\"]:\n                        f.write(f\"**Line:** {issue['line']}\\n\")\n                    if \"error\" in issue:\n                        f.write(f\"**Error:** {issue['error']}\\n\")\n                    if \"port\" in issue:\n                        f.write(f\"**Port:** {issue['port']}\\n\")\n                    f.write(\"\\n\")\n                \n                if len(issues) > 10:\n                    f.write(f\"... and {len(issues) - 10} more issues\\n\\n\")\n        \n        # Recommendations\n        f.write(\"## 🔧 Recommendations\\n\\n\")\n        for i, rec in enumerate(report[\"recommendations\"], 1):\n            f.write(f\"{i}. {rec}\\n\")\n    \n    print(f\"\\n✅ Analysis complete! Report saved to {report_file}\")\n    print(f\"📊 Total issues found: {report['summary']['total_issues']}\")\n    \n    if report['summary']['total_issues'] > 0:\n        print(\"\\n🚨 Issues found that require attention:\")\n        for category, count in report['summary'].items():\n            if count > 0 and category != 'total_issues':\n                print(f\"  - {category.replace('_', ' ').title()}: {count}\")\n    else:\n        print(\"\\n🎉 No issues found! MCP ecosystem is healthy.\")\n\n\nif __name__ == \"__main__\":\n    main() 