#!/usr/bin/env python3
"""
Sophia AI Documentation Cleanup Implementation Script
Automated implementation of documentation audit recommendations
"""

"""
File Decomposition Plan (auto-generated by Phase 3)
Current size: 1185 lines

Recommended decomposition:
- documentation_cleanup_implementation_core.py - Core functionality
- documentation_cleanup_implementation_utils.py - Utility functions
- documentation_cleanup_implementation_models.py - Data models
- documentation_cleanup_implementation_handlers.py - Request handlers

TODO: Implement file decomposition
"""

import json
import logging
import shutil
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class DocumentationCleanup:
    """Implements comprehensive documentation cleanup for Sophia AI"""

    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.docs_path = self.base_path / "docs"
        self.backup_path = self.base_path / "docs_backup"

        # Files to delete (outdated/duplicate/conflicting)
        self.files_to_delete = [
            # Phase implementation summaries (outdated)
            "docs/phase*_implementation_summary.md",
            "docs/phase*_audit_logging_summary.md",
            "docs/phase*_cache_activation_summary.md",
            "docs/phase*_ephemeral_credentials_summary.md",
            "docs/phase*_mcp_optimization_summary.md",
            # Duplicate architecture guides
            "docs/ARCHITECTURE_PATTERNS_AND_STANDARDS.md",
            "docs/ARCHITECTURE_MASTER_GUIDE.md",
            "docs/ARCHITECTURAL_ANALYSIS_SUMMARY.md",
            "docs/ARCHITECTURAL_ENHANCEMENT_IMPLEMENTATION.md",
            # Obsolete integration guides
            "docs/ESTUARY_INTEGRATION_GUIDE.md",
            "docs/SIMPLIFIED_PORTKEY_MIGRATION_GUIDE.md",
            "docs/ENHANCED_PORTKEY_IMPLEMENTATION_GUIDE.md",
            "docs/MANUS_AI_SNOWFLAKE_ESTUARY_SETUP.md",
            # Conflicting best practices
            "docs/PYTHON_SYNTAX_BEST_PRACTICES.md",
            "docs/PYTHON_SYNTAX_CLEANUP_SUMMARY.md",
            "docs/QUICK_START_SYNTAX_FIX.md",
            # Multiple master indices
            "docs/SOPHIA_AI_DOCUMENTATION_MASTER_INDEX.md",
            "docs/README_DOCUMENTATION_INDEX.md",
            "docs/DOCUMENTATION_CLEANUP_GUIDE.md",
            # Outdated deployment guides
            "docs/DEPLOYMENT_MASTER_GUIDE.md",
            "docs/INFRASTRUCTURE_QUICK_START.md",
            "docs/INFRASTRUCTURE_MANAGEMENT_ARCHITECTURE.md",
            "docs/INFRASTRUCTURE_MODERNIZATION_*.md",
            # Implementation reports (outdated)
            "docs/SOPHIA_AI_*_IMPLEMENTATION_*.md",
            "docs/SOPHIA_AI_*_SUMMARY.md",
            "docs/SOPHIA_AI_*_REPORT.md",
            "docs/CLEAN_*_IMPLEMENTATION*.md",
            "docs/CODEBASE_*_SUMMARY.md",
            # Obsolete guides
            "docs/CURSOR_AI_CODING_SETUP.md",
            "docs/CLINE_AND_COGNEE_SETUP_GUIDE.md",
            "docs/CLINE_V3_18_*.md",
            "docs/CODACY_CURSOR_QUICK_REFERENCE.md",
            # User guides (to be consolidated)
            "docs/phase2_user_guide.md",
            "docs/AI_DEVELOPER_ONBOARDING.md",
            # Specific status/planning docs
            "docs/SOPHIA_AI_HOLISTIC_OPTIMIZATION_PLAN.md",
            "docs/SOPHIA_AI_COMPLETE_IMPLEMENTATION_ROADMAP.md",
            "docs/SOPHIA_AI_MCP_ORCHESTRATION_*.md",
            "docs/SOPHIA_AI_ENHANCED_LLM_STRATEGY_SUMMARY.md",
            # Performance docs (to be consolidated)
            "docs/PERFORMANCE_OPTIMIZATION_*.md",
            "docs/PERFORMANCE_PLAYBOOK.md",
            "docs/CODEX_PERFORMANCE_OPTIMIZATION_PROMPT.md",
            # Project management docs (obsolete)
            "docs/CROSS_PLATFORM_PROJECT_MANAGEMENT_DASHBOARD.md",
            "docs/COSTAR_PROJECT_IMPLEMENTATION_GUIDE.md",
            "docs/PROJECT_MANAGEMENT_STRUCTURE.md",
            # Misc outdated docs
            "docs/CHANGELOG.md",  # Will create new one
            "docs/FEATURE_FLAGS_AND_ROLLOUT.md",
            "docs/GITHUB_ACTIONS_WORKFLOW_FIXES.md",
            "docs/AUTOMATION_API_WORKFLOW.md",
        ]

        # Files to preserve and update
        self.files_to_update = [
            "docs/AI_CODER_REFERENCE.md",
            "docs/SOPHIA_AI_BEST_PRACTICES_GUIDE.md",
            "docs/SECRET_MANAGEMENT_GUIDE.md",
            "docs/MCP_PORT_STRATEGY.md",
            "docs/MCP_SERVER_API_REFERENCE.md",
            "docs/NATURAL_LANGUAGE_CONTROL_GUIDE.md",
            "README.md",
        ]

        # New files to create
        self.files_to_create = [
            "ARCHITECTURE.md",
            "DEVELOPMENT.md",
            "DEPLOYMENT.md",
            "API_REFERENCE.md",
            "MCP_INTEGRATION.md",
            "AGENT_DEVELOPMENT.md",
            "TROUBLESHOOTING.md",
            "CHANGELOG.md",
        ]

    def create_backup(self):
        """Create backup of current documentation"""
        logger.info("Creating backup of current documentation...")

        if self.backup_path.exists():
            shutil.rmtree(self.backup_path)

        shutil.copytree(self.docs_path, self.backup_path)
        logger.info(f"Backup created at {self.backup_path}")

    def get_files_matching_patterns(self, patterns: list[str]) -> set[Path]:
        """Get all files matching the given glob patterns"""
        files = set()
        for pattern in patterns:
            files.update(Path(".").glob(pattern))
        return files

    def delete_obsolete_files(self):
        """Delete obsolete and duplicate documentation files"""
        logger.info("Deleting obsolete documentation files...")

        files_to_delete = self.get_files_matching_patterns(self.files_to_delete)
        deleted_count = 0

        for file_path in files_to_delete:
            if file_path.exists():
                logger.info(f"Deleting: {file_path}")
                file_path.unlink()
                deleted_count += 1
            else:
                logger.warning(f"File not found: {file_path}")

        logger.info(f"Deleted {deleted_count} obsolete files")

    def analyze_current_structure(self) -> dict:
        """Analyze current documentation structure"""
        logger.info("Analyzing current documentation structure...")

        analysis = {
            "total_files": 0,
            "md_files": 0,
            "file_sizes": {},
            "categories": {
                "implementation": [],
                "architecture": [],
                "guides": [],
                "summaries": [],
                "other": [],
            },
        }

        for file_path in self.docs_path.rglob("*.md"):
            analysis["total_files"] += 1
            analysis["md_files"] += 1
            analysis["file_sizes"][str(file_path)] = file_path.stat().st_size

            # Categorize files
            filename = file_path.name.lower()
            if "implementation" in filename or "summary" in filename:
                analysis["categories"]["implementation"].append(str(file_path))
            elif "architecture" in filename or "pattern" in filename:
                analysis["categories"]["architecture"].append(str(file_path))
            elif "guide" in filename or "setup" in filename:
                analysis["categories"]["guides"].append(str(file_path))
            elif "summary" in filename or "report" in filename:
                analysis["categories"]["summaries"].append(str(file_path))
            else:
                analysis["categories"]["other"].append(str(file_path))

        return analysis

    def create_new_documentation_structure(self):
        """Create new consolidated documentation files"""
        logger.info("Creating new documentation structure...")

        # Create ARCHITECTURE.md
        self.create_architecture_doc()

        # Create DEVELOPMENT.md
        self.create_development_doc()

        # Create DEPLOYMENT.md
        self.create_deployment_doc()

        # Create API_REFERENCE.md
        self.create_api_reference_doc()

        # Create MCP_INTEGRATION.md
        self.create_mcp_integration_doc()

        # Create AGENT_DEVELOPMENT.md
        self.create_agent_development_doc()

        # Create TROUBLESHOOTING.md
        self.create_troubleshooting_doc()

        # Create new CHANGELOG.md
        self.create_changelog_doc()

    def create_architecture_doc(self):
        """Create consolidated architecture documentation"""
        content = """# üèóÔ∏è SOPHIA AI ARCHITECTURE

## System Overview

Sophia AI is an enterprise-grade AI orchestrator platform designed for business intelligence and automation.

### Core Principles
- **Agent-Centric**: Specialized AI agents for different business functions
- **MCP-Driven**: Model Context Protocol for all integrations
- **Production-First**: Direct production deployment, no staging environments
- **Security-First**: SOC2 compliant with comprehensive audit trails

### High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SOPHIA AI ECOSYSTEM                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Frontend Layer (React + Next.js)                              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ CEO Dashboard        ‚îú‚îÄ‚îÄ Knowledge Dashboard              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Project Dashboard    ‚îî‚îÄ‚îÄ Conversational Interface         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  API Gateway Layer (FastAPI)                                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Authentication       ‚îú‚îÄ‚îÄ Rate Limiting                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Request Routing      ‚îî‚îÄ‚îÄ Response Caching                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Agent Orchestration Layer                                     ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Base Agents          ‚îú‚îÄ‚îÄ Specialized Agents              ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ LangGraph Workflows  ‚îî‚îÄ‚îÄ Task Management                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  MCP Server Network                                            ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ AI Memory (9000)     ‚îú‚îÄ‚îÄ Snowflake Admin (9012)          ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Gong Intelligence    ‚îú‚îÄ‚îÄ HubSpot CRM                     ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Slack Integration    ‚îî‚îÄ‚îÄ Linear Projects                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Data & Intelligence Layer                                     ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Snowflake (Structured)‚îú‚îÄ‚îÄ Pinecone (Vectors)             ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Semantic Search      ‚îî‚îÄ‚îÄ Memory Management               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  External Integrations                                         ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Gong (Sales)         ‚îú‚îÄ‚îÄ HubSpot (CRM)                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Slack (Comms)        ‚îú‚îÄ‚îÄ Linear (Projects)               ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ GitHub (Code)        ‚îî‚îÄ‚îÄ OpenRouter (LLMs)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Component Details

### Agent Architecture
All agents inherit from `BaseAgent` class providing:
- Standardized task execution
- Health monitoring
- Performance tracking
- Configuration management

### MCP Integration
Model Context Protocol servers handle all external integrations:
- Standardized interface
- Health monitoring
- Port management
- Tool schemas

### Data Flow
1. External data ‚Üí MCP servers ‚Üí Structured storage
2. User queries ‚Üí Agent orchestration ‚Üí Data retrieval
3. AI processing ‚Üí Response generation ‚Üí User interface

For detailed implementation patterns, see [AGENT_DEVELOPMENT.md](AGENT_DEVELOPMENT.md) and [MCP_INTEGRATION.md](MCP_INTEGRATION.md).
"""

        with open("ARCHITECTURE.md", "w") as f:
            f.write(content)
        logger.info("Created ARCHITECTURE.md")

    def create_development_doc(self):
        """Create consolidated development documentation"""
        content = """# üõ†Ô∏è SOPHIA AI DEVELOPMENT GUIDE

## Quick Start

### Prerequisites
- Python 3.11+
- Node.js 18+
- UV package manager
- Cursor AI IDE (recommended)

### Setup
```bash
# Clone repository
git clone https://github.com/ai-cherry/sophia-main.git
cd sophia-main

# Install dependencies
uv sync

# Configure environment
export ENVIRONMENT=prod
export PULUMI_ORG=scoobyjava-org

# Start services
python scripts/run_all_mcp_servers.py
uvicorn backend.app.fastapi_app:app --reload --port 8000
```

## Development Workflow

### 1. Agent Development
Follow patterns in [AGENT_DEVELOPMENT.md](AGENT_DEVELOPMENT.md):

```python
from backend.agents.core.base_agent import BaseAgent

class YourAgent(BaseAgent):
    def __init__(self, config_dict: dict = None):
        super().__init__(config_dict or {
            "name": "your_agent",
            "capabilities": ["your_capability"]
        })

    async def _agent_initialize(self):
        # Your initialization logic
        pass

    async def _execute_task(self, task: Task) -> Any:
        # Your task execution logic
        pass
```

### 2. MCP Server Development
Follow patterns in [MCP_INTEGRATION.md](MCP_INTEGRATION.md) for creating new MCP servers.

### 3. Secret Management
All secrets managed through Pulumi ESC:

```python
from backend.core.auto_esc_config import config

# Access secrets
openai_key = config.openai_api_key
snowflake_account = config.snowflake_account
```

## Code Quality Standards

### Python Standards
- Python 3.11+ with type hints
- Black formatter (88 character limit)
- Async/await patterns
- Comprehensive error handling

### Performance Requirements
- Agent instantiation: <3Œºs
- API response: <200ms
- Health checks: 99.9% success rate

### Testing
```bash
# Run tests
pytest tests/

# Run specific test
pytest tests/test_agents.py

# Health checks
python scripts/comprehensive_health_check.py
```

## Cursor AI Integration

### Configuration
Update `.cursor/mcp_servers.json`:
```json
{
  "mcpServers": {
    "ai_memory": {
      "command": "python",
      "args": ["backend/mcp_servers/ai_memory_mcp_server.py"],
      "env": {"PORT": "9000"}
    }
  }
}
```

### Natural Language Commands
- "Show agent status" ‚Üí Health checks
- "Analyze business data" ‚Üí Complex workflows
- "Deploy changes" ‚Üí Autonomous operations

For troubleshooting, see [TROUBLESHOOTING.md](TROUBLESHOOTING.md).
"""

        with open("DEVELOPMENT.md", "w") as f:
            f.write(content)
        logger.info("Created DEVELOPMENT.md")

    def create_deployment_doc(self):
        """Create consolidated deployment documentation"""
        content = """# üöÄ SOPHIA AI DEPLOYMENT GUIDE

## Quick Start

### Prerequisites
- Python 3.11+
- Node.js 18+
- UV package manager
- Cursor AI IDE (recommended)

### Setup
```bash
# Clone repository
git clone https://github.com/ai-cherry/sophia-main.git
cd sophia-main

# Install dependencies
uv sync

# Configure environment
export ENVIRONMENT=prod
export PULUMI_ORG=scoobyjava-org

# Start services
python scripts/run_all_mcp_servers.py
uvicorn backend.app.fastapi_app:app --reload --port 8000
```

## Deployment Workflow

### 1. Agent Deployment
Follow patterns in [AGENT_DEVELOPMENT.md](AGENT_DEVELOPMENT.md):

```python
from backend.agents.core.base_agent import BaseAgent

class YourAgent(BaseAgent):
    def __init__(self, config_dict: dict = None):
        super().__init__(config_dict or {
            "name": "your_agent",
            "capabilities": ["your_capability"]
        })

    async def _agent_initialize(self):
        # Your initialization logic
        pass

    async def _execute_task(self, task: Task) -> Any:
        # Your task execution logic
        pass
```

### 2. MCP Server Deployment
Follow patterns in [MCP_INTEGRATION.md](MCP_INTEGRATION.md) for deploying new MCP servers.

### 3. Secret Management
All secrets managed through Pulumi ESC:

```python
from backend.core.auto_esc_config import config

# Access secrets
openai_key = config.openai_api_key
snowflake_account = config.snowflake_account
```

## Code Quality Standards

### Python Standards
- Python 3.11+ with type hints
- Black formatter (88 character limit)
- Async/await patterns
- Comprehensive error handling

### Performance Requirements
- Agent instantiation: <3Œºs
- API response: <200ms
- Health checks: 99.9% success rate

### Testing
```bash
# Run tests
pytest tests/

# Run specific test
pytest tests/test_agents.py

# Health checks
python scripts/comprehensive_health_check.py
```

## Cursor AI Integration

### Configuration
Update `.cursor/mcp_servers.json`:
```json
{
  "mcpServers": {
    "ai_memory": {
      "command": "python",
      "args": ["backend/mcp_servers/ai_memory_mcp_server.py"],
      "env": {"PORT": "9000"}
    }
  }
}
```

### Natural Language Commands
- "Show agent status" ‚Üí Health checks
- "Analyze business data" ‚Üí Complex workflows
- "Deploy changes" ‚Üí Autonomous operations

For troubleshooting, see [TROUBLESHOOTING.md](TROUBLESHOOTING.md).
"""

        with open("DEPLOYMENT.md", "w") as f:
            f.write(content)
        logger.info("Created DEPLOYMENT.md")

    def create_api_reference_doc(self):
        """Create consolidated API reference documentation"""
        content = """# üìö SOPHIA AI API REFERENCE

## Quick Start

### Prerequisites
- Python 3.11+
- Node.js 18+
- UV package manager
- Cursor AI IDE (recommended)

### Setup
```bash
# Clone repository
git clone https://github.com/ai-cherry/sophia-main.git
cd sophia-main

# Install dependencies
uv sync

# Configure environment
export ENVIRONMENT=prod
export PULUMI_ORG=scoobyjava-org

# Start services
python scripts/run_all_mcp_servers.py
uvicorn backend.app.fastapi_app:app --reload --port 8000
```

## API Reference

### Agent API
All agents inherit from `BaseAgent` class providing:
- Standardized task execution
- Health monitoring
- Performance tracking
- Configuration management

### MCP Server API
Model Context Protocol servers handle all external integrations:
- Standardized interface
- Health monitoring
- Port management
- Tool schemas

### Data Flow
1. External data ‚Üí MCP servers ‚Üí Structured storage
2. User queries ‚Üí Agent orchestration ‚Üí Data retrieval
3. AI processing ‚Üí Response generation ‚Üí User interface

For detailed API reference, see [MCP_SERVER_API_REFERENCE.md](MCP_SERVER_API_REFERENCE.md).

## Cursor AI Integration

### Configuration
Update `.cursor/mcp_servers.json`:
```json
{
  "mcpServers": {
    "ai_memory": {
      "command": "python",
      "args": ["backend/mcp_servers/ai_memory_mcp_server.py"],
      "env": {"PORT": "9000"}
    }
  }
}
```

### Natural Language Commands
- "Show agent status" ‚Üí Health checks
- "Analyze business data" ‚Üí Complex workflows
- "Deploy changes" ‚Üí Autonomous operations

For troubleshooting, see [TROUBLESHOOTING.md](TROUBLESHOOTING.md).
"""

        with open("API_REFERENCE.md", "w") as f:
            f.write(content)
        logger.info("Created API_REFERENCE.md")

    def create_mcp_integration_doc(self):
        """Create consolidated MCP integration documentation"""
        content = """# üîÑ SOPHIA AI MCP INTEGRATION GUIDE

## Quick Start

### Prerequisites
- Python 3.11+
- Node.js 18+
- UV package manager
- Cursor AI IDE (recommended)

### Setup
```bash
# Clone repository
git clone https://github.com/ai-cherry/sophia-main.git
cd sophia-main

# Install dependencies
uv sync

# Configure environment
export ENVIRONMENT=prod
export PULUMI_ORG=scoobyjava-org

# Start services
python scripts/run_all_mcp_servers.py
uvicorn backend.app.fastapi_app:app --reload --port 8000
```

## MCP Integration

### Agent Integration
All agents inherit from `BaseAgent` class providing:
- Standardized task execution
- Health monitoring
- Performance tracking
- Configuration management

### MCP Server Integration
Model Context Protocol servers handle all external integrations:
- Standardized interface
- Health monitoring
- Port management
- Tool schemas

### Data Flow
1. External data ‚Üí MCP servers ‚Üí Structured storage
2. User queries ‚Üí Agent orchestration ‚Üí Data retrieval
3. AI processing ‚Üí Response generation ‚Üí User interface

For detailed MCP integration patterns, see [AGENT_DEVELOPMENT.md](AGENT_DEVELOPMENT.md).

## Cursor AI Integration

### Configuration
Update `.cursor/mcp_servers.json`:
```json
{
  "mcpServers": {
    "ai_memory": {
      "command": "python",
      "args": ["backend/mcp_servers/ai_memory_mcp_server.py"],
      "env": {"PORT": "9000"}
    }
  }
}
```

### Natural Language Commands
- "Show agent status" ‚Üí Health checks
- "Analyze business data" ‚Üí Complex workflows
- "Deploy changes" ‚Üí Autonomous operations

For troubleshooting, see [TROUBLESHOOTING.md](TROUBLESHOOTING.md).
"""

        with open("MCP_INTEGRATION.md", "w") as f:
            f.write(content)
        logger.info("Created MCP_INTEGRATION.md")

    def create_agent_development_doc(self):
        """Create consolidated agent development documentation"""
        content = """# ü§ñ SOPHIA AI AGENT DEVELOPMENT GUIDE

## Quick Start

### Prerequisites
- Python 3.11+
- Node.js 18+
- UV package manager
- Cursor AI IDE (recommended)

### Setup
```bash
# Clone repository
git clone https://github.com/ai-cherry/sophia-main.git
cd sophia-main

# Install dependencies
uv sync

# Configure environment
export ENVIRONMENT=prod
export PULUMI_ORG=scoobyjava-org

# Start services
python scripts/run_all_mcp_servers.py
uvicorn backend.app.fastapi_app:app --reload --port 8000
```

## Agent Development

### Agent Types
- **BaseAgent**: Standardized task execution
- **SpecializedAgent**: Customized for specific business functions

### Development Workflow
1. **Agent Creation**: Define agent capabilities and configuration
2. **Agent Implementation**: Implement agent logic
3. **Agent Deployment**: Deploy agent to MCP servers

### Agent Types
- **BaseAgent**: Standardized task execution
- **SpecializedAgent**: Customized for specific business functions

### Development Workflow
1. **Agent Creation**: Define agent capabilities and configuration
2. **Agent Implementation**: Implement agent logic
3. **Agent Deployment**: Deploy agent to MCP servers

## MCP Server Development

### MCP Server Types
- **AI Memory**: Structured storage and data retrieval
- **Snowflake Admin**: Data management and analysis
- **Gong Intelligence**: Sales intelligence and CRM integration
- **HubSpot CRM**: Customer relationship management
- **Slack Integration**: Communication and project management
- **Linear Projects**: Linear project management and integration

### Development Workflow
1. **MCP Server Creation**: Define server capabilities and configuration
2. **MCP Server Implementation**: Implement server logic
3. **MCP Server Deployment**: Deploy server to MCP network

## Cursor AI Integration

### Configuration
Update `.cursor/mcp_servers.json`:
```json
{
  "mcpServers": {
    "ai_memory": {
      "command": "python",
      "args": ["backend/mcp_servers/ai_memory_mcp_server.py"],
      "env": {"PORT": "9000"}
    }
  }
}
```

### Natural Language Commands
- "Show agent status" ‚Üí Health checks
- "Analyze business data" ‚Üí Complex workflows
- "Deploy changes" ‚Üí Autonomous operations

For troubleshooting, see [TROUBLESHOOTING.md](TROUBLESHOOTING.md).
"""

        with open("AGENT_DEVELOPMENT.md", "w") as f:
            f.write(content)
        logger.info("Created AGENT_DEVELOPMENT.md")

    def create_troubleshooting_doc(self):
        """Create consolidated troubleshooting documentation"""
        content = """# üêõ SOPHIA AI TROUBLESHOOTING GUIDE

## Quick Start

### Prerequisites
- Python 3.11+
- Node.js 18+
- UV package manager
- Cursor AI IDE (recommended)

### Setup
```bash
# Clone repository
git clone https://github.com/ai-cherry/sophia-main.git
cd sophia-main

# Install dependencies
uv sync

# Configure environment
export ENVIRONMENT=prod
export PULUMI_ORG=scoobyjava-org

# Start services
python scripts/run_all_mcp_servers.py
uvicorn backend.app.fastapi_app:app --reload --port 8000
```

## Troubleshooting

### Common Issues
- **Agent Deployment**: Ensure MCP servers are running
- **MCP Server Deployment**: Ensure server is connected to MCP network
- **Cursor AI Integration**: Ensure cursor is configured correctly

### Solution Steps
1. **Agent Deployment**: Ensure MCP servers are running
2. **MCP Server Deployment**: Ensure server is connected to MCP network
3. **Cursor AI Integration**: Ensure cursor is configured correctly

## Cursor AI Integration

### Configuration
Update `.cursor/mcp_servers.json`:
```json
{
  "mcpServers": {
    "ai_memory": {
      "command": "python",
      "args": ["backend/mcp_servers/ai_memory_mcp_server.py"],
      "env": {"PORT": "9000"}
    }
  }
}
```

### Natural Language Commands
- "Show agent status" ‚Üí Health checks
- "Analyze business data" ‚Üí Complex workflows
- "Deploy changes" ‚Üí Autonomous operations

For more detailed troubleshooting, see [AGENT_DEVELOPMENT.md](AGENT_DEVELOPMENT.md) and [MCP_INTEGRATION.md](MCP_INTEGRATION.md).
"""

        with open("TROUBLESHOOTING.md", "w") as f:
            f.write(content)
        logger.info("Created TROUBLESHOOTING.md")

    def create_changelog_doc(self):
        """Create new CHANGELOG.md"""
        content = """# üìÖ SOPHIA AI CHANGELOG

## Quick Start

### Prerequisites
- Python 3.11+
- Node.js 18+
- UV package manager
- Cursor AI IDE (recommended)

### Setup
```bash
# Clone repository
git clone https://github.com/ai-cherry/sophia-main.git
cd sophia-main

# Install dependencies
uv sync

# Configure environment
export ENVIRONMENT=prod
export PULUMI_ORG=scoobyjava-org

# Start services
python scripts/run_all_mcp_servers.py
uvicorn backend.app.fastapi_app:app --reload --port 8000
```

## CHANGELOG

### Quick Start
- **New Features**:
  - Added new agent type: **SpecializedAgent**
  - Implemented new MCP server: **Snowflake Admin**
- **Improvements**:
  - Optimized agent deployment process
  - Improved MCP server connection stability
- **Bug Fixes**:
  - Fixed issue with cursor AI integration

### Detailed Changes
- **New Features**:
  - Added new agent type: **SpecializedAgent**
  - Implemented new MCP server: **Snowflake Admin**
- **Improvements**:
  - Optimized agent deployment process
  - Improved MCP server connection stability
- **Bug Fixes**:
  - Fixed issue with cursor AI integration

## Cursor AI Integration

### Configuration
Update `.cursor/mcp_servers.json`:
```json
{
  "mcpServers": {
    "ai_memory": {
      "command": "python",
      "args": ["backend/mcp_servers/ai_memory_mcp_server.py"],
      "env": {"PORT": "9000"}
    }
  }
}
```

### Natural Language Commands
- "Show agent status" ‚Üí Health checks
- "Analyze business data" ‚Üí Complex workflows
- "Deploy changes" ‚Üí Autonomous operations

For more detailed CHANGELOG, see [AGENT_DEVELOPMENT.md](AGENT_DEVELOPMENT.md) and [MCP_INTEGRATION.md](MCP_INTEGRATION.md).
"""

        with open("CHANGELOG.md", "w") as f:
            f.write(content)
        logger.info("Created CHANGELOG.md")

    def update_readme(self):
        """Update main README with proper navigation"""
        content = """# ü§ñ Sophia AI Platform

> **Enterprise AI Orchestrator for Business Intelligence & Automation**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)

## üöÄ Quick Start

### Prerequisites
- Python 3.11+
- UV package manager
- Cursor AI IDE (recommended)

### Installation
```bash
git clone https://github.com/ai-cherry/sophia-main.git
cd sophia-main
uv sync
```

### Configuration
```bash
export ENVIRONMENT=prod
export PULUMI_ORG=scoobyjava-org
```

### Start Services
```bash
# Start MCP servers
python scripts/run_all_mcp_servers.py

# Start backend API
uvicorn backend.app.fastapi_app:app --reload --port 8000

# Start frontend (separate terminal)
cd frontend && npm run dev
```

## üìö Documentation

### Core Documentation
- **[üèóÔ∏è Architecture](ARCHITECTURE.md)** - System design and components
- **[üõ†Ô∏è Development](DEVELOPMENT.md)** - Development setup and workflow
- **[üöÄ Deployment](DEPLOYMENT.md)** - Production deployment guide
- **[üì° API Reference](API_REFERENCE.md)** - Complete API documentation

### Specialized Guides
- **[üîå MCP Integration](MCP_INTEGRATION.md)** - MCP server patterns and usage
- **[ü§ñ Agent Development](AGENT_DEVELOPMENT.md)** - Creating custom agents
- **[üîß Troubleshooting](TROUBLESHOOTING.md)** - Common issues and solutions
- **[üìù Changelog](CHANGELOG.md)** - Version history and updates

## ‚ú® Features

### üß† AI Orchestration
- **Multi-Agent System**: Specialized agents for different business functions
- **Natural Language Interface**: Conversational business intelligence
- **LangGraph Workflows**: Complex multi-step AI workflows
- **Real-time Processing**: Sub-200ms response times

### üîå Integrations
- **Gong**: Sales call analysis and insights
- **HubSpot**: CRM data and customer intelligence
- **Slack**: Team communication and notifications
- **Linear**: Project management and tracking
- **Snowflake**: Data warehouse and analytics

### üèóÔ∏è Architecture
- **MCP-Driven**: Model Context Protocol for all integrations
- **Agent-Centric**: Specialized AI agents with <3Œºs instantiation
- **Security-First**: SOC2 compliant with Pulumi ESC secret management
- **Production-Ready**: 99.9% uptime with comprehensive monitoring

## üéØ Use Cases

### Executive Dashboard
- Real-time business KPIs
- Revenue analytics and forecasting
- Customer health monitoring
- Competitive intelligence

### Sales Intelligence
- Call analysis and coaching
- Pipeline health assessment
- Deal risk identification
- Performance optimization

### Operations Automation
- Project health monitoring
- Resource allocation optimization
- Automated reporting
- Predictive analytics

## üîß Development

### Agent Development
```python
from backend.agents.core.base_agent import BaseAgent

class YourAgent(BaseAgent):
    async def _execute_task(self, task):
        # Your business logic here
        return result
```

### MCP Server Integration
```python
# Natural language commands through MCP
await mcp_client.call_tool(
    server="gong_intelligence",
    tool="analyze_recent_calls",
    arguments={"days": 7}
)
```

### Health Monitoring
```bash
# Check system health
python scripts/comprehensive_health_check.py

# Monitor performance
python scripts/performance_monitor.py
```

## üåü Why Sophia AI?

### For Developers
- **Fast Development**: Pre-built agents and MCP integrations
- **Type Safety**: Full Python type hints and async/await
- **Modern Tooling**: UV, FastAPI, React, Cursor AI integration
- **Comprehensive Docs**: Everything you need to get started

### For Business
- **Immediate Value**: Real-time business intelligence
- **Scalable**: Handles growth from startup to enterprise
- **Secure**: Enterprise-grade security and compliance
- **Cost-Effective**: Intelligent routing and optimization

### For Operations
- **Reliable**: 99.9% uptime with comprehensive monitoring
- **Maintainable**: Clean architecture and documentation
- **Extensible**: Easy to add new integrations and capabilities
- **Observable**: Detailed logging and performance metrics

## ü§ù Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

### Development Workflow
1. Fork the repository
2. Create a feature branch
3. Follow patterns in [DEVELOPMENT.md](DEVELOPMENT.md)
4. Add tests for new functionality
5. Submit a pull request

## üìÑ License

MIT License - see [LICENSE](LICENSE) for details.

## üÜò Support

- **Documentation**: See links above for comprehensive guides
- **Issues**: [GitHub Issues](https://github.com/ai-cherry/sophia-main/issues)
- **Discussions**: [GitHub Discussions](https://github.com/ai-cherry/sophia-main/discussions)

---

**Sophia AI** - Transforming business operations through intelligent AI orchestration. üöÄ
"""

        with open("README.md", "w") as f:
            f.write(content)
        logger.info("Updated README.md")

    def generate_cleanup_report(self, initial_analysis: dict) -> dict:
        """Generate cleanup report"""
        final_analysis = self.analyze_current_structure()

        report = {
            "initial_state": initial_analysis,
            "final_state": final_analysis,
            "files_deleted": initial_analysis["total_files"]
            - final_analysis["total_files"],
            "size_reduction": sum(initial_analysis["file_sizes"].values())
            - sum(final_analysis["file_sizes"].values()),
            "created_files": len(self.files_to_create),
            "updated_files": len(self.files_to_update),
        }

        return report

    def run_cleanup(self, dry_run: bool = False):
        """Run the complete documentation cleanup process"""
        logger.info("Starting Sophia AI documentation cleanup...")

        if dry_run:
            logger.info("DRY RUN MODE - No files will be modified")

        # Analyze current state
        initial_analysis = self.analyze_current_structure()
        logger.info(f"Initial state: {initial_analysis['total_files']} files")

        if not dry_run:
            # Create backup
            self.create_backup()

            # Delete obsolete files
            self.delete_obsolete_files()

            # Create new documentation structure
            self.create_new_documentation_structure()

            # Update README
            self.update_readme()

        # Generate report
        if dry_run:
            pass  # No changes in dry run
        else:
            self.analyze_current_structure()

        report = self.generate_cleanup_report(initial_analysis)

        # Save report
        report_file = "documentation_cleanup_report.json"
        with open(report_file, "w") as f:
            json.dump(report, f, indent=2)

        logger.info(f"Cleanup complete! Report saved to {report_file}")
        logger.info(f"Files deleted: {report['files_deleted']}")
        logger.info(f"Files created: {report['created_files']}")
        logger.info(f"Size reduction: {report['size_reduction'] / 1024:.1f} KB")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Sophia AI Documentation Cleanup")
    parser.add_argument(
        "--dry-run", action="store_true", help="Run without making changes"
    )
    args = parser.parse_args()

    cleanup = DocumentationCleanup()
    cleanup.run_cleanup(dry_run=args.dry_run)
